# Tool Execution Layer Specification

**Version:** 1.0.0
**Status:** Final
**Last Updated:** 2026-01-14
**Layer:** L03 - Tool Execution Layer

---

## Document Information

| Property | Value |
|----------|-------|
| **Specification ID** | L03-TOOL-EXEC-v1.0 |
| **Layer Position** | L03 (between L02 Agent Runtime and L11 Integration Layer) |
| **Technology Stack** | PostgreSQL 16 + pgvector, Redis 7, Ollama, PM2, Kubernetes |
| **Key Integrations** | Phase 15 (Document Management), Phase 16 (Session Orchestration) |
| **Architecture Decisions** | ADR-001 (MCP stdio transport), ADR-002 (Lightweight dev stack) |
| **Boundary Conditions** | BC-1 (Nested sandbox with L02), BC-2 (tool.invoke() with L11) |

---

## Table of Contents

### Core Specification

1. [Executive Summary](#section-1-executive-summary)
2. [Scope Definition](#section-2-scope-definition)
3. [Architecture](#section-3-architecture)
4. [Interfaces](#section-4-interfaces)
5. [Data Model](#section-5-data-model)
6. [Integration with Data Layer](#section-6-integration-with-data-layer)
7. [Reliability and Scalability](#section-7-reliability-and-scalability)
8. [Security](#section-8-security)
9. [Observability](#section-9-observability)
10. [Configuration](#section-10-configuration)
11. [Implementation Guide](#section-11-implementation-guide)
12. [Testing Strategy](#section-12-testing-strategy)
13. [Migration and Deployment](#section-13-migration-and-deployment)
14. [Open Questions and Decisions](#section-14-open-questions-and-decisions)
15. [References and Appendices](#section-15-references-and-appendices)

### Appendices

- [Appendix A: Gap Analysis Integration Summary](#appendix-a-gap-analysis-integration-summary)
- [Appendix B: Error Code Reference](#appendix-b-error-code-reference)
- [Appendix C: Tool Manifest Schema](#appendix-c-tool-manifest-schema-complete-json-schema)
- [Appendix D: MCP Bridge Configuration Examples](#appendix-d-mcp-bridge-configuration-examples)

---

## Document Purpose

This specification defines the **Tool Execution Layer (L03)**, a critical component of the agentic AI platform responsible for secure, isolated execution of tools invoked by AI agents. The layer provides:

- **Nested sandbox architecture** for tool isolation within agent sandboxes (BC-1)
- **Tool registry** with semantic search and version management
- **Permission and authorization** via ABAC integration
- **Resilience patterns** including circuit breakers and retry logic
- **MCP integration** for document context (Phase 15) and checkpointing (Phase 16)
- **Comprehensive observability** with metrics, logging, tracing, and alerting

---

# Tool Execution Layer Specification v1.0 - Part 1

**Document Status:** Draft
**Version:** 1.0 (Part 1 of 3)
**Date:** 2026-01-14
**Layer:** L03 - Tool Execution Layer
**Sections:** 1-5 (Executive Summary, Scope, Architecture, Interfaces, Data Model)

---

## Section 1: Executive Summary

### 1.1 Purpose

The Tool Execution Layer (L03) provides a secure, isolated environment for AI agent tool invocations, maintaining a registry of available tools with capability manifests and enforcing tool-level permissions. It acts as the critical boundary between agent intent and external system access, ensuring that tools execute safely within nested sandboxes, respect rate limits, handle failures gracefully through circuit breakers, and maintain state for long-running operations.

This layer addresses the emerging security challenge of AI agents as "the new insider threat" in 2026 enterprise environments. Research shows that 60% of production agent failures stem from tool versioning issues, while uncontrolled tool access represents a significant attack surface for agent misbehavior. L03 mitigates these risks through capability-based authorization, comprehensive audit logging, and fail-safe resilience patterns.

The Tool Execution Layer integrates two critical MCP (Model Context Protocol) bridges: the **Document Bridge (Phase 15)** provides tools with access to authoritative documentation during execution, ensuring consistency with organizational knowledge; the **State Bridge (Phase 16)** enables checkpoint-based recovery for long-running operations, allowing tools to resume after interruptions without reprocessing. These integrations position L03 as the operational nexus between agent reasoning (L02) and the agentic data ecosystem (L01, Phase 15/16).

### 1.2 Key Capabilities

| Capability | Description | Technology Foundation | Phase Integration |
|------------|-------------|----------------------|-------------------|
| **Protocol-Agnostic Tool Registry** | Unified interface for tools from MCP servers, OpenAPI specs, LangChain definitions, and native functions with semantic search via pgvector | PostgreSQL 16 + pgvector, ToolRegistry pattern | Phase 15: MCP tool discovery |
| **Nested Sandbox Execution (BC-1)** | Tool sandboxes isolated within agent sandboxes with resource sub-allocation, filesystem restrictions, and network policies | Kubernetes Agent Sandbox (gVisor for cloud, Firecracker for on-prem) | N/A |
| **Capability-Based Authorization** | Unforgeable capability tokens grant tool execution rights without central authorization service lookups | JWT (RS256) with OPA policy validation | N/A |
| **External API Management** | Rate limiting, circuit breaking, exponential backoff with jitter, and credential rotation for external service integrations | Redis 7 (state), Resilience4j (circuit breaker), Tenacity (retry), HashiCorp Vault (secrets) | N/A |
| **Fail-Safe Resilience** | Three-state circuit breakers (closed, open, half-open) with health-based triggers prevent cascading failures across tools | Redis 7 (distributed state), Resilience4j library | N/A |
| **Result Validation & Type Safety** | JSON Schema validation of tool outputs with type coercion and sanitization before returning to agents | AJV validator, custom sanitization rules | N/A |
| **Document Context Bridge (Phase 15)** | MCP client for document-consolidator service provides tools with authoritative document access, caching, and version pinning | MCP stdio transport (JSON-RPC 2.0), PM2 process management, Redis cache (5-min TTL) | **Phase 15: Full integration** |
| **State Checkpoint Bridge (Phase 16)** | MCP client for context-orchestrator service enables hybrid checkpointing (micro: Redis/30s, macro: PostgreSQL/events, named: manual) for resumable operations | MCP stdio transport (JSON-RPC 2.0), Redis (hot checkpoints), PostgreSQL (cold checkpoints) | **Phase 16: Full integration** |

### 1.3 Position in Stack

```
+========================================================================+
|                       L11: INTEGRATION LAYER                           |
|  (Workflow orchestration, multi-agent coordination)                    |
+========================================================================+
                               |
                               | BC-2: tool.invoke()
                               | (ToolInvokeRequest -> ToolInvokeResponse)
                               v
+========================================================================+
|                    L03: TOOL EXECUTION LAYER                           |
|                                                                        |
|  +------------------------------------------------------------------+  |
|  | Tool Registry   | Tool Executor  | Permission    | Circuit       |  |
|  | (PostgreSQL +   | (Nested        | Checker       | Breaker       |  |
|  |  pgvector)      |  Sandbox)      | (OPA + JWT)   | (Resilience4j)|  |
|  +------------------------------------------------------------------+  |
|  | External API    | Result         | Document      | State         |  |
|  | Manager         | Validator      | Bridge        | Bridge        |  |
|  | (Redis +        | (AJV + Schema) | (Phase 15     | (Phase 16     |  |
|  |  Vault)         |                |  MCP)         |  MCP)         |  |
|  +------------------------------------------------------------------+  |
|                                                                        |
|  MCP Bridges (stdio JSON-RPC):                                        |
|  +---------------------------+  +----------------------------------+   |
|  | document-consolidator     |  | context-orchestrator             |   |
|  | (Phase 15)                |  | (Phase 16)                       |   |
|  | - get_source_of_truth     |  | - save_context_snapshot          |   |
|  | - search_documents        |  | - create_checkpoint              |   |
|  | - find_overlaps           |  | - rollback_to                    |   |
|  | - get_document_metadata   |  | - get_unified_context            |   |
|  +---------------------------+  +----------------------------------+   |
+========================================================================+
                               ^
                               | BC-1: Nested sandbox context
                               | (agent_did, resource_limits, network_policy)
                               |
+========================================================================+
|                    L02: AGENT RUNTIME LAYER                            |
|  (Agent sandbox management, lifecycle control)                         |
+========================================================================+
                               ^
                               |
+========================================================================+
|                    L01: AGENTIC DATA LAYER                             |
|  (Event Store, ABAC Engine, Vector Store, Audit Log)                  |
+========================================================================+
```

**Key Interfaces:**
- **BC-1 (Boundary Condition 1):** Tool sandboxes are nested within agent sandboxes owned by L02 (Agent Runtime Layer). L03 inherits resource limits, network policies, and filesystem restrictions from L02, then applies additional tool-specific constraints.
- **BC-2 (Boundary Condition 2):** L03 exposes `tool.invoke()` interface consumed by L11 (Integration Layer) for workflow orchestration and multi-agent coordination.
- **Phase 15 Integration:** Document Bridge connects L03 to document-consolidator MCP server for authoritative document access during tool execution.
- **Phase 16 Integration:** State Bridge connects L03 to context-orchestrator MCP server for checkpoint-based state persistence and recovery.

### 1.4 Design Principles

1. **Nested Isolation (BC-1 Principle)**
   Tool sandboxes operate within agent sandboxes with strictly more restrictive permissions. Tool resource limits must be less than or equal to agent resource limits. Tool network access must be a subset of agent network access. Tool filesystem access must be within agent filesystem boundaries. This prevents privilege escalation while enabling fine-grained tool-level control.

2. **Fail-Safe Resilience**
   Circuit breakers default to open (blocking) on ambiguous states. Rate limiters use token bucket algorithm with burst tolerance. Retries use exponential backoff with full jitter to prevent thundering herd. External API failures never propagate to block agent progressâ€”tools return structured errors with retry guidance.

3. **Capability-Based Authorization**
   Tool invocation tokens are unforgeable capabilities (JWT with RS256 signatures). Possessing a valid capability token grants tool execution rights without additional authorization service lookups. This decentralized pattern scales better than centralized RBAC/ABAC for distributed agent systems while maintaining security through cryptographic signatures.

4. **Checkpoint-Driven Recovery (Phase 16)**
   Long-running tools (> 30 seconds) automatically checkpoint progress at 30-second intervals (micro-checkpoints to Redis) and at key milestones (macro-checkpoints to PostgreSQL). Tools can resume from the last valid checkpoint after timeout, crash, or cancellation, minimizing reprocessing and enabling resilient operations.

5. **Document Version Pinning (Phase 15)**
   Tools requiring document context explicitly pin document versions at invocation start. Pinned versions remain immutable throughout tool execution, preventing "moving target" issues where documents change mid-execution. Checkpoints include document version maps to ensure consistent state on resume.

6. **Protocol Agnosticism**
   Tool registry abstracts tool sources (MCP servers, OpenAPI specs, LangChain tools, native functions) behind a unified interface. Tools are discovered via semantic search over capability descriptions using pgvector embeddings. This prevents vendor lock-in and enables gradual migration between tool ecosystems.

7. **Defense in Depth**
   Security layered across multiple boundaries: (1) Permission Checker validates capability tokens, (2) OPA enforces policy-based access control, (3) Sandbox Manager enforces resource limits and isolation, (4) Result Validator sanitizes outputs for XSS/injection, (5) Audit Logger records all invocations for forensic analysis. Compromise of any single layer does not compromise the system.

---

## Section 2: Scope Definition

### 2.1 In Scope

| Capability | Description | Components Involved | Gap References |
|------------|-------------|---------------------|----------------|
| **Tool Registry & Discovery** | Maintain catalog of available tools with capability manifests, semantic descriptions, version history, and dependency metadata. Support semantic search via pgvector embeddings. Manage tool lifecycle (active, deprecated, sunset, removed). Handle multiple concurrent versions per tool with SemVer conflict resolution. | Tool Registry, MCP Bridge (tool discovery from document-consolidator/context-orchestrator) | G-001, G-002, G-003 |
| **Nested Sandbox Execution** | Execute tools within isolated sandboxes nested inside agent sandboxes (BC-1). Inherit resource limits (CPU, memory, timeout) from agent context and sub-allocate to tools. Enforce filesystem restrictions (subset of agent mounts) and network policies (subset of agent allowed hosts). Support gVisor (cloud) and Firecracker (on-prem) isolation technologies. | Tool Executor, Sandbox Manager | BC-1 interface |
| **Permission Enforcement** | Validate capability tokens (JWT) for tool invocation authorization. Query OPA for policy-based access control (filesystem, network, credentials). Enforce least-privilege principle: tools only access explicitly allowed resources. Cache permissions in Redis with invalidation on policy updates. | Permission Checker | G-006, G-007 |
| **External API Management** | Manage connections to external services (APIs, databases, file systems). Handle authentication via runtime secret injection from HashiCorp Vault (ephemeral credentials). Enforce rate limits per tool/API (token bucket algorithm, Redis counters). Implement circuit breakers per API endpoint (Resilience4j, Redis state). Apply retry logic with exponential backoff and full jitter (Tenacity library). | External Adapter Manager, Circuit Breaker Controller | G-008, G-009 |
| **Result Validation** | Validate tool outputs against JSON Schema defined in tool manifest. Perform type coercion (e.g., string -> number, ISO 8601 -> Date) and sanitization (SQL injection, XSS, command injection patterns). Enforce structured output contracts for tools with schema definitions. Return validation errors to agent with specific field-level feedback. | Result Validator | G-010, G-011, G-012 |
| **Document Context Integration (Phase 15)** | Provide tools with access to authoritative documents via document-consolidator MCP server. Support semantic search (`search_documents`), content retrieval (`get_source_of_truth`), metadata access (`get_document_metadata`), and version pinning. Cache frequently accessed documents in Redis (5-min TTL) with pub/sub invalidation. Query ABAC engine for document access permissions. | Document Bridge, MCP Client | G-013, G-014, Phase 15 integration |
| **State Checkpoint Management (Phase 16)** | Persist tool execution state for resumability via context-orchestrator MCP server. Implement hybrid checkpointing: micro-checkpoints (Redis, 30s intervals), macro-checkpoints (PostgreSQL, event milestones), named checkpoints (manual recovery points). Support resume from checkpoint after timeout, crash, or cancellation. Store checkpoint diffs for large states using delta encoding. | State Bridge, MCP Client, State Checkpointer | G-015, G-016, Phase 16 integration |
| **Audit Logging & Compliance** | Stream tool invocation events to Kafka in CloudEvents 1.0 format. Record invocation parameters (PII-sanitized), results, duration, resource usage, errors, and document/state access patterns. Partition by tenant_id for multi-tenancy isolation. Retain 90 days in hot storage, 7 years in cold storage (S3 Glacier). Support SIEM integration (Splunk, Datadog, Elastic). | Audit Logger | G-017, G-018, G-019 |

### 2.2 Out of Scope

| Excluded Capability | Rationale | Owning Layer |
|---------------------|-----------|--------------|
| **LLM Function Calling** | Transforming tool manifests into provider-specific function calling formats (OpenAI functions, Anthropic tools, Google function declarations) is L11 responsibility. L03 maintains vendor-neutral tool definitions. | L11: Integration Layer |
| **Agent Sandbox Management** | Creating, managing, and destroying agent-level sandboxes is L02 responsibility. L03 operates within sandboxes provided by L02 (BC-1 nested isolation). | L02: Agent Runtime Layer |
| **Multi-Agent Coordination** | Orchestrating tool invocations across multiple agents, resolving inter-agent dependencies, and managing distributed workflows is L11 responsibility. L03 executes single-agent tool invocations. | L11: Integration Layer |
| **Policy Authoring** | Defining ABAC policies for tool access control is L01 responsibility (ABAC Engine). L03 enforces policies but does not author them. | L01: Agentic Data Layer |
| **Document Content Management** | Storing, versioning, consolidating, and searching document content is Phase 15 responsibility. L03 consumes documents via MCP bridge but does not manage document lifecycle. | Phase 15: Document Management (MCP Server) |
| **Session State Management** | Tracking agent session lifecycle, managing session context, and coordinating state across session phases is Phase 16 responsibility. L03 checkpoints tool-specific state but does not manage session-level state. | Phase 16: Session Orchestration (MCP Server) |

### 2.3 Boundary Decisions

#### BC-1: Nested Sandbox Interface (L02 -> L03)

**Decision:** Tool sandboxes are nested within agent sandboxes owned by L02 (Agent Runtime Layer).

**Rationale:** Agent-level sandboxes provide coarse-grained isolation (agent from agent). Tool-level sandboxes provide fine-grained isolation (tool from tool within same agent). Nesting ensures tools cannot escape agent security boundaries while allowing per-tool restrictions.

**Interface Contract:**
```
L02 provides:
- agent_did (identity)
- parent_sandbox_id (Kubernetes Sandbox CRD)
- resource_limits (CPU: millicores, memory: MB, timeout: seconds)
- network_policy (allowed_hosts, allowed_ports, DNS servers)
- filesystem_policy (mount paths, read-only vs read-write)

L03 consumes:
- Validates tool resource requests <= agent limits
- Creates nested sandbox (SandboxClaim referencing parent_sandbox_id)
- Adds tool-specific network restrictions (subset of allowed_hosts)
- Adds tool-specific filesystem restrictions (subdirectories of agent mounts)
- Enforces timeout <= agent timeout
```

**Technology:** Kubernetes Agent Sandbox CRD with gVisor runtime (cloud deployments) or Firecracker runtime (on-prem deployments).

**Gap Addressed:** None directly, but foundation for G-004 (async execution patterns) and G-005 (priority scheduling).

---

#### BC-2: Tool Invocation Interface (L03 -> L11)

**Decision:** L03 exposes `tool.invoke()` method consumed by L11 (Integration Layer) for workflow orchestration.

**Rationale:** L11 orchestrates multi-agent workflows and coordinates tool invocations across agents. L11 needs a synchronous interface for immediate tool execution and an asynchronous interface for long-running tools (> 30s). L03 provides both via a single `tool.invoke()` method with `async_mode` parameter.

**Interface Contract:**
```
L11 invokes:
- tool.invoke(request: ToolInvokeRequest) -> ToolInvokeResponse

Request includes:
- tool_id, tool_version (semantic version)
- agent_context (agent_did, tenant_id, session_id)
- parameters (validated against tool manifest schema)
- resource_limits (optional, defaults from manifest)
- document_context (Phase 15: document_refs, version_pinning, query)
- checkpoint_config (Phase 16: enable_checkpointing, interval, resume_from)
- execution_options (async_mode, priority, idempotency_key, require_approval)

Response includes:
- status (pending, running, success, error, timeout, cancelled, permission_denied, pending_approval)
- result (tool-specific, validated against manifest schema)
- error (code, message, details, retryable flag)
- execution_metadata (duration, resource usage, documents_accessed, checkpoints_created)
- checkpoint_ref (for resumable operations)
- polling_info (for async mode)
```

**Technology:** REST API (JSON over HTTP) or gRPC (protobuf) for performance-critical deployments.

**Gap Addressed:** G-006 (capability token in agent_context), G-020 (multi-tool workflow orchestration from L11).

---

#### ADR-001: MCP Integration Architecture

**Decision:** MCP servers (document-consolidator, context-orchestrator) communicate with L03 via stdio transport (JSON-RPC 2.0), not HTTP.

**Rationale:** stdio transport provides process-level isolation, no network configuration overhead, guaranteed message delivery within same host, and inherent security through OS-level process boundaries. PM2 manages MCP server lifecycle (auto-restart on crash, log aggregation, clustering).

**Implementation:**
```
PM2 starts MCP server process:
  pm2 start mcp-document-consolidator --name "doc-bridge"

L03 MCP Client:
  - Opens stdin/stdout pipes to MCP server process
  - Sends JSON-RPC requests on stdin
  - Reads JSON-RPC responses from stdout
  - Enforces timeout (30s default, kills process if no response)
  - Captures stderr for error logging
```

**Gap Addressed:** None directly, but foundation for Phase 15/16 integrations (G-013, G-014, G-015).

---

#### ADR-002: Lightweight Development Stack

**Decision:** PostgreSQL 16 + pgvector (tool registry), Redis 7 (hot state), Ollama (local LLM inference), PM2 (MCP process management).

**Rationale:** Avoid heavy infrastructure dependencies (Kubernetes-only, cloud-specific services). Enable local development and on-prem deployments. PostgreSQL provides relational storage + vector search in single database. Redis provides fast cache/state with JSON data type. Ollama enables local semantic search without API costs.

**Technology Mapping:**
- **PostgreSQL 16 + pgvector:** Tool registry, tool versions, tool manifests, cold checkpoints, audit logs (90-day retention)
- **Redis 7 (JSON data type):** Circuit breaker state, rate limit counters, hot checkpoints (TTL 1 hour), permission cache, document cache
- **Ollama (Mistral 7B):** Semantic embeddings for tool descriptions, tool selection from natural language queries
- **PM2:** MCP server process lifecycle, auto-restart, log rotation, clustering for high availability

**Gap Addressed:** Technology foundation for G-001 (manifest schema in PostgreSQL), G-008 (circuit breaker notifications via Redis pub/sub), G-010 (result validation schema storage).

---

## Section 3: Architecture

### 3.1 Component Diagram

```
+======================================================================+
|                    L03: TOOL EXECUTION LAYER                         |
+======================================================================+
|                                                                      |
|  +----------------+  +----------------+  +------------------+        |
|  | Tool Registry  |  | Tool Executor  |  | Permission       |        |
|  |                |  |                |  | Checker          |        |
|  | - Tool catalog |  | - Sandbox mgmt |  | - JWT validation |        |
|  | - Semantic     |  | - Resource     |  | - OPA query      |        |
|  |   search       |  |   allocation   |  | - Capability     |        |
|  | - Versioning   |  | - Isolation    |  |   tokens         |        |
|  | - Deprecation  |  |   (gVisor/FC)  |  | - Cache mgmt     |        |
|  +-------+--------+  +-------+--------+  +--------+---------+        |
|          |                   |                    |                  |
|          |                   v                    v                  |
|          |          +------------------+  +------------------+       |
|          |          | External Adapter |  | Circuit Breaker  |       |
|          |          | Manager          |  | Controller       |       |
|          |          |                  |  |                  |       |
|          |          | - API clients    |  | - State machine  |       |
|          |          | - Credential     |  | - Health checks  |       |
|          |          |   injection      |  | - Transitions    |       |
|          |          | - Rate limiting  |  | - Notifications  |       |
|          |          | - Retry logic    |  | - Redis state    |       |
|          |          +------------------+  +--------+---------+       |
|          |                   |                    |                  |
|          v                   v                    v                  |
|  +------------------+  +------------------+                          |
|  | Result Validator |  | Audit Logger     |                          |
|  |                  |  |                  |                          |
|  | - Schema check   |  | - CloudEvents    |                          |
|  | - Type coercion  |  | - Kafka stream   |                          |
|  | - Sanitization   |  | - PII redaction  |                          |
|  | - Error handling |  | - Tenant partition|                         |
|  +------------------+  +------------------+                          |
|                                                                      |
|  +------------------------------------------------------------------+|
|  | MCP BRIDGES (stdio JSON-RPC)                                     ||
|  +------------------------------------------------------------------+|
|  |                                                                  ||
|  |  +--------------------------+  +------------------------------+ ||
|  |  | Document Bridge          |  | State Bridge                 | ||
|  |  | (Phase 15)               |  | (Phase 16)                   | ||
|  |  |                          |  |                              | ||
|  |  | - MCP client             |  | - MCP client                 | ||
|  |  | - Document query         |  | - Checkpoint creation        | ||
|  |  | - Cache management       |  | - State restoration          | ||
|  |  | - Version pinning        |  | - Delta encoding             | ||
|  |  | - Permission check       |  | - TTL management             | ||
|  |  +------------+-------------+  +-------------+----------------+ ||
|  |               |                              |                  ||
|  |               v stdin/stdout                 v stdin/stdout     ||
|  |  +--------------------------+  +------------------------------+ ||
|  |  | document-consolidator    |  | context-orchestrator         | ||
|  |  | (MCP Server, Phase 15)   |  | (MCP Server, Phase 16)       | ||
|  |  +--------------------------+  +------------------------------+ ||
|  +------------------------------------------------------------------+|
|                                                                      |
+======================================================================+
                           ^                    ^
                           |                    |
                    BC-1: Nested sandbox  BC-2: tool.invoke()
                    (from L02)            (to L11)
                           |                    |
+==========================+====================+=======================+
|          L02: Agent Runtime        |    L11: Integration Layer       |
+====================================+==================================+
```

### 3.2 Component Inventory

| Component | Purpose | Technology (ADR-002) | Dependencies | Status |
|-----------|---------|---------------------|--------------|--------|
| **Tool Registry** | Catalog of available tools with capability manifests, semantic search, versioning, deprecation lifecycle | PostgreSQL 16 + pgvector (storage), Ollama (embeddings), ToolRegistry library (protocol-agnostic interface) | Data Layer (PostgreSQL), Ollama (embedding generation) | Core |
| **Tool Executor** | Execute tools in nested sandboxes with resource limits, isolation, and timeout enforcement | Kubernetes Agent Sandbox CRD (gVisor for cloud, Firecracker for on-prem) | Agent Runtime Layer (parent sandbox context via BC-1) | Core |
| **Permission Checker** | Validate capability tokens, query OPA for policy decisions, cache permissions, handle invalidation | JWT (RS256), Open Policy Agent (OPA), Redis 7 (permission cache) | Data Layer (ABAC Engine), Redis (cache) | Core |
| **External Adapter Manager** | Manage external API connections, credential injection, rate limiting, retry logic | HashiCorp Vault (secrets), Redis 7 (rate limit counters), Tenacity (retry library) | HashiCorp Vault (credential storage), Redis (state) | Core |
| **Circuit Breaker Controller** | Prevent cascading failures via circuit breaker state machine, health checks, notifications | Resilience4j (circuit breaker library), Redis 7 (distributed state), Redis pub/sub (notifications) | Redis (state + pub/sub) | Core |
| **Result Validator** | Validate tool outputs against JSON Schema, type coercion, sanitization, error handling | AJV (JSON Schema validator), custom sanitization rules | Tool Registry (schema definitions) | Core |
| **Document Bridge (Phase 15)** | MCP client for document-consolidator, document query/cache/version pinning, permission checks | MCP Client (JSON-RPC 2.0), PM2 (process management), Redis 7 (document cache), Python asyncio (stdio pipes) | MCP Server (document-consolidator), Redis (cache), ABAC Engine (permissions) | Phase 15 |
| **State Bridge (Phase 16)** | MCP client for context-orchestrator, checkpoint creation/restoration, delta encoding, TTL management | MCP Client (JSON-RPC 2.0), PM2 (process management), Redis 7 (hot checkpoints), PostgreSQL 16 (cold checkpoints) | MCP Server (context-orchestrator), Redis (hot state), PostgreSQL (cold state) | Phase 16 |
| **Audit Logger** | Stream tool invocation events to Kafka in CloudEvents 1.0 format, PII redaction, tenant partitioning | Apache Kafka (event stream), CloudEvents SDK, custom PII sanitization rules | Kafka cluster (event ingestion) | Core |

**Dependency Graph:**
```
Tool Registry -----> PostgreSQL 16 (storage)
              \----> Ollama (embeddings)

Tool Executor -----> L02 Agent Runtime (BC-1 parent sandbox)
              \----> Kubernetes Sandbox CRD

Permission Checker -> Redis 7 (cache)
                   \-> OPA (policy engine)
                   \-> L01 Data Layer (ABAC Engine)

External Adapter ---> HashiCorp Vault (secrets)
                 \--> Redis 7 (rate limits)

Circuit Breaker ----> Redis 7 (state + pub/sub)

Result Validator ---> Tool Registry (schemas)

Document Bridge ----> document-consolidator (MCP)
                \---> Redis 7 (cache)
                \---> L01 Data Layer (ABAC Engine)

State Bridge -------> context-orchestrator (MCP)
             \------> Redis 7 (hot checkpoints)
             \------> PostgreSQL 16 (cold checkpoints)

Audit Logger -------> Kafka (event stream)
```

### 3.3 Component Specifications

#### 3.3.1 Tool Registry

**Purpose:**
Maintain a catalog of available tools with capability manifests, semantic descriptions, version history, and deprecation lifecycle. Support semantic search via pgvector embeddings for agent queries like "find a tool to parse CSV files". Handle multiple concurrent versions per tool with SemVer-based conflict resolution.

**Technology Choice & Rationale:**
- **PostgreSQL 16 + pgvector:** Relational storage for structured tool metadata with vector search for semantic queries. Single database reduces operational complexity compared to separate vector DB.
- **Ollama (Mistral 7B):** Generate embeddings for tool descriptions locally without API costs. Mistral 7B provides good quality embeddings (768-dim) at reasonable inference speed (~50ms per description).
- **ToolRegistry Library:** Protocol-agnostic abstraction layer supports tools from MCP servers, OpenAPI specs, LangChain definitions, and native Python functions.

**Configuration Schema (JSON Schema 2020-12):**
```json
{
  "$schema": "https://json-schema.org/draft/2020-12/schema",
  "type": "object",
  "properties": {
    "registry": {
      "type": "object",
      "properties": {
        "postgresql_connection_string": {
          "type": "string",
          "description": "PostgreSQL connection URL with pgvector extension enabled"
        },
        "ollama_base_url": {
          "type": "string",
          "default": "http://localhost:11434",
          "description": "Ollama API endpoint for embedding generation"
        },
        "embedding_model": {
          "type": "string",
          "default": "mistral:7b",
          "description": "Ollama model for tool description embeddings"
        },
        "embedding_dimensions": {
          "type": "integer",
          "default": 768,
          "description": "Vector dimensions (must match Ollama model output)"
        },
        "semantic_search_threshold": {
          "type": "number",
          "minimum": 0,
          "maximum": 1,
          "default": 0.7,
          "description": "Cosine similarity threshold for semantic search results"
        },
        "version_retention_policy": {
          "type": "object",
          "properties": {
            "max_versions_per_tool": {
              "type": "integer",
              "default": 5,
              "description": "Maximum concurrent versions to retain"
            },
            "deprecation_warning_days": {
              "type": "integer",
              "default": 90,
              "description": "Days to warn before removing deprecated version"
            }
          }
        }
      },
      "required": ["postgresql_connection_string"]
    }
  }
}
```

**Dependencies:**
- PostgreSQL 16 (Data Layer L01)
- Ollama service (local or remote)
- MCP servers (for tool discovery via Phase 15/16 bridges)

**Error Codes (E3000-E3099):**
- `E3001`: Tool not found (tool_id does not exist in registry)
- `E3002`: Tool version not found (tool_version does not exist for tool_id)
- `E3003`: Tool deprecated (version in sunset phase, warnings issued)
- `E3004`: Tool removed (version deleted, no longer available)
- `E3005`: Semantic search failed (Ollama embedding generation error)
- `E3006`: Version conflict (requested version range has no compatible versions)
- `E3007`: Duplicate tool registration (tool_id already exists with same version)
- `E3008`: Invalid tool manifest (schema validation failed)

**Gap Integration:**
- **G-001 (High):** Tool capability manifest schema fully defined in Section 5.1.1 with all fields (permissions, result_schema, timeout, retry policy, circuit breaker config).
- **G-002 (Medium):** Semantic versioning conflict resolution implemented via `max_versions_per_tool` retention policy and agent-specified version ranges (e.g., "^2.1.0").
- **G-003 (Medium):** Tool deprecation workflow defined with lifecycle states (active, deprecated, sunset, removed) and `deprecation_warning_days` configuration.

---

#### 3.3.2 Tool Executor

**Purpose:**
Execute tools within isolated sandboxes nested inside agent sandboxes (BC-1). Inherit resource limits (CPU, memory, timeout) from agent context and sub-allocate to tools. Enforce filesystem restrictions (subset of agent mounts) and network policies (subset of agent allowed hosts). Support both gVisor (cloud) and Firecracker (on-prem) isolation technologies.

**Technology Choice & Rationale:**
- **Kubernetes Agent Sandbox CRD:** Industry standard for agent workload isolation (Google, Kubernetes SIG Apps). Provides Sandbox, SandboxTemplate, and SandboxClaim resources for declarative sandbox management.
- **gVisor (cloud):** Intercepts syscalls in user-space Go program. No KVM required, works in standard Kubernetes (GKE, EKS, AKS). Adequate isolation for most tools. Anthropic-validated in production (Claude web). Recommended for cloud deployments.
- **Firecracker (on-prem):** Boots real microVMs in ~125ms with ~5MB overhead. Hardware-level isolation via KVM. Stronger security for high-risk tools (arbitrary code execution, untrusted plugins). Vercel-validated in production. Recommended for on-prem/bare-metal deployments.

**Configuration Schema:**
```json
{
  "$schema": "https://json-schema.org/draft/2020-12/schema",
  "type": "object",
  "properties": {
    "executor": {
      "type": "object",
      "properties": {
        "isolation_technology": {
          "type": "string",
          "enum": ["gvisor", "firecracker"],
          "default": "gvisor",
          "description": "Sandbox isolation technology (gvisor for cloud, firecracker for on-prem)"
        },
        "default_resource_limits": {
          "type": "object",
          "properties": {
            "cpu_millicore_limit": {
              "type": "integer",
              "default": 500,
              "description": "Default CPU limit per tool (millicores)"
            },
            "memory_mb_limit": {
              "type": "integer",
              "default": 1024,
              "description": "Default memory limit per tool (MB)"
            },
            "timeout_seconds": {
              "type": "integer",
              "default": 30,
              "description": "Default execution timeout per tool (seconds)"
            }
          }
        },
        "concurrent_tools_per_agent": {
          "type": "integer",
          "default": 4,
          "description": "Maximum concurrent tool executions per agent"
        },
        "sandbox_warm_pool": {
          "type": "object",
          "properties": {
            "enabled": {
              "type": "boolean",
              "default": false,
              "description": "Pre-warm sandboxes for reduced cold start latency"
            },
            "pool_size": {
              "type": "integer",
              "default": 10,
              "description": "Number of pre-warmed sandboxes per agent"
            }
          }
        }
      }
    }
  }
}
```

**Dependencies:**
- Agent Runtime Layer L02 (parent sandbox context via BC-1)
- Kubernetes cluster with Agent Sandbox CRD installed
- gVisor runtime or Firecracker/KVM for VM isolation

**Error Codes (E3100-E3199):**
- `E3101`: Sandbox creation failed (Kubernetes API error, resource exhaustion)
- `E3102`: Resource limit exceeded (tool requested more CPU/memory than agent allows)
- `E3103`: Timeout exceeded (tool execution exceeded timeout limit, process killed)
- `E3104`: Network policy violation (tool attempted connection to disallowed host)
- `E3105`: Filesystem policy violation (tool attempted access outside allowed paths)
- `E3106`: Concurrent tool limit exceeded (agent already running max concurrent tools)
- `E3107`: Sandbox crashed (microVM or gVisor process terminated unexpectedly)
- `E3108`: Tool process exit non-zero (tool binary returned error exit code)

**Gap Integration:**
- **G-004 (High):** Async execution patterns for long-running tools (> 15 min) supported via `async_mode` parameter in `tool.invoke()` request (Section 4.1).
- **G-005 (Medium):** Tool execution priority scheduling implemented via `priority` field in `execution_options` (Section 4.1).

---

#### 3.3.3 Permission Checker

**Purpose:**
Validate capability tokens (JWT with RS256 signatures) for tool invocation authorization. Query Open Policy Agent (OPA) for policy-based access control decisions (filesystem, network, credentials). Enforce least-privilege principle: tools only access explicitly allowed resources. Cache permissions in Redis with pub/sub invalidation on policy updates.

**Technology Choice & Rationale:**
- **JWT (RS256):** Industry-standard token format for capability-based authorization. RS256 (RSA signatures) enables distributed validation without shared secrets (only public key needed). Token structure: `{tool_id, allowed_operations, expiration, agent_did, signature}`.
- **Open Policy Agent (OPA):** Policy engine for attribute-based access control (ABAC). Policies written in Rego language, evaluated locally without network calls. Integrates with Data Layer's ABAC Engine for centralized policy management.
- **Redis 7 (permission cache):** Cache OPA decisions for repeated invocations (same tool + agent + resources). TTL 5 minutes. Invalidate via Redis pub/sub on policy updates from Data Layer.

**Configuration Schema:**
```json
{
  "$schema": "https://json-schema.org/draft/2020-12/schema",
  "type": "object",
  "properties": {
    "permission_checker": {
      "type": "object",
      "properties": {
        "jwt_public_key_path": {
          "type": "string",
          "description": "Path to RSA public key (PEM format) for JWT signature verification"
        },
        "jwt_algorithm": {
          "type": "string",
          "default": "RS256",
          "description": "JWT signature algorithm (RS256 recommended)"
        },
        "opa_endpoint": {
          "type": "string",
          "default": "http://localhost:8181/v1/data/tool_execution/allow",
          "description": "OPA REST API endpoint for policy evaluation"
        },
        "permission_cache": {
          "type": "object",
          "properties": {
            "enabled": {
              "type": "boolean",
              "default": true
            },
            "redis_connection_string": {
              "type": "string"
            },
            "ttl_seconds": {
              "type": "integer",
              "default": 300,
              "description": "Cache TTL (5 minutes default)"
            },
            "invalidation_channel": {
              "type": "string",
              "default": "policy:updates",
              "description": "Redis pub/sub channel for cache invalidation"
            }
          }
        }
      },
      "required": ["jwt_public_key_path"]
    }
  }
}
```

**Dependencies:**
- Data Layer L01 (ABAC Engine for policy definitions, Redis for cache)
- Open Policy Agent (OPA) service
- JWT signing service (issues capability tokens)

**Error Codes (E3200-E3299):**
- `E3201`: Invalid capability token (JWT signature verification failed)
- `E3202`: Expired capability token (token expiration timestamp < current time)
- `E3203`: Permission denied - filesystem (OPA denied access to requested filesystem paths)
- `E3204`: Permission denied - network (OPA denied access to requested network hosts)
- `E3205`: Permission denied - credentials (OPA denied access to requested credentials)
- `E3206`: OPA query failed (OPA service unreachable or returned error)
- `E3207`: Missing required claims (JWT missing tool_id, agent_did, or expiration)
- `E3208`: Token revoked (token in revocation list, stored in Redis)

**Gap Integration:**
- **G-006 (Critical):** Capability token format fully specified in Section 4.1.1 with JWT structure (claims, signature algorithm, expiration).
- **G-007 (High):** Permission cache invalidation on policy updates implemented via Redis pub/sub subscription to `policy:updates` channel.

---

#### 3.3.4 External Adapter Manager

**Purpose:**
Manage connections to external services (APIs, databases, file systems). Handle authentication via runtime secret injection from HashiCorp Vault (ephemeral credentials with lifespan = tool timeout). Enforce rate limits per tool/API using token bucket algorithm with Redis counters. Implement retry logic with exponential backoff and full jitter using Tenacity library.

**Technology Choice & Rationale:**
- **HashiCorp Vault:** Industry-standard secrets management with dynamic secrets (ephemeral credentials), automatic rotation, audit trail, and FIPS 140-2 compliance. Integrates with AWS IAM, GCP Service Accounts, Azure AD for cloud provider credentials.
- **Redis 7 (rate limit counters):** Token bucket algorithm state stored in Redis with atomic increment/decrement operations. Distributed rate limiting across multiple L03 instances.
- **Tenacity (Python):** Retry library with exponential backoff, full jitter, and configurable stop conditions. 97% success rate on flakes in 2025 benchmarks, 3.5x better than baseline implementations.

**Configuration Schema:**
```json
{
  "$schema": "https://json-schema.org/draft/2020-12/schema",
  "type": "object",
  "properties": {
    "external_adapter": {
      "type": "object",
      "properties": {
        "vault": {
          "type": "object",
          "properties": {
            "address": {
              "type": "string",
              "description": "HashiCorp Vault server address"
            },
            "auth_method": {
              "type": "string",
              "enum": ["token", "kubernetes", "aws-iam", "gcp-iam", "azure"],
              "description": "Vault authentication method"
            },
            "secret_path_prefix": {
              "type": "string",
              "default": "secret/tool-execution",
              "description": "Vault path prefix for tool credentials"
            }
          },
          "required": ["address", "auth_method"]
        },
        "rate_limiting": {
          "type": "object",
          "properties": {
            "algorithm": {
              "type": "string",
              "enum": ["token_bucket", "leaky_bucket", "fixed_window", "sliding_window"],
              "default": "token_bucket",
              "description": "Rate limiting algorithm"
            },
            "redis_connection_string": {
              "type": "string"
            },
            "default_requests_per_minute": {
              "type": "integer",
              "default": 60
            },
            "burst_size": {
              "type": "integer",
              "default": 10,
              "description": "Burst tolerance above rate limit"
            }
          }
        },
        "retry": {
          "type": "object",
          "properties": {
            "max_attempts": {
              "type": "integer",
              "default": 3
            },
            "base_delay_ms": {
              "type": "integer",
              "default": 1000,
              "description": "Initial backoff delay (milliseconds)"
            },
            "max_delay_ms": {
              "type": "integer",
              "default": 60000,
              "description": "Maximum backoff delay (milliseconds)"
            },
            "jitter": {
              "type": "string",
              "enum": ["none", "full", "equal", "decorrelated"],
              "default": "full",
              "description": "Jitter strategy (full recommended to prevent thundering herd)"
            },
            "retryable_status_codes": {
              "type": "array",
              "items": {"type": "integer"},
              "default": [429, 500, 502, 503, 504],
              "description": "HTTP status codes to retry"
            }
          }
        }
      }
    }
  }
}
```

**Dependencies:**
- HashiCorp Vault (credential storage)
- Redis 7 (rate limit counters)
- External APIs/services (HTTP clients, database drivers, file system access)

**Error Codes (E3300-E3399):**
- `E3301`: Vault connection failed (unable to reach Vault server)
- `E3302`: Credential retrieval failed (secret not found in Vault)
- `E3303`: Rate limit exceeded (tool exhausted API quota, 429 response)
- `E3304`: External API error (5xx response from external service)
- `E3305`: Max retries exhausted (all retry attempts failed)
- `E3306`: Connection timeout (external service did not respond within timeout)
- `E3307`: Authentication failed (401/403 from external service, credential invalid)
- `E3308`: Invalid response format (external service returned malformed response)

**Gap Integration:**
- None directly addressed in this component (gaps related to circuit breaker handled in next component).

---

#### 3.3.5 Circuit Breaker Controller

**Purpose:**
Prevent cascading failures via three-state circuit breaker state machine (closed, open, half-open). Monitor external API health and trigger state transitions based on failure rates or consecutive failure counts. Send notifications to dependent tools on state changes via Redis pub/sub. Store distributed circuit breaker state in Redis for coordination across multiple L03 instances.

**Technology Choice & Rationale:**
- **Resilience4j:** Industry-standard circuit breaker library for Java/JVM languages. Hystrix (Netflix) is in maintenance mode; Resilience4j is the recommended alternative. Configurable state machine with sliding window failure tracking.
- **Redis 7 (circuit state + pub/sub):** Distributed state storage for circuit breaker status (open/closed, failure count, timestamps). Pub/sub for real-time notifications to subscribed tools. Atomic operations for state transitions.

**Configuration Schema:**
```json
{
  "$schema": "https://json-schema.org/draft/2020-12/schema",
  "type": "object",
  "properties": {
    "circuit_breaker": {
      "type": "object",
      "properties": {
        "redis_connection_string": {
          "type": "string"
        },
        "notification_channel": {
          "type": "string",
          "default": "circuit:state:changes",
          "description": "Redis pub/sub channel for circuit breaker notifications"
        },
        "default_config": {
          "type": "object",
          "properties": {
            "failure_rate_threshold": {
              "type": "number",
              "minimum": 0,
              "maximum": 100,
              "default": 50,
              "description": "Failure rate percentage to trigger open state"
            },
            "slow_call_rate_threshold": {
              "type": "number",
              "minimum": 0,
              "maximum": 100,
              "default": 100,
              "description": "Slow call rate percentage to trigger open state"
            },
            "slow_call_duration_threshold_ms": {
              "type": "integer",
              "default": 5000,
              "description": "Call duration to consider slow (milliseconds)"
            },
            "sliding_window_type": {
              "type": "string",
              "enum": ["count_based", "time_based"],
              "default": "count_based"
            },
            "sliding_window_size": {
              "type": "integer",
              "default": 100,
              "description": "Number of calls (count_based) or seconds (time_based) in window"
            },
            "minimum_number_of_calls": {
              "type": "integer",
              "default": 10,
              "description": "Minimum calls before calculating failure rate"
            },
            "wait_duration_in_open_state_seconds": {
              "type": "integer",
              "default": 60,
              "description": "Duration to wait before transitioning to half-open"
            },
            "permitted_number_of_calls_in_half_open_state": {
              "type": "integer",
              "default": 10,
              "description": "Test calls in half-open state before closing"
            }
          }
        },
        "half_open_strategy": {
          "type": "string",
          "enum": ["canary", "all_or_nothing"],
          "default": "canary",
          "description": "Canary: gradually increase traffic; All-or-nothing: send all or none"
        }
      },
      "required": ["redis_connection_string"]
    }
  }
}
```

**Dependencies:**
- Redis 7 (state storage + pub/sub)
- External Adapter Manager (for external API call metrics)

**Error Codes (E3400-E3499):**
- `E3401`: Circuit breaker open (too many failures, requests blocked)
- `E3402`: Circuit breaker state transition failed (Redis update error)
- `E3403`: Invalid circuit configuration (threshold > 100, window size < 1)
- `E3404`: Circuit health check failed (unable to probe endpoint)
- `E3405`: Half-open test failed (test calls in half-open state still failing)

**Gap Integration:**
- **G-008 (Medium):** Circuit breaker transition notifications implemented via Redis pub/sub on `circuit:state:changes` channel. Dependent tools subscribe and adjust behavior (e.g., skip fallback API if also open).
- **G-009 (Medium):** Half-open state testing strategy configurable via `half_open_strategy` parameter (canary vs all-or-nothing). Canary gradually increases traffic percentage if successful.

---

#### 3.3.6 Result Validator

**Purpose:**
Validate tool outputs against JSON Schema defined in tool manifest. Perform type coercion (e.g., string -> number, ISO 8601 -> Date) and sanitization (SQL injection, XSS, command injection patterns). Enforce structured output contracts for tools with schema definitions. Return validation errors to agent with specific field-level feedback.

**Technology Choice & Rationale:**
- **AJV (Another JSON Schema Validator):** Fastest JSON Schema validator for JavaScript/TypeScript. Supports JSON Schema 2020-12, custom keywords, and async validation. Used by major projects (Webpack, ESLint, VS Code).
- **Custom Sanitization Rules:** Regex patterns and field-based sanitization for security threats. Redact patterns for SQL injection (`'; DROP TABLE`, `1' OR '1'='1`), XSS (`<script>`, `javascript:`), command injection (``; rm -rf`, `| cat /etc/passwd`).

**Configuration Schema:**
```json
{
  "$schema": "https://json-schema.org/draft/2020-12/schema",
  "type": "object",
  "properties": {
    "result_validator": {
      "type": "object",
      "properties": {
        "strict_mode": {
          "type": "boolean",
          "default": true,
          "description": "Reject outputs that fail schema validation (false: log warning and allow)"
        },
        "type_coercion": {
          "type": "object",
          "properties": {
            "enabled": {
              "type": "boolean",
              "default": true
            },
            "rules": {
              "type": "array",
              "items": {
                "type": "object",
                "properties": {
                  "from_type": {"type": "string"},
                  "to_type": {"type": "string"},
                  "coercion_function": {"type": "string"}
                }
              },
              "default": [
                {"from_type": "string", "to_type": "number", "coercion_function": "parseFloat"},
                {"from_type": "string", "to_type": "integer", "coercion_function": "parseInt"},
                {"from_type": "string", "to_type": "boolean", "coercion_function": "Boolean"},
                {"from_type": "string", "to_type": "date", "coercion_function": "new Date"}
              ]
            }
          }
        },
        "sanitization": {
          "type": "object",
          "properties": {
            "enabled": {
              "type": "boolean",
              "default": true
            },
            "patterns": {
              "type": "array",
              "items": {
                "type": "object",
                "properties": {
                  "threat_type": {"type": "string"},
                  "regex_pattern": {"type": "string"},
                  "action": {"type": "string", "enum": ["reject", "redact", "escape"]}
                }
              },
              "default": [
                {"threat_type": "sql_injection", "regex_pattern": "('|(\\-\\-)|(;)|(\\|\\|)|(\\*))", "action": "reject"},
                {"threat_type": "xss", "regex_pattern": "(<script|javascript:|onerror=)", "action": "escape"},
                {"threat_type": "command_injection", "regex_pattern": "(;|\\||`|\\$\\()", "action": "reject"}
              ]
            }
          }
        }
      }
    }
  }
}
```

**Dependencies:**
- Tool Registry (for schema definitions from tool manifests)
- AJV library (JSON Schema validation)

**Error Codes (E3500-E3599):**
- `E3501`: Schema validation failed (output does not match tool manifest schema)
- `E3502`: Type coercion failed (unable to coerce value to expected type)
- `E3503`: Sanitization rejected (output contains SQL injection pattern)
- `E3504`: Sanitization rejected (output contains XSS pattern)
- `E3505`: Sanitization rejected (output contains command injection pattern)
- `E3506`: Missing required field (output missing required schema field)
- `E3507`: Invalid field type (output field type does not match schema)
- `E3508`: Schema not found (tool manifest does not define result_schema)

**Gap Integration:**
- **G-010 (Critical):** Result validation schema definition enforced via AJV validator with JSON Schema 2020-12 from tool manifest `result_schema` field.
- **G-011 (High):** Type coercion rules defined in `type_coercion.rules` configuration with support for string -> number/integer/boolean/date conversions.
- **G-012 (High):** Structured output validation implemented via `strict_mode` flag. When enabled, tools must return outputs matching `result_schema` or invocation fails with `E3501`.

---

#### 3.3.7 Document Bridge (Phase 15)

**Purpose:**
MCP client for document-consolidator service. Provides tools with access to authoritative documents via `get_source_of_truth`, `search_documents`, `find_overlaps`, and `get_document_metadata`. Cache frequently accessed documents in Redis (5-min TTL) with pub/sub invalidation on writes. Query ABAC engine for document access permissions. Support version pinning for long-running tools.

**Technology Choice & Rationale:**
- **MCP Client (JSON-RPC 2.0):** Implements MCP specification 2025-11-25 for tool discovery, resource access, and capability negotiation. Communicates with document-consolidator MCP server via stdin/stdout pipes (ADR-001).
- **PM2 (process management):** Manages document-consolidator MCP server lifecycle (auto-restart on crash, log rotation, clustering for HA).
- **Redis 7 (document cache):** Two-tier caching: (1) Hot: `get_source_of_truth` results cached with 5-min TTL, (2) Warm: Immutable document versions cached locally until process restart. Cache invalidation via Redis pub/sub on `document:updates` channel.
- **Python asyncio (stdio pipes):** Non-blocking I/O for stdin/stdout communication with MCP server process.

**Configuration Schema:**
```json
{
  "$schema": "https://json-schema.org/draft/2020-12/schema",
  "type": "object",
  "properties": {
    "document_bridge": {
      "type": "object",
      "properties": {
        "mcp_server": {
          "type": "object",
          "properties": {
            "pm2_process_name": {
              "type": "string",
              "default": "doc-bridge-mcp",
              "description": "PM2 process name for document-consolidator MCP server"
            },
            "startup_timeout_ms": {
              "type": "integer",
              "default": 5000,
              "description": "Timeout for MCP server startup and capability negotiation"
            },
            "request_timeout_ms": {
              "type": "integer",
              "default": 30000,
              "description": "Timeout for individual MCP requests"
            },
            "max_retries": {
              "type": "integer",
              "default": 3,
              "description": "Max retries for failed MCP requests"
            }
          }
        },
        "cache": {
          "type": "object",
          "properties": {
            "enabled": {
              "type": "boolean",
              "default": true
            },
            "redis_connection_string": {
              "type": "string"
            },
            "hot_cache_ttl_seconds": {
              "type": "integer",
              "default": 300,
              "description": "TTL for get_source_of_truth results (5 minutes)"
            },
            "metadata_cache_ttl_seconds": {
              "type": "integer",
              "default": 600,
              "description": "TTL for document metadata (10 minutes)"
            },
            "invalidation_channel": {
              "type": "string",
              "default": "document:updates",
              "description": "Redis pub/sub channel for cache invalidation"
            }
          }
        },
        "version_pinning": {
          "type": "object",
          "properties": {
            "enabled": {
              "type": "boolean",
              "default": true,
              "description": "Support version pinning for long-running tools"
            },
            "pin_storage": {
              "type": "string",
              "enum": ["checkpoint", "redis", "local"],
              "default": "checkpoint",
              "description": "Where to store version pins (checkpoint: Phase 16 integration)"
            }
          }
        },
        "permissions": {
          "type": "object",
          "properties": {
            "check_enabled": {
              "type": "boolean",
              "default": true,
              "description": "Query ABAC engine for document access permissions"
            },
            "abac_endpoint": {
              "type": "string",
              "description": "Data Layer ABAC Engine endpoint for permission checks"
            }
          }
        }
      },
      "required": ["mcp_server"]
    }
  }
}
```

**Dependencies:**
- document-consolidator MCP server (Phase 15)
- PM2 (process management)
- Redis 7 (cache + pub/sub)
- Data Layer L01 (ABAC Engine for document permissions)

**Error Codes (E3600-E3699):**
- `E3601`: Document not found (document_id does not exist in consolidator)
- `E3602`: Document unavailable (MCP server down, all retries failed, no cache)
- `E3603`: Document permission denied (ABAC check failed for agent)
- `E3604`: Document version conflict (requested version deprecated/removed)
- `E3605`: MCP server timeout (no response within request_timeout_ms)
- `E3606`: MCP protocol error (invalid JSON-RPC response from server)
- `E3607`: Cache unavailable (Redis connection failed, MCP fallback used)
- `E3608`: Version pinning failed (unable to store pinned versions)

**Gap Integration:**
- **G-013 (High):** Document access permission model implemented via ABAC integration. Before MCP document retrieval, query Data Layer ABAC Engine with `(agent_did, document_id, access_mode)` tuple.
- **G-014 (Medium):** Bulk document retrieval optimization implemented via batched MCP requests. Send array of document_ids in single `tools/call` request, reduce round-trips, cache batch results.

---

#### 3.3.8 State Bridge (Phase 16)

**Purpose:**
MCP client for context-orchestrator service. Enables hybrid checkpointing: micro-checkpoints (Redis, 30s intervals), macro-checkpoints (PostgreSQL, event milestones), named checkpoints (manual recovery points). Supports resume from checkpoint after timeout, crash, or cancellation. Stores checkpoint diffs for large states using delta encoding. Implements TTL management for hot checkpoints (Redis) and retention policies for cold checkpoints (PostgreSQL).

**Technology Choice & Rationale:**
- **MCP Client (JSON-RPC 2.0):** Implements MCP specification 2025-11-25 for checkpoint operations (`save_context_snapshot`, `create_checkpoint`, `rollback_to`, `get_unified_context`).
- **Redis 7 (hot checkpoints):** LangGraph Redis Checkpoint 0.1.0 pattern with inline JSON storage for single-operation retrieval. TTL 1 hour for micro-checkpoints. Automatic expiration via Redis TTL with `refresh_on_read`.
- **PostgreSQL 16 (cold checkpoints):** Durable storage for macro-checkpoints and named checkpoints. Delta encoding: store only changed state since parent checkpoint. Retention 90 days hot, 7 years cold (archived to S3 Glacier).

**Configuration Schema:**
```json
{
  "$schema": "https://json-schema.org/draft/2020-12/schema",
  "type": "object",
  "properties": {
    "state_bridge": {
      "type": "object",
      "properties": {
        "mcp_server": {
          "type": "object",
          "properties": {
            "pm2_process_name": {
              "type": "string",
              "default": "state-bridge-mcp",
              "description": "PM2 process name for context-orchestrator MCP server"
            },
            "startup_timeout_ms": {
              "type": "integer",
              "default": 5000
            },
            "request_timeout_ms": {
              "type": "integer",
              "default": 10000,
              "description": "Checkpoint operations are fast, 10s timeout sufficient"
            }
          }
        },
        "checkpointing": {
          "type": "object",
          "properties": {
            "micro_checkpoints": {
              "type": "object",
              "properties": {
                "enabled": {
                  "type": "boolean",
                  "default": true
                },
                "interval_seconds": {
                  "type": "integer",
                  "default": 30,
                  "description": "Frequency of micro-checkpoints for long-running tools"
                },
                "storage": {
                  "type": "string",
                  "enum": ["redis"],
                  "default": "redis"
                },
                "ttl_seconds": {
                  "type": "integer",
                  "default": 3600,
                  "description": "TTL for micro-checkpoints (1 hour)"
                }
              }
            },
            "macro_checkpoints": {
              "type": "object",
              "properties": {
                "enabled": {
                  "type": "boolean",
                  "default": true
                },
                "storage": {
                  "type": "string",
                  "enum": ["postgresql"],
                  "default": "postgresql"
                },
                "retention_days": {
                  "type": "integer",
                  "default": 90,
                  "description": "Hot retention in PostgreSQL (90 days)"
                },
                "archive_storage": {
                  "type": "string",
                  "default": "s3",
                  "description": "Cold storage for archived checkpoints (S3 Glacier)"
                },
                "archive_retention_years": {
                  "type": "integer",
                  "default": 7,
                  "description": "Compliance retention in cold storage"
                }
              }
            },
            "named_checkpoints": {
              "type": "object",
              "properties": {
                "enabled": {
                  "type": "boolean",
                  "default": true
                },
                "storage": {
                  "type": "string",
                  "enum": ["postgresql"],
                  "default": "postgresql"
                },
                "retention": {
                  "type": "string",
                  "enum": ["indefinite", "days", "manual"],
                  "default": "indefinite",
                  "description": "Named checkpoints retained indefinitely unless explicitly deleted"
                }
              }
            }
          }
        },
        "delta_encoding": {
          "type": "object",
          "properties": {
            "enabled": {
              "type": "boolean",
              "default": true,
              "description": "Store only state changes since parent checkpoint"
            },
            "threshold_kb": {
              "type": "integer",
              "default": 100,
              "description": "Use delta encoding if checkpoint > 100 KB"
            }
          }
        },
        "compression": {
          "type": "object",
          "properties": {
            "enabled": {
              "type": "boolean",
              "default": true
            },
            "algorithm": {
              "type": "string",
              "enum": ["gzip", "zstd"],
              "default": "gzip"
            },
            "threshold_kb": {
              "type": "integer",
              "default": 10,
              "description": "Compress if checkpoint > 10 KB"
            }
          }
        }
      }
    }
  }
}
```

**Dependencies:**
- context-orchestrator MCP server (Phase 16)
- PM2 (process management)
- Redis 7 (hot checkpoints)
- PostgreSQL 16 (cold checkpoints)
- S3 or compatible object storage (cold archive)

**Error Codes (E3700-E3799):**
- `E3701`: Checkpoint creation failed (MCP server error, Redis/PostgreSQL write failed)
- `E3702`: Checkpoint not found (checkpoint_id does not exist)
- `E3703`: Checkpoint restoration failed (corrupted checkpoint data, deserialization error)
- `E3704`: State conflict detected (concurrent tool executions modified same state)
- `E3705`: Delta encoding failed (unable to compute diff from parent checkpoint)
- `E3706`: Compression failed (gzip/zstd compression error)
- `E3707`: TTL expired (micro-checkpoint deleted, unable to resume)
- `E3708`: Archive retrieval failed (S3 Glacier restore in progress, ETA hours)

**Gap Integration:**
- **G-015 (Medium):** Checkpoint diff/delta encoding implemented via `delta_encoding.enabled` flag. When enabled and checkpoint > 100 KB, store only changed state fields with `parent_checkpoint_id` reference.
- **G-016 (Low):** Checkpoint compression threshold tuning via `compression.threshold_kb` parameter. Auto-tune by measuring checkpoint size distribution, compress if > 10 KB (gzip recommended, benchmarked vs zstd).

---

## Section 4: Interfaces

### 4.1 Provided Interfaces

#### 4.1.1 tool.invoke() - Primary Tool Execution Interface (BC-2)

**Interface Type:** Synchronous/Asynchronous REST API (JSON over HTTP) or gRPC (protobuf)

**Purpose:** Primary interface for L11 (Integration Layer) to invoke tools on behalf of agents. Supports synchronous execution for short-running tools (< 30s) and asynchronous execution for long-running tools (> 30s) with polling.

**Python Protocol Definition:**

```python
from typing import Protocol, Optional, Dict, List, Any, Literal
from dataclasses import dataclass
from datetime import datetime
from enum import Enum

# ========== Enums ==========

class ToolInvocationStatus(str, Enum):
    PENDING = "pending"
    RUNNING = "running"
    SUCCESS = "success"
    ERROR = "error"
    TIMEOUT = "timeout"
    CANCELLED = "cancelled"
    PERMISSION_DENIED = "permission_denied"
    PENDING_APPROVAL = "pending_approval"

class ToolErrorCode(str, Enum):
    # Client errors
    INVALID_PARAMETERS = "invalid_parameters"
    TOOL_NOT_FOUND = "tool_not_found"
    TOOL_VERSION_NOT_FOUND = "tool_version_not_found"
    PERMISSION_DENIED = "permission_denied"
    RATE_LIMIT_EXCEEDED = "rate_limit_exceeded"
    IDEMPOTENCY_CONFLICT = "idempotency_conflict"

    # Server errors
    TOOL_EXECUTION_ERROR = "tool_execution_error"
    SANDBOX_FAILURE = "sandbox_failure"
    EXTERNAL_API_ERROR = "external_api_error"
    CIRCUIT_BREAKER_OPEN = "circuit_breaker_open"
    TIMEOUT = "timeout"
    RESOURCE_EXHAUSTED = "resource_exhausted"

    # Phase 15 errors
    DOCUMENT_NOT_FOUND = "document_not_found"
    DOCUMENT_UNAVAILABLE = "document_unavailable"
    DOCUMENT_VERSION_CONFLICT = "document_version_conflict"

    # Phase 16 errors
    CHECKPOINT_FAILED = "checkpoint_failed"
    RESUME_FAILED = "resume_failed"
    STATE_CONFLICT = "state_conflict"

    # Generic
    INTERNAL_ERROR = "internal_error"

# ========== Request Data Classes ==========

@dataclass
class AgentContext:
    """Agent identity and session context from L02 (BC-1)."""
    agent_did: str  # Decentralized Identifier for agent
    tenant_id: str  # Multi-tenancy isolation
    user_did: Optional[str] = None  # End user (if applicable)
    session_id: str = ""  # Session for context tracking

@dataclass
class ResourceLimits:
    """Resource limits inherited from agent and sub-allocated to tool."""
    cpu_millicore_limit: Optional[int] = None
    memory_mb_limit: Optional[int] = None
    timeout_seconds: Optional[int] = None
    network_bandwidth_mbps: Optional[int] = None

@dataclass
class DocumentContext:
    """Phase 15 - Document context for tool execution."""
    document_refs: Optional[List[str]] = None  # URIs (e.g., "doc://spec-v1.0")
    version_pinning: bool = False  # Pin document versions for consistency
    query: Optional[str] = None  # Semantic search query

@dataclass
class CheckpointConfig:
    """Phase 16 - Checkpoint configuration for resumable operations."""
    enable_checkpointing: bool = True
    checkpoint_interval_seconds: int = 30
    resume_from_checkpoint_id: Optional[str] = None

@dataclass
class ExecutionOptions:
    """Execution behavior options."""
    async_mode: bool = False  # Synchronous by default
    priority: Literal["low", "normal", "high"] = "normal"
    idempotency_key: Optional[str] = None  # Prevent duplicate invocations
    require_approval: bool = False  # Human-in-the-loop approval

@dataclass
class ToolInvokeRequest:
    """Request to invoke a tool on behalf of an agent."""
    # Core tool identification
    tool_id: str
    tool_version: str  # Semantic version (e.g., "1.2.0")
    invocation_id: str  # Unique invocation ID (UUID)

    # Agent context (from L02 via BC-1)
    agent_context: AgentContext

    # Tool parameters (validated against tool manifest schema)
    parameters: Dict[str, Any]

    # Optional overrides and configurations
    resource_limits: Optional[ResourceLimits] = None
    document_context: Optional[DocumentContext] = None
    checkpoint_config: Optional[CheckpointConfig] = None
    execution_options: Optional[ExecutionOptions] = None

    # **NEW: Capability Token (Gap G-006)**
    capability_token: str  # JWT (RS256) with tool permissions

# ========== Response Data Classes ==========

@dataclass
class ToolError:
    """Structured error information."""
    code: ToolErrorCode
    message: str
    details: Optional[Dict[str, Any]] = None
    retryable: bool = False

@dataclass
class DocumentAccess:
    """Phase 15 - Document access metadata."""
    document_id: str
    document_version: str
    access_count: int

@dataclass
class CheckpointMetadata:
    """Phase 16 - Checkpoint metadata."""
    checkpoint_id: str
    checkpoint_type: Literal["micro", "macro", "named"]
    timestamp: str  # ISO 8601

@dataclass
class ExecutionMetadata:
    """Execution metrics and resource usage."""
    duration_ms: int
    started_at: str  # ISO 8601
    completed_at: Optional[str] = None  # ISO 8601

    # Resource usage
    cpu_used_millicore_seconds: int = 0
    memory_peak_mb: int = 0
    network_bytes_sent: int = 0
    network_bytes_received: int = 0

    # Phase 15 - Document access
    documents_accessed: Optional[List[DocumentAccess]] = None

    # Phase 16 - Checkpoints created
    checkpoints_created: Optional[List[CheckpointMetadata]] = None

@dataclass
class PollingInfo:
    """Async mode polling information."""
    status_url: str  # URL to poll for status
    estimated_completion_seconds: Optional[int] = None

@dataclass
class ToolInvokeResponse:
    """Response from tool invocation."""
    invocation_id: str
    status: ToolInvocationStatus

    # Success response
    result: Optional[Any] = None  # Tool-specific result (validated)

    # Error response
    error: Optional[ToolError] = None

    # Execution metadata
    execution_metadata: ExecutionMetadata = None

    # Phase 16 - Checkpoint reference (for async/long-running)
    checkpoint_ref: Optional[str] = None

    # Async mode tracking
    polling_info: Optional[PollingInfo] = None

# ========== Protocol ==========

class ToolExecutionService(Protocol):
    """Tool Execution Layer service interface (BC-2)."""

    def invoke(self, request: ToolInvokeRequest) -> ToolInvokeResponse:
        """
        Invoke a tool on behalf of an agent.

        Args:
            request: Tool invocation request with parameters and context.

        Returns:
            Tool invocation response with result or error.

        Raises:
            PermissionDenied: If capability token invalid or ABAC check fails.
            ToolNotFound: If tool_id or tool_version does not exist.
            RateLimitExceeded: If tool exhausted API quota.
            CircuitBreakerOpen: If external API circuit breaker is open.
            Timeout: If tool execution exceeds timeout limit.
        """
        ...
```

**Capability Token Format (Gap G-006):**

JWT (RS256) structure for capability-based authorization:
```json
{
  "header": {
    "alg": "RS256",
    "typ": "JWT"
  },
  "payload": {
    "tool_id": "analyze_code",
    "tool_version": "^2.0.0",
    "agent_did": "did:agent:xyz789",
    "tenant_id": "tenant_acme",
    "allowed_operations": ["execute"],
    "filesystem_permissions": {
      "allowed_paths": ["/workspace/tool1"],
      "mode": "rw"
    },
    "network_permissions": {
      "allowed_hosts": ["api.example.com"],
      "allowed_ports": [443]
    },
    "credential_permissions": {
      "allowed_secrets": ["aws_s3_read", "external_api_token"]
    },
    "exp": 1673980800,
    "iat": 1673977200,
    "iss": "l02-agent-runtime"
  },
  "signature": "..."
}
```

**Gap Integration:**
- **G-006 (Critical):** Capability token format fully specified as JWT (RS256) with claims for tool permissions, expiration, agent identity.
- **G-020 (High):** Multi-tool workflow orchestration supported via L11 calling `tool.invoke()` sequentially or in parallel based on workflow DAG.

---

#### 4.1.2 tool.list() - Tool Discovery Interface

**Purpose:** Query available tools with filtering and semantic search.

**Python Protocol Definition:**
```python
@dataclass
class ToolListRequest:
    """Request to list available tools."""
    agent_context: AgentContext
    filters: Optional[Dict[str, Any]] = None  # category, tags
    capability_query: Optional[str] = None  # Semantic search query
    pagination: Optional[Dict[str, int]] = None  # page, page_size

@dataclass
class ToolSummary:
    """Tool summary for listing."""
    tool_id: str
    tool_name: str
    description: str
    category: str
    versions: List[str]  # Available versions
    latest_version: str
    tags: List[str]
    requires_approval: bool  # HITL flag

@dataclass
class ToolListResponse:
    """Response with list of available tools."""
    tools: List[ToolSummary]
    total_count: int
    page: int
    page_size: int
```

---

#### 4.1.3 tool.status() - Execution Status Query

**Purpose:** Query status of tool invocation (for async mode).

**Python Protocol Definition:**
```python
@dataclass
class ToolStatusRequest:
    """Request to query tool invocation status."""
    invocation_id: str
    agent_context: AgentContext

@dataclass
class ToolStatusResponse:
    """Response with tool invocation status."""
    invocation_id: str
    status: ToolInvocationStatus
    progress_percent: Optional[int] = None  # For long-running tools
    current_phase: Optional[str] = None  # E.g., "parsing", "processing"
    error: Optional[ToolError] = None
    latest_checkpoint: Optional[CheckpointMetadata] = None  # Phase 16
```

---

#### 4.1.4 tool.cancel() - Execution Cancellation

**Purpose:** Cancel running tool invocation.

**Python Protocol Definition:**
```python
@dataclass
class ToolCancelRequest:
    """Request to cancel tool invocation."""
    invocation_id: str
    agent_context: AgentContext
    reason: Optional[str] = None  # Cancellation reason

@dataclass
class ToolCancelResponse:
    """Response to cancellation request."""
    invocation_id: str
    cancelled: bool
    message: str  # E.g., "Cancellation in progress" or "Already completed"
```

---

### 4.2 Required Interfaces

#### 4.2.1 Agent Sandbox Context (from L02, BC-1)

**Provider:** L02 (Agent Runtime Layer)
**Direction:** L02 -> L03
**Purpose:** Provide parent sandbox context for nested tool sandbox creation.

**Interface Contract:**
```python
@dataclass
class AgentSandboxContext:
    """Parent sandbox context from Agent Runtime Layer."""
    agent_did: str
    tenant_id: str
    parent_sandbox_id: str  # Kubernetes Sandbox CRD ID

    resource_limits: ResourceLimits  # CPU, memory, timeout
    network_policy: NetworkPolicy  # Allowed hosts, ports, DNS
    filesystem_policy: FilesystemPolicy  # Mount paths, permissions

@dataclass
class NetworkPolicy:
    """Network policy for tool execution."""
    allowed_hosts: List[str]  # Hostnames or IP addresses
    allowed_ports: List[int]  # TCP/UDP ports
    dns_servers: List[str]  # DNS resolver IPs

@dataclass
class FilesystemPolicy:
    """Filesystem policy for tool execution."""
    mounts: List[Mount]

@dataclass
class Mount:
    """Filesystem mount."""
    path: str  # Mount path (e.g., "/workspace")
    mode: Literal["ro", "rw"]  # Read-only or read-write
```

---

#### 4.2.2 ABAC Policy Engine (from L01)

**Provider:** L01 (Agentic Data Layer - ABAC Engine)
**Direction:** L03 -> L01 (request), L01 -> L03 (response)
**Purpose:** Query attribute-based access control policies for tool permissions.

**Interface Contract:**
```python
@dataclass
class ABACCheckRequest:
    """Request to check ABAC policy."""
    agent_id: str  # Agent DID
    resource_type: str  # "tool"
    resource_id: str  # Tool ID
    action: str  # "execute"
    context: Dict[str, Any]  # Filesystem paths, network endpoints, credentials

@dataclass
class ABACCheckResponse:
    """Response from ABAC policy check."""
    allowed: bool
    reason: Optional[str] = None  # Policy ID or denial reason
    cache_ttl_seconds: int = 300  # Cache TTL for this decision
```

**Endpoint:** `POST /api/v1/abac/check-permission`
**Timeout:** 500ms (fast fail for real-time invocation)

---

#### 4.2.3 Event Store (from L01)

**Provider:** L01 (Agentic Data Layer - Event Store)
**Direction:** L03 -> L01 (publish events)
**Purpose:** Publish tool invocation events for audit, analytics, and downstream processing.

**Interface Contract:** Apache Kafka topic: `tool-execution-events`
**Format:** CloudEvents 1.0 (see Section 4.3)

---

#### 4.2.4 Document Bridge (from Phase 15 MCP)

**Provider:** document-consolidator MCP server (Phase 15)
**Direction:** L03 <-> MCP (bidirectional JSON-RPC)
**Purpose:** Access authoritative documents during tool execution.

**Interface Contract:**
- MCP JSON-RPC methods: `get_source_of_truth`, `search_documents`, `find_overlaps`, `get_document_metadata`, `ingest_document`
- Transport: stdio (stdin/stdout pipes)
- Timeout: 30s per request

---

#### 4.2.5 State Bridge (from Phase 16 MCP)

**Provider:** context-orchestrator MCP server (Phase 16)
**Direction:** L03 <-> MCP (bidirectional JSON-RPC)
**Purpose:** Checkpoint and restore tool execution state.

**Interface Contract:**
- MCP JSON-RPC methods: `save_context_snapshot`, `create_checkpoint`, `rollback_to`, `get_unified_context`, `switch_task`
- Transport: stdio (stdin/stdout pipes)
- Timeout: 10s per request

---

### 4.3 Events Published

All events published in **CloudEvents 1.0** format to Kafka topic `tool-execution-events`. Partition key: `tenant_id` (tenant isolation).

#### 4.3.1 tool.invoked

**Published:** When tool invocation starts (after permission checks pass).

**Schema:**
```json
{
  "specversion": "1.0",
  "type": "ai.agent.tool.invoked",
  "source": "tool-execution-layer",
  "id": "<invocation_id>",
  "time": "2026-01-14T10:30:00Z",
  "datacontenttype": "application/json",
  "data": {
    "agent_did": "did:agent:xyz789",
    "tenant_id": "tenant_acme",
    "tool_id": "analyze_code",
    "tool_version": "2.1.0",
    "parameters": {/* PII-sanitized */},
    "async_mode": false,
    "priority": "normal"
  }
}
```

---

#### 4.3.2 tool.succeeded

**Published:** When tool invocation completes successfully.

**Schema:**
```json
{
  "specversion": "1.0",
  "type": "ai.agent.tool.succeeded",
  "source": "tool-execution-layer",
  "id": "<event_id>",
  "time": "2026-01-14T10:35:00Z",
  "datacontenttype": "application/json",
  "data": {
    "invocation_id": "<invocation_id>",
    "agent_did": "did:agent:xyz789",
    "tenant_id": "tenant_acme",
    "tool_id": "analyze_code",
    "tool_version": "2.1.0",
    "result_summary": "Analysis complete: 15 issues found",
    "execution_metadata": {
      "duration_ms": 12340,
      "cpu_used_millicore_seconds": 6170,
      "memory_peak_mb": 512,
      "documents_accessed": [
        {"document_id": "doc-123", "document_version": "v2.0", "access_count": 3}
      ],
      "checkpoints_created": [
        {"checkpoint_id": "cp-456", "checkpoint_type": "macro", "timestamp": "2026-01-14T10:34:00Z"}
      ]
    }
  }
}
```

---

#### 4.3.3 tool.failed

**Published:** When tool invocation fails (error, timeout, permission denied).

**Schema:**
```json
{
  "specversion": "1.0",
  "type": "ai.agent.tool.failed",
  "source": "tool-execution-layer",
  "id": "<event_id>",
  "time": "2026-01-14T10:31:00Z",
  "datacontenttype": "application/json",
  "data": {
    "invocation_id": "<invocation_id>",
    "agent_did": "did:agent:xyz789",
    "tenant_id": "tenant_acme",
    "tool_id": "analyze_code",
    "tool_version": "2.1.0",
    "error": {
      "code": "timeout",
      "message": "Tool execution exceeded 30s timeout",
      "retryable": true
    },
    "execution_metadata": {
      "duration_ms": 30100,
      "checkpoints_created": [
        {"checkpoint_id": "cp-789", "checkpoint_type": "micro", "timestamp": "2026-01-14T10:30:30Z"}
      ]
    }
  }
}
```

---

#### 4.3.4 tool.timeout

**Published:** When tool invocation times out (subset of tool.failed, for specific monitoring).

**Schema:** Same as `tool.failed` with `error.code: "timeout"`.

---

#### 4.3.5 tool.checkpoint.created (Phase 16)

**Published:** When checkpoint created during long-running tool execution.

**Schema:**
```json
{
  "specversion": "1.0",
  "type": "ai.agent.tool.checkpoint.created",
  "source": "tool-execution-layer",
  "id": "<event_id>",
  "time": "2026-01-14T10:30:30Z",
  "datacontenttype": "application/json",
  "data": {
    "invocation_id": "<invocation_id>",
    "checkpoint_id": "cp-789",
    "checkpoint_type": "micro",
    "progress_percent": 25,
    "current_phase": "parsing"
  }
}
```

---

#### 4.3.6 circuit.opened

**Published:** When circuit breaker transitions to open state for external API.

**Schema:**
```json
{
  "specversion": "1.0",
  "type": "ai.agent.circuit.opened",
  "source": "tool-execution-layer",
  "id": "<event_id>",
  "time": "2026-01-14T10:32:00Z",
  "datacontenttype": "application/json",
  "data": {
    "circuit_name": "external-api-example-com",
    "tool_id": "analyze_code",
    "failure_rate": 65.4,
    "failure_count": 32,
    "window_size": 100,
    "reason": "Failure rate 65.4% exceeded threshold 50%"
  }
}
```

---

#### 4.3.7 circuit.closed

**Published:** When circuit breaker transitions from half-open to closed state.

**Schema:**
```json
{
  "specversion": "1.0",
  "type": "ai.agent.circuit.closed",
  "source": "tool-execution-layer",
  "id": "<event_id>",
  "time": "2026-01-14T10:35:00Z",
  "datacontenttype": "application/json",
  "data": {
    "circuit_name": "external-api-example-com",
    "tool_id": "analyze_code",
    "test_success_count": 10,
    "reason": "Half-open test calls succeeded"
  }
}
```

---

### 4.4 Events Consumed

*None.* L03 is an event producer only. Event consumption handled by downstream layers (L01 Event Store, L11 Integration Layer, external SIEM systems).

---

## Section 5: Data Model

### 5.1 Owned Entities

#### 5.1.1 ToolDefinition (PostgreSQL)

**Purpose:** Registry entry for a tool with capability manifest and semantic embedding.

**Schema:**
```sql
CREATE TABLE tool_definitions (
  tool_id VARCHAR(255) PRIMARY KEY,
  tool_name VARCHAR(255) NOT NULL,
  description TEXT NOT NULL,
  category VARCHAR(100) NOT NULL,  -- e.g., "data_access", "computation", "external_api"
  tags TEXT[],  -- Array of tags
  latest_version VARCHAR(50) NOT NULL,  -- Semantic version
  source_type VARCHAR(50) NOT NULL,  -- "mcp", "openapi", "langchain", "native"
  source_metadata JSONB,  -- Source-specific metadata (MCP server ID, OpenAPI spec URL)
  deprecation_state VARCHAR(20) DEFAULT 'active',  -- "active", "deprecated", "sunset", "removed"
  deprecation_date TIMESTAMP,
  created_at TIMESTAMP DEFAULT NOW(),
  updated_at TIMESTAMP DEFAULT NOW(),

  -- Gap G-001: Tool capability manifest fields
  requires_approval BOOLEAN DEFAULT FALSE,  -- HITL approval required
  default_timeout_seconds INTEGER DEFAULT 30,
  default_cpu_millicore_limit INTEGER DEFAULT 500,
  default_memory_mb_limit INTEGER DEFAULT 1024,

  -- Permissions (Gap G-001)
  required_permissions JSONB,  -- {filesystem: [...], network: [...], credentials: [...]}

  -- Result schema (Gap G-010)
  result_schema JSONB,  -- JSON Schema 2020-12 for output validation

  -- Retry policy (Gap G-001)
  retry_policy JSONB,  -- {max_attempts, base_delay_ms, max_delay_ms, retryable_errors}

  -- Circuit breaker config (Gap G-001)
  circuit_breaker_config JSONB,  -- {failure_rate_threshold, window_size, wait_duration_seconds}

  -- Semantic search (pgvector)
  description_embedding VECTOR(768)  -- Ollama Mistral 7B embeddings
);

CREATE INDEX idx_tool_category ON tool_definitions(category);
CREATE INDEX idx_tool_deprecation_state ON tool_definitions(deprecation_state);
CREATE INDEX idx_tool_description_embedding ON tool_definitions USING ivfflat (description_embedding vector_cosine_ops);
```

**Gap Integration:**
- **G-001 (High):** Tool capability manifest schema fully defined with all required fields (permissions, result_schema, timeout, retry policy, circuit breaker config).
- **G-010 (Critical):** Result validation schema stored in `result_schema` field as JSON Schema 2020-12.

---

#### 5.1.2 ToolVersion (PostgreSQL)

**Purpose:** Version history for tools supporting multiple concurrent versions.

**Schema:**
```sql
CREATE TABLE tool_versions (
  version_id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  tool_id VARCHAR(255) REFERENCES tool_definitions(tool_id) ON DELETE CASCADE,
  version VARCHAR(50) NOT NULL,  -- Semantic version (e.g., "2.1.0")
  manifest JSONB NOT NULL,  -- Full tool manifest (parameters schema, return schema)
  compatibility_range VARCHAR(100),  -- Compatible agent versions (e.g., "^1.0.0")
  release_notes TEXT,
  deprecated_in_favor_of VARCHAR(50),  -- Version to migrate to
  created_at TIMESTAMP DEFAULT NOW(),
  removed_at TIMESTAMP,  -- Set when version removed (Gap G-003)

  UNIQUE(tool_id, version)
);

CREATE INDEX idx_tool_version_tool_id ON tool_versions(tool_id);
CREATE INDEX idx_tool_version_version ON tool_versions(version);
```

**Gap Integration:**
- **G-002 (Medium):** Semantic versioning conflict resolution supported via `compatibility_range` field and query logic to find highest compatible version.
- **G-003 (Medium):** Tool deprecation workflow implemented via `deprecated_in_favor_of` and `removed_at` fields.

---

#### 5.1.3 ToolInvocation (PostgreSQL)

**Purpose:** Execution record for tool invocations (audit trail, analytics).

**Schema:**
```sql
CREATE TABLE tool_invocations (
  invocation_id UUID PRIMARY KEY,
  tool_id VARCHAR(255) NOT NULL,
  tool_version VARCHAR(50) NOT NULL,
  agent_did VARCHAR(255) NOT NULL,
  tenant_id VARCHAR(255) NOT NULL,
  session_id VARCHAR(255),

  parameters JSONB,  -- PII-sanitized
  result JSONB,  -- Tool output

  status VARCHAR(50) NOT NULL,  -- "success", "error", "timeout", etc.
  error_code VARCHAR(100),
  error_message TEXT,

  -- Execution metadata
  started_at TIMESTAMP NOT NULL,
  completed_at TIMESTAMP,
  duration_ms INTEGER,
  cpu_used_millicore_seconds INTEGER,
  memory_peak_mb INTEGER,
  network_bytes_sent BIGINT,
  network_bytes_received BIGINT,

  -- Phase 15 integration
  documents_accessed JSONB,  -- [{document_id, version, access_count}]

  -- Phase 16 integration
  checkpoints_created JSONB,  -- [{checkpoint_id, type, timestamp}]
  checkpoint_ref VARCHAR(255),  -- Final checkpoint ID for resumable operations

  created_at TIMESTAMP DEFAULT NOW()
);

CREATE INDEX idx_invocation_agent ON tool_invocations(agent_did);
CREATE INDEX idx_invocation_tenant ON tool_invocations(tenant_id);
CREATE INDEX idx_invocation_tool ON tool_invocations(tool_id);
CREATE INDEX idx_invocation_status ON tool_invocations(status);
CREATE INDEX idx_invocation_started_at ON tool_invocations(started_at);
```

---

#### 5.1.4 ToolCheckpoint (Phase 16, PostgreSQL + Redis)

**Purpose:** Checkpoint state for resumable tool operations.

**PostgreSQL Schema (cold checkpoints):**
```sql
CREATE TABLE tool_checkpoints (
  checkpoint_id UUID PRIMARY KEY,
  invocation_id UUID REFERENCES tool_invocations(invocation_id) ON DELETE CASCADE,
  checkpoint_type VARCHAR(20) NOT NULL,  -- "micro", "macro", "named"
  checkpoint_label VARCHAR(255),  -- For named checkpoints

  parent_checkpoint_id UUID,  -- For delta encoding (Gap G-015)
  is_delta BOOLEAN DEFAULT FALSE,

  state JSONB NOT NULL,  -- Tool execution state
  state_compressed BYTEA,  -- gzip/zstd compressed state (if > 10 KB, Gap G-016)
  state_size_bytes INTEGER,

  progress_percent INTEGER,
  current_phase VARCHAR(100),

  -- Phase 15 integration
  document_versions JSONB,  -- {document_id: version} for version pinning

  created_at TIMESTAMP DEFAULT NOW(),
  expires_at TIMESTAMP,  -- TTL for micro-checkpoints
  archived_at TIMESTAMP  -- When moved to S3 Glacier
);

CREATE INDEX idx_checkpoint_invocation ON tool_checkpoints(invocation_id);
CREATE INDEX idx_checkpoint_type ON tool_checkpoints(checkpoint_type);
CREATE INDEX idx_checkpoint_expires_at ON tool_checkpoints(expires_at) WHERE expires_at IS NOT NULL;
```

**Redis Schema (hot checkpoints):**
```
Key: checkpoint:tool:{invocation_id}:latest
Value: JSON {
  checkpoint_id: "...",
  invocation_id: "...",
  state: {...},
  progress_percent: 25,
  current_phase: "parsing",
  timestamp: "2026-01-14T10:30:30Z"
}
TTL: 3600 seconds (1 hour)
```

**Gap Integration:**
- **G-015 (Medium):** Checkpoint diff/delta encoding via `parent_checkpoint_id` and `is_delta` fields. When enabled, only changed state stored with reference to parent.
- **G-016 (Low):** Checkpoint compression threshold via `state_compressed` field. State compressed with gzip if > 10 KB, stored in BYTEA column.

---

#### 5.1.5 CircuitState (Redis)

**Purpose:** Distributed circuit breaker state for external APIs.

**Redis Schema:**
```
Key: circuit:state:{circuit_name}
Value: JSON {
  state: "closed" | "open" | "half_open",
  failure_count: 32,
  success_count: 5,
  slow_call_count: 3,
  sliding_window: [
    {timestamp: "2026-01-14T10:31:00Z", result: "failure", duration_ms: 5200},
    ...
  ],
  last_failure_time: "2026-01-14T10:32:00Z",
  opened_at: "2026-01-14T10:32:00Z",
  last_state_transition: "2026-01-14T10:32:00Z",
  half_open_test_calls_permitted: 10,
  half_open_test_calls_completed: 0
}
TTL: None (persistent until circuit removed)
```

---

#### 5.1.6 ExternalServiceCredential (HashiCorp Vault)

**Purpose:** Ephemeral credentials for external service access.

**Vault Path:** `secret/tool-execution/{tool_id}/{credential_name}`

**Schema:**
```json
{
  "credential_type": "api_key" | "oauth_token" | "aws_iam" | "gcp_sa" | "azure_ad",
  "credential_value": "...",  -- Encrypted by Vault
  "expires_at": "2026-01-14T11:00:00Z",  -- Ephemeral lifetime
  "rotation_schedule": "daily" | "weekly" | "on_demand",
  "metadata": {
    "service_name": "external-api-example-com",
    "scopes": ["read", "write"]
  }
}
```

---

### 5.2 Configuration Schemas (JSON Schema 2020-12)

#### 5.2.1 Tool Manifest Schema

**Purpose:** Define tool parameters, return schema, permissions, and execution config.

**JSON Schema:**
```json
{
  "$schema": "https://json-schema.org/draft/2020-12/schema",
  "$id": "https://tool-execution-layer/schemas/tool-manifest.json",
  "title": "Tool Manifest",
  "type": "object",
  "properties": {
    "tool_id": {"type": "string"},
    "tool_name": {"type": "string"},
    "description": {"type": "string"},
    "category": {
      "type": "string",
      "enum": ["data_access", "computation", "external_api", "file_system", "llm_interaction"]
    },
    "version": {
      "type": "string",
      "pattern": "^\\d+\\.\\d+\\.\\d+$"
    },

    "parameters_schema": {
      "type": "object",
      "description": "JSON Schema 2020-12 for input parameters"
    },

    "result_schema": {
      "type": "object",
      "description": "JSON Schema 2020-12 for output validation (Gap G-010)"
    },

    "permissions": {
      "type": "object",
      "properties": {
        "filesystem": {
          "type": "array",
          "items": {
            "type": "object",
            "properties": {
              "path": {"type": "string"},
              "mode": {"type": "string", "enum": ["ro", "rw"]}
            }
          }
        },
        "network": {
          "type": "array",
          "items": {
            "type": "object",
            "properties": {
              "host": {"type": "string"},
              "port": {"type": "integer"}
            }
          }
        },
        "credentials": {
          "type": "array",
          "items": {"type": "string"}
        }
      }
    },

    "execution_config": {
      "type": "object",
      "properties": {
        "default_timeout_seconds": {"type": "integer", "default": 30},
        "default_cpu_millicore_limit": {"type": "integer", "default": 500},
        "default_memory_mb_limit": {"type": "integer", "default": 1024},
        "requires_approval": {"type": "boolean", "default": false},
        "retry_policy": {
          "type": "object",
          "properties": {
            "max_attempts": {"type": "integer", "default": 3},
            "base_delay_ms": {"type": "integer", "default": 1000},
            "max_delay_ms": {"type": "integer", "default": 60000},
            "retryable_errors": {
              "type": "array",
              "items": {"type": "string"}
            }
          }
        },
        "circuit_breaker_config": {
          "type": "object",
          "properties": {
            "failure_rate_threshold": {"type": "number", "minimum": 0, "maximum": 100},
            "sliding_window_size": {"type": "integer"},
            "wait_duration_seconds": {"type": "integer"}
          }
        }
      }
    }
  },
  "required": ["tool_id", "tool_name", "version", "parameters_schema"]
}
```

**Gap Integration:**
- **G-001 (High):** Complete tool manifest schema with all required fields (permissions, result_schema, execution_config).

---

### 5.3 Data Flows (ASCII Diagrams)

#### 5.3.1 Tool Invocation Flow with Phase 15 Document Context

```
+========================================================================+
|                 Tool Invocation with Document Context                  |
+========================================================================+

L11 Integration Layer
  |
  | 1. tool.invoke(request)
  |    - tool_id, parameters
  |    - document_context: {document_refs, version_pinning}
  v
+------------------------+
| L03 Permission Checker |
+------------------------+
  |
  | 2. Validate capability token (JWT RS256)
  | 3. Query ABAC Engine (permission check)
  v
+------------------------+
| L03 Tool Registry      |
+------------------------+
  |
  | 4. Lookup tool manifest (PostgreSQL)
  | 5. Resolve version (SemVer conflict resolution, Gap G-002)
  v
+------------------------+
| L03 Document Bridge    |
| (Phase 15)             |
+------------------------+
  |
  | 6. Check document permissions (ABAC, Gap G-013)
  | 7. Query document cache (Redis, 5-min TTL)
  |    - Cache miss -> MCP call to document-consolidator
  | 8. Pin document versions (if version_pinning=true)
  v
+--------------------------+
| document-consolidator    |
| (MCP Server, Phase 15)   |
+--------------------------+
  |
  | 9. get_source_of_truth(document_refs)
  | 10. Return document content + version
  v
+------------------------+
| L03 Document Bridge    |
+------------------------+
  |
  | 11. Cache documents in Redis
  | 12. Build document context for tool
  v
+------------------------+
| L03 Tool Executor      |
+------------------------+
  |
  | 13. Create nested sandbox (BC-1)
  |     - Inherit agent resource limits
  |     - Enforce tool filesystem/network restrictions
  | 14. Inject credentials from Vault (ephemeral)
  | 15. Inject document context as environment variables
  | 16. Execute tool binary in sandbox
  v
+------------------------+
| Tool Process           |
| (gVisor/Firecracker)   |
+------------------------+
  |
  | 17. Process parameters
  | 18. Access documents from environment
  | 19. Call external APIs (via External Adapter Manager)
  | 20. Return result
  v
+------------------------+
| L03 Result Validator   |
+------------------------+
  |
  | 21. Validate result against result_schema (Gap G-010)
  | 22. Type coercion (Gap G-011)
  | 23. Sanitization (SQL injection, XSS, Gap G-011)
  v
+------------------------+
| L03 Audit Logger       |
+------------------------+
  |
  | 24. Publish tool.succeeded event (CloudEvents, Gap G-018)
  |     - Include documents_accessed metadata
  v
L11 Integration Layer
  |
  | 25. ToolInvokeResponse(status=success, result=...)
```

---

#### 5.3.2 Long-Running Tool Flow with Phase 16 Checkpoints

```
+========================================================================+
|            Long-Running Tool with Hybrid Checkpointing                 |
+========================================================================+

L11 Integration Layer
  |
  | 1. tool.invoke(request)
  |    - async_mode=true
  |    - checkpoint_config: {enable_checkpointing=true, interval=30s}
  v
+------------------------+
| L03 Tool Executor      |
+------------------------+
  |
  | 2. Create nested sandbox
  | 3. Start tool execution (async)
  | 4. Return ToolInvokeResponse(status=running, polling_info)
  v
+------------------------+
| Tool Process           |
| (Long-running, 5 min)  |
+------------------------+
  |
  | ... processing ...
  | T=30s
  v
+------------------------+
| L03 State Bridge       |
| (Phase 16)             |
+------------------------+
  |
  | 5. Micro-checkpoint timer triggers (30s interval)
  | 6. Serialize tool state (progress, phase, counters)
  | 7. Store in Redis (hot checkpoint, TTL 1 hour)
  v
+--------------------------+
| context-orchestrator     |
| (MCP Server, Phase 16)   |
+--------------------------+
  |
  | 8. save_context_snapshot(taskId, updates, syncToFile=false)
  | 9. Redis: checkpoint:tool:{invocation_id}:latest
  v
+------------------------+
| Tool Process           |
+------------------------+
  |
  | ... processing continues ...
  | T=60s (milestone: "parsing complete")
  v
+------------------------+
| L03 State Bridge       |
+------------------------+
  |
  | 10. Macro-checkpoint event triggered (milestone)
  | 11. Serialize tool state + document versions
  | 12. Store in PostgreSQL (cold checkpoint, 90-day retention)
  | 13. Delta encoding if state > 100 KB (Gap G-015)
  v
+--------------------------+
| context-orchestrator     |
| (MCP Server, Phase 16)   |
+--------------------------+
  |
  | 14. create_checkpoint(taskId, label="parsing-complete")
  | 15. PostgreSQL: tool_checkpoints table
  v
+------------------------+
| Tool Process           |
+------------------------+
  |
  | ... processing continues ...
  | T=150s (timeout or crash)
  v
+------------------------+
| L03 Tool Executor      |
+------------------------+
  |
  | 16. Detect timeout/crash
  | 17. Kill tool process
  | 18. Publish tool.failed event
  v
L11 Integration Layer
  |
  | 19. Retry with resume_from_checkpoint_id
  v
+------------------------+
| L03 State Bridge       |
+------------------------+
  |
  | 20. Retrieve latest checkpoint from Redis
  | 21. If Redis expired, fallback to PostgreSQL macro-checkpoint
  | 22. Deserialize state
  v
+------------------------+
| L03 Tool Executor      |
+------------------------+
  |
  | 23. Create new sandbox
  | 24. Restore tool state from checkpoint
  | 25. Resume execution from last phase
  v
+------------------------+
| Tool Process           |
| (Resumed)              |
+------------------------+
  |
  | ... processing from checkpoint ...
  | T=300s (completion)
  v
+------------------------+
| L03 Audit Logger       |
+------------------------+
  |
  | 26. Publish tool.succeeded event
  |     - Include checkpoints_created metadata
  v
L11 Integration Layer
  |
  | 27. ToolInvokeResponse(status=success, result=...)
```

---

#### 5.3.3 Circuit Breaker State Flow

```
+========================================================================+
|                  Circuit Breaker State Transitions                     |
+========================================================================+

INITIAL STATE: CLOSED
+------------------------+
| Tool calls external    |
| API via External       |
| Adapter Manager        |
+------------------------+
  |
  | Success/Failure tracked in Redis
  | Key: circuit:state:{circuit_name}
  v
+------------------------+
| Circuit Breaker        |
| Controller             |
+------------------------+
  |
  | Failure rate calculated (sliding window)
  | failure_rate = failures / (failures + successes)
  |
  | IF failure_rate > threshold (e.g., 50%)
  v
STATE TRANSITION: CLOSED -> OPEN
+------------------------+
| Circuit Breaker        |
| State: OPEN            |
+------------------------+
  |
  | 1. Block all requests to external API
  | 2. Publish circuit.opened event (Gap G-008)
  |    - Redis pub/sub: circuit:state:changes
  | 3. Dependent tools notified (subscribe to channel)
  | 4. Start wait_duration timer (e.g., 60s)
  v
  ... wait_duration elapses ...
  |
STATE TRANSITION: OPEN -> HALF-OPEN
+------------------------+
| Circuit Breaker        |
| State: HALF-OPEN       |
+------------------------+
  |
  | 5. Allow limited test requests (e.g., 10)
  | 6. Canary strategy: gradually increase traffic (Gap G-009)
  |    - Start with 1% of requests
  |    - Increase to 10%, 50%, 100% if successful
  |
  | IF test requests succeed
  v
STATE TRANSITION: HALF-OPEN -> CLOSED
+------------------------+
| Circuit Breaker        |
| State: CLOSED          |
+------------------------+
  |
  | 7. Resume normal operations
  | 8. Publish circuit.closed event
  | 9. Reset failure counters
  |
  | IF test requests fail
  v
STATE TRANSITION: HALF-OPEN -> OPEN
+------------------------+
| Circuit Breaker        |
| State: OPEN            |
+------------------------+
  |
  | 10. Re-open circuit
  | 11. Restart wait_duration timer
  | 12. Publish circuit.opened event
```

---

## Gap Tracking Table

| Gap ID | Description | Priority | Section | How Addressed |
|--------|-------------|----------|---------|---------------|
| **G-001** | Tool capability manifest schema not fully defined | High | 5.1.1, 5.2.1 | Complete manifest schema defined in ToolDefinition PostgreSQL table and JSON Schema with all fields: permissions (filesystem, network, credentials), result_schema, timeout, retry_policy, circuit_breaker_config. |
| **G-002** | Semantic versioning conflict resolution for parallel versions | Medium | 3.3.1, 5.1.2 | Implemented via `compatibility_range` field in ToolVersion table and `max_versions_per_tool` retention policy in Tool Registry configuration. Query logic finds highest compatible version within agent's version range. |
| **G-003** | Tool deprecation workflow and migration paths | Medium | 3.3.1, 5.1.2 | Lifecycle states (active, deprecated, sunset, removed) defined in ToolDefinition.deprecation_state field. ToolVersion includes `deprecated_in_favor_of` and `removed_at` fields for migration guidance. `deprecation_warning_days` configuration triggers agent warnings. |
| **G-006** | Capability token format and signing mechanism | Critical | 4.1.1 | JWT (RS256) structure fully specified with claims for tool_id, tool_version, agent_did, tenant_id, allowed_operations, filesystem_permissions, network_permissions, credential_permissions, exp, iat, iss. Public key path configured in Permission Checker. |
| **G-007** | Permission cache invalidation on policy updates | High | 3.3.3 | Redis pub/sub subscription to `policy:updates` channel from Data Layer ABAC Engine. On notification, invalidate cached permissions in Redis (key pattern: `permission:cache:{agent_did}:{tool_id}:*`). |
| **G-008** | Circuit breaker transition notifications to dependent tools | Medium | 3.3.5, 5.3.3 | Redis pub/sub channel `circuit:state:changes` for circuit breaker state transitions. Dependent tools subscribe and adjust behavior (e.g., skip fallback API if also open). Events published on open, half-open, closed transitions. |
| **G-009** | Half-open state testing strategy (canary vs all-or-nothing) | Medium | 3.3.5, 5.3.3 | Configurable via `half_open_strategy` parameter in Circuit Breaker Controller config. Canary strategy: gradually increase traffic percentage (1% -> 10% -> 50% -> 100%) if test calls successful. All-or-nothing strategy: send all permitted test calls immediately. |
| **G-010** | Result validation schema definition and enforcement | Critical | 3.3.6, 5.1.1, 5.2.1 | JSON Schema 2020-12 stored in ToolDefinition.result_schema field and tool manifest. AJV validator enforces schema checks before returning results to agent. `strict_mode` flag rejects outputs that fail validation (E3501 error). |
| **G-011** | Type coercion and sanitization rules | High | 3.3.6 | Type coercion rules defined in Result Validator configuration: string -> number/integer/boolean/date. Sanitization patterns for SQL injection, XSS, command injection with configurable actions (reject, redact, escape). |
| **G-012** | Structured output validation against tool manifest | High | 3.3.6 | Implemented via AJV validator with JSON Schema 2020-12 from tool manifest `result_schema` field. `strict_mode` enforces validation, returns field-level errors (E3501-E3507). |
| **G-013** | Document access permission model (ABAC integration) | High | 3.3.7, 5.3.1 | ABAC permission check before MCP document retrieval. Query Data Layer ABAC Engine with `(agent_did, document_id, access_mode)` tuple. Cache permissions in Redis (5-min TTL). Document Bridge enforces permissions before returning documents to tools. |
| **G-014** | Bulk document retrieval optimization | Medium | 3.3.7 | Batched MCP requests for multiple documents. Send array of document_ids in single `tools/call` JSON-RPC request to document-consolidator. Reduce round-trips from N to 1. Cache batch results in Redis. |
| **G-015** | Checkpoint diff/delta encoding for large states | Medium | 3.3.8, 5.1.4 | Delta encoding enabled via State Bridge configuration `delta_encoding.enabled` flag. When checkpoint > 100 KB, store only changed state fields with `parent_checkpoint_id` reference in PostgreSQL tool_checkpoints table. `is_delta` flag indicates delta checkpoint. |
| **G-016** | Checkpoint compression threshold tuning | Low | 3.3.8, 5.1.4 | Compression threshold configurable via `compression.threshold_kb` parameter (default 10 KB). gzip compression recommended (benchmarked vs zstd). Compressed state stored in BYTEA column `state_compressed` in tool_checkpoints table. |

**Total Gaps Addressed in Part 1:** 13 out of 24 total gaps (54%)

**Remaining Gaps for Part 2 (Sections 6-10):** G-004, G-005, G-017, G-018, G-019, G-020, G-021, G-022

**Status:** All gaps targeted at Sections 1-5 have been fully addressed in this specification part.

---

**End of Part 1**
**Next Part:** tool-execution-spec-part2.md (Sections 6-10)
# Tool Execution Layer Specification v1.0 - Part 2

**Document Status:** Draft
**Version:** 1.0 (Part 2 of 3)
**Date:** 2026-01-14
**Layer:** L03 - Tool Execution Layer
**Sections:** 6-10 (Integration, Reliability, Security, Observability, Configuration)
**Continuation of:** tool-execution-spec-part1.md

---

## Section 6: Integration with Data Layer

### 6.1 Relationship Model

L03 (Tool Execution Layer) has bidirectional integration with L01 (Agentic Data Layer) across multiple touchpoints:

| Touchpoint | Relationship | L03 Role | L01 Component | Data Flow |
|------------|--------------|----------|---------------|-----------|
| **Event Publishing** | Producer | Publisher | Event Store | L03 -> L01: tool invocation events (CloudEvents 1.0) |
| **ABAC Permissions** | Consumer | Query client | ABAC Engine | L03 -> L01: permission checks, L01 -> L03: allow/deny decisions |
| **Context Retrieval** | Consumer | Request client | Context Injector | L03 -> L01: context requests, L01 -> L03: credentials/config |
| **Tool Registry Storage** | Owner/Consumer | Data owner | PostgreSQL | L03 owns tool_definitions schema, L01 provides PostgreSQL instance |
| **Circuit Breaker State** | Owner/Consumer | State owner | Redis | L03 owns circuit state, L01 provides Redis instance |
| **Audit Streaming** | Producer | Publisher | Kafka | L03 -> L01: audit events for compliance/SIEM |

**Provider vs Consumer Summary:**
- **L03 Provides:** Tool execution capability, tool registry, circuit breaker state
- **L01 Provides:** Infrastructure (PostgreSQL, Redis, Kafka), ABAC decisions, agent context
- **Bidirectional:** L03 stores data in L01's infrastructure, queries L01's services

---

### 6.2 Agent Identity Integration

**Purpose:** Resolve Decentralized Identifiers (DIDs) for agent authentication and tool invocation tracking.

**Integration Pattern:**
```
L11 Integration Layer
  |
  | ToolInvokeRequest includes:
  | - agent_context.agent_did (e.g., "did:agent:xyz789")
  | - agent_context.tenant_id
  | - agent_context.user_did (optional)
  v
L03 Permission Checker
  |
  | 1. Validate DID format (did:agent:{uuid} or did:web:{domain})
  | 2. Query L01 DID Registry for DID Document
  |    - Endpoint: GET /api/v1/did/resolve/{did}
  | 3. Verify DID is active (not revoked, not expired)
  | 4. Extract public keys for JWT capability token verification
  v
L01 DID Registry
  |
  | Return DID Document:
  | {
  |   "id": "did:agent:xyz789",
  |   "verificationMethod": [{
  |     "id": "did:agent:xyz789#keys-1",
  |     "type": "JsonWebKey2020",
  |     "publicKeyJwk": {...}
  |   }],
  |   "authentication": ["did:agent:xyz789#keys-1"],
  |   "service": [{
  |     "id": "did:agent:xyz789#agent-runtime",
  |     "type": "AgentRuntime",
  |     "serviceEndpoint": "https://agent-runtime.example.com"
  |   }]
  | }
  v
L03 Permission Checker
  |
  | 5. Cache DID Document in Redis (TTL 1 hour)
  | 6. Use public key to verify capability token signature
  | 7. Proceed with tool invocation
```

**Error Handling:**
- DID not found: Return `E3201` (Invalid capability token)
- DID revoked: Return `E3202` (Expired capability token)
- DID Document malformed: Return `E3201` (Invalid capability token)
- L01 DID Registry unavailable: Use cached DID Document, fail if cache miss

**Caching Strategy:**
```
Redis Key: did:cache:{agent_did}
TTL: 3600 seconds (1 hour)
Value: DID Document JSON
Invalidation: Subscribe to Redis pub/sub channel `did:updates`
```

---

### 6.3 Event Integration

**Purpose:** Publish tool invocation lifecycle events to L01 Event Store for audit, analytics, and downstream workflows.

**Event Catalog:**
- `tool.invoked`: Tool execution started
- `tool.succeeded`: Tool execution completed successfully
- `tool.failed`: Tool execution failed (error, timeout, permission denied)
- `tool.timeout`: Tool execution exceeded timeout limit
- `tool.checkpoint.created`: Checkpoint created (Phase 16)
- `circuit.opened`: Circuit breaker opened for external API
- `circuit.closed`: Circuit breaker closed after recovery

**Transport:** Apache Kafka topic `tool-execution-events`

**Partition Strategy:** Partition by `tenant_id` for tenant isolation and ordered processing per tenant.

**Message Format:** CloudEvents 1.0 (see Section 4.3 for schemas)

**Delivery Guarantees:**
- **At-least-once delivery:** Kafka producer with `acks=all` and retries
- **Idempotent consumers:** Events include `invocation_id` for deduplication
- **Ordered per partition:** Events for same tenant processed in order

**Integration Code Example (Python):**
```python
from kafka import KafkaProducer
from cloudevents.http import CloudEvent
from cloudevents.conversion import to_structured
import json

class EventPublisher:
    def __init__(self, kafka_bootstrap_servers: str):
        self.producer = KafkaProducer(
            bootstrap_servers=kafka_bootstrap_servers,
            value_serializer=lambda v: json.dumps(v).encode('utf-8'),
            acks='all',  # At-least-once delivery
            retries=3
        )

    def publish_tool_invoked(self, invocation_id: str, agent_did: str,
                            tenant_id: str, tool_id: str, tool_version: str,
                            parameters: dict):
        event = CloudEvent({
            "specversion": "1.0",
            "type": "ai.agent.tool.invoked",
            "source": "tool-execution-layer",
            "id": invocation_id,
            "datacontenttype": "application/json"
        }, {
            "agent_did": agent_did,
            "tenant_id": tenant_id,
            "tool_id": tool_id,
            "tool_version": tool_version,
            "parameters": self._sanitize_pii(parameters)  # Gap G-017
        })

        # Partition by tenant_id
        self.producer.send(
            topic="tool-execution-events",
            key=tenant_id.encode('utf-8'),
            value=to_structured(event)
        )
```

---

### 6.4 ABAC Integration

**Purpose:** Query L01 ABAC Engine for attribute-based access control decisions on tool invocations.

**Integration Flow:**
```
L03 Permission Checker receives ToolInvokeRequest
  |
  | 1. Extract capability token from request
  | 2. Validate JWT signature using agent DID public key
  | 3. Extract permissions from JWT claims:
  |    - filesystem_permissions: {allowed_paths, mode}
  |    - network_permissions: {allowed_hosts, allowed_ports}
  |    - credential_permissions: {allowed_secrets}
  v
L03 Permission Checker queries L01 ABAC Engine
  |
  | POST /api/v1/abac/check-permission
  | {
  |   "agent_id": "did:agent:xyz789",
  |   "resource_type": "tool",
  |   "resource_id": "analyze_code",
  |   "action": "execute",
  |   "context": {
  |     "filesystem_paths": ["/workspace/tool1"],
  |     "network_endpoints": ["api.example.com:443"],
  |     "credentials": ["aws_s3_read"]
  |   }
  | }
  v
L01 ABAC Engine evaluates policy
  |
  | Policy Example (OPA Rego):
  | allow {
  |   input.agent_id == "did:agent:xyz789"
  |   input.resource_type == "tool"
  |   input.action == "execute"
  |   agent_policies[input.agent_id].tools[_] == input.resource_id
  |   filesystem_allowed(input.context.filesystem_paths)
  |   network_allowed(input.context.network_endpoints)
  | }
  v
L01 ABAC Engine responds
  |
  | {
  |   "allowed": true,
  |   "reason": "policy_tool_access_v2",
  |   "cache_ttl_seconds": 300
  | }
  v
L03 Permission Checker caches decision
  |
  | Redis Key: permission:cache:{agent_did}:{tool_id}:{hash(context)}
  | TTL: 300 seconds (from cache_ttl_seconds)
  | Value: {"allowed": true, "reason": "policy_tool_access_v2"}
  |
  | Subscribe to Redis pub/sub: policy:updates
  | On notification, invalidate all permission cache entries
  v
L03 proceeds with tool invocation (if allowed)
```

**Error Handling:**
- ABAC Engine unavailable: Fail closed (deny access), log error `E3206`
- Timeout (> 500ms): Fail closed (deny access), log warning
- Policy evaluation error: Deny access, log error `E3206`

**Gap Integration:**
- **G-007 (High):** Permission cache invalidation on policy updates implemented via Redis pub/sub subscription to `policy:updates` channel.

---

### 6.5 Context Injector Integration

**Purpose:** Retrieve tool-specific credentials and configuration from L01 Context Injector for tool execution.

**Integration Flow:**
```
L03 Tool Executor prepares tool invocation
  |
  | 1. Query tool manifest for required credentials:
  |    - tool_manifest.permissions.credentials: ["aws_s3_read", "external_api_token"]
  v
L03 queries L01 Context Injector
  |
  | GET /api/v1/context/agent/{agent_did}/tool/{tool_id}
  | Headers:
  |   Authorization: Bearer {capability_token}
  v
L01 Context Injector
  |
  | 1. Validate capability token
  | 2. Query agent session context (session_id from token)
  | 3. Retrieve credentials from HashiCorp Vault:
  |    - vault://secret/tool-execution/{tool_id}/aws_s3_read
  |    - vault://secret/tool-execution/{tool_id}/external_api_token
  | 4. Generate ephemeral credentials (lifetime = tool timeout)
  | 5. Return credentials + config
  v
L01 Context Injector responds
  |
  | {
  |   "credentials": {
  |     "aws_access_key_id_ref": "vault://secrets/aws/access_key",
  |     "aws_secret_access_key_ref": "vault://secrets/aws/secret_key",
  |     "api_token_ref": "vault://secrets/external_api/token"
  |   },
  |   "config": {
  |     "timeout": 30000,
  |     "retry_max_attempts": 3,
  |     "rate_limit_per_minute": 60
  |   },
  |   "session_context": {
  |     "user_id": "user_123",
  |     "project_id": "project_456"
  |   }
  | }
  v
L03 Tool Executor injects credentials
  |
  | 1. Fetch actual credential values from Vault using refs
  | 2. Inject as environment variables in tool sandbox:
  |    - AWS_ACCESS_KEY_ID={value}
  |    - AWS_SECRET_ACCESS_KEY={value}
  |    - EXTERNAL_API_TOKEN={value}
  | 3. Tool process accesses via environment variables
  | 4. Credentials auto-expire after tool timeout
```

**Credential Rotation Handling (Gap G-003 from gap analysis, Q3 resolution):**
- **No mid-execution rotation:** Credentials fetched once at invocation start with lifespan = tool timeout
- **Ephemeral credentials:** Each invocation gets unique credentials that expire automatically
- **Rotation between invocations:** Next invocation fetches newly rotated credentials from Vault
- **Rationale:** Mid-execution rotation adds complexity without significant security benefit (short-lived credentials already limit exposure window)

---

### 6.6 MCP Tool Adapter Integration (Phase 13 Patterns)

**Note:** Phase 13 (Tool Registry with MCP adapter) is referenced in gap analysis. This section describes how L03 integrates with MCP-based tools.

**MCP Tool Discovery Pattern:**
```
L03 Tool Registry startup
  |
  | 1. Enumerate configured MCP servers (from config)
  |    - document-consolidator (Phase 15)
  |    - context-orchestrator (Phase 16)
  |    - custom-tools-mcp-server (example)
  v
L03 MCP Client connects to each server
  |
  | PM2 process: pm2 list
  | Ensure all MCP servers running, restart if crashed
  |
  | For each server:
  | 1. Open stdin/stdout pipes (stdio transport, ADR-001)
  | 2. Send JSON-RPC capability negotiation request:
  |    {"jsonrpc": "2.0", "method": "initialize", "params": {...}}
  | 3. Receive server capabilities:
  |    {"result": {"capabilities": {"tools": {...}, "resources": {...}}}}
  v
L03 MCP Client discovers tools
  |
  | Send JSON-RPC request:
  | {"jsonrpc": "2.0", "method": "tools/list", "params": {}}
  |
  | Receive tool schemas:
  | {
  |   "result": {
  |     "tools": [
  |       {
  |         "name": "get_source_of_truth",
  |         "description": "Retrieve authoritative document content",
  |         "inputSchema": {
  |           "type": "object",
  |           "properties": {
  |             "query": {"type": "string"},
  |             "document_id": {"type": "string"}
  |           }
  |         }
  |       }
  |     ]
  |   }
  | }
  v
L03 Tool Registry imports MCP tools
  |
  | For each tool:
  | 1. Transform MCP schema to internal tool manifest format
  | 2. Generate semantic embedding (Ollama) for tool description
  | 3. Insert into PostgreSQL tool_definitions table:
  |    - tool_id: "mcp:doc-bridge:get_source_of_truth"
  |    - source_type: "mcp"
  |    - source_metadata: {
  |        "mcp_server": "document-consolidator",
  |        "mcp_method": "tools/call",
  |        "tool_name": "get_source_of_truth"
  |      }
  | 4. Cache in Redis for fast lookup
  v
Agent invokes MCP tool via L03
  |
  | tool.invoke(tool_id="mcp:doc-bridge:get_source_of_truth", ...)
  |
  | L03 looks up tool in registry
  | Identifies source_type="mcp"
  | Routes to MCP Client
  |
  | MCP Client sends JSON-RPC:
  | {"jsonrpc": "2.0", "method": "tools/call", "params": {
  |   "name": "get_source_of_truth",
  |   "arguments": {"query": "authentication patterns", "document_id": "doc-123"}
  | }}
  |
  | Receives response:
  | {"result": {"content": [...], "isError": false}}
  |
  | L03 validates result, returns to agent
```

**MCP Server Health Monitoring:**
```
PM2 monitors MCP server processes
  |
  | - Auto-restart on crash (max 10 restarts per hour)
  | - Log stderr to PM2 logs
  | - Send SIGTERM for graceful shutdown
  v
L03 MCP Client health checks
  |
  | Every 60 seconds:
  | 1. Send JSON-RPC ping: {"jsonrpc": "2.0", "method": "ping"}
  | 2. Timeout: 5 seconds
  | 3. If no response, mark server unhealthy
  | 4. Retry capability negotiation
  | 5. If server recovered, re-discover tools
```

---

### 6.7 Phase 15 Document Bridge Integration

**Purpose:** Integrate with document-consolidator MCP server for authoritative document access during tool execution.

#### 6.7.1 MCP stdio Transport (ADR-001)

**Transport Configuration:**
```json
{
  "document_bridge": {
    "mcp_server": {
      "process_name": "document-consolidator",
      "command": "npx -y @anthropic-ai/mcp-server-document-consolidator",
      "args": ["--db-connection", "postgresql://..."],
      "transport": "stdio",
      "restart_policy": {
        "max_restarts": 10,
        "restart_window_seconds": 3600
      }
    }
  }
}
```

**PM2 Process Management:**
```bash
# Start MCP server via PM2
pm2 start "npx -y @anthropic-ai/mcp-server-document-consolidator" \
  --name "doc-bridge-mcp" \
  --interpreter node \
  --max-restarts 10 \
  --restart-delay 3000

# L03 opens stdin/stdout pipes
import subprocess
proc = subprocess.Popen(
    ["pm2", "logs", "doc-bridge-mcp", "--lines", "0", "--raw"],
    stdin=subprocess.PIPE,
    stdout=subprocess.PIPE,
    stderr=subprocess.PIPE
)

# Send JSON-RPC request on stdin
request = {
    "jsonrpc": "2.0",
    "id": "req-123",
    "method": "tools/call",
    "params": {
        "name": "get_source_of_truth",
        "arguments": {"query": "authentication patterns"}
    }
}
proc.stdin.write(json.dumps(request).encode() + b'\n')
proc.stdin.flush()

# Read JSON-RPC response from stdout
response = json.loads(proc.stdout.readline())
```

#### 6.7.2 Document Query Caching Strategy

**Two-Tier Caching:**

**Tier 1: Hot Cache (Redis)**
```
Key: doc:cache:get_source_of_truth:{hash(query)}
TTL: 300 seconds (5 minutes)
Value: {
  "document_id": "doc-123",
  "document_version": "v2.0",
  "content": "...",
  "metadata": {...},
  "cached_at": "2026-01-14T10:30:00Z"
}

Operations:
- Cache hit: Return cached content, extend TTL (refresh_on_read)
- Cache miss: Query MCP server, cache result
```

**Tier 2: Warm Cache (Local Process Memory)**
```python
# In-memory LRU cache for immutable document versions
from functools import lru_cache

@lru_cache(maxsize=1000)
def get_document_version(document_id: str, version: str) -> dict:
    """Cache immutable document versions locally."""
    # Version-specific documents never change, safe to cache indefinitely
    return mcp_client.call("get_document_metadata", {
        "document_id": document_id,
        "version": version
    })
```

**Cache Invalidation:**
```
L01 Data Layer publishes document updates
  |
  | Redis pub/sub channel: document:updates
  | Message: {"document_id": "doc-123", "operation": "update"}
  v
L03 Document Bridge subscribes
  |
  | On notification:
  | 1. Delete Redis cache keys matching document_id:
  |    DEL doc:cache:*:doc-123:*
  | 2. Invalidate local process cache (if version-agnostic query)
  | 3. Log cache invalidation event
```

**Caching Decision Matrix:**

| Query Type | Cacheable | Cache Tier | TTL | Invalidation |
|------------|-----------|------------|-----|--------------|
| `get_source_of_truth` (latest) | Yes | Redis | 5 min | Pub/sub on update |
| `get_source_of_truth` (specific version) | Yes | Local + Redis | Indefinite (immutable) | Never |
| `search_documents` | No | None | N/A | N/A (semantic search, always fresh) |
| `find_overlaps` | No | None | N/A | N/A (validation check, always fresh) |
| `get_document_metadata` | Yes | Redis | 10 min | Pub/sub on update |

**Gap Integration:**
- **G-013 (High):** Document access permission model implemented (see Section 6.4 ABAC Integration for permission checks before document retrieval).
- **G-014 (Medium):** Bulk document retrieval optimization via batched MCP requests (send array of document_ids in single JSON-RPC request).

#### 6.7.3 Error Handling for MCP Unavailability

**Three-Tier Fallback Strategy:**

**Tier 1: Primary (MCP Server)**
```python
try:
    result = mcp_client.call("get_source_of_truth", {
        "query": query,
        "timeout_ms": 30000
    })
    return result
except MCPTimeoutError:
    # MCP server not responding, try fallback
    pass
```

**Tier 2: Fallback (Cached Content)**
```python
# Check Redis cache for stale data (acceptable for reads)
cached = redis.get(f"doc:cache:get_source_of_truth:{hash(query)}")
if cached:
    logger.warning("MCP server unavailable, using cached document (may be stale)")
    return cached
```

**Tier 3: Direct PostgreSQL (Emergency)**
```python
# Direct query to PostgreSQL (bypass MCP)
# Limited to simple queries, no semantic search
conn = psycopg2.connect(postgresql_connection_string)
cursor = conn.cursor()
cursor.execute("""
    SELECT content, version FROM documents
    WHERE document_id = %s
    ORDER BY version DESC LIMIT 1
""", (document_id,))
result = cursor.fetchone()
if result:
    logger.error("MCP server and cache unavailable, using direct PostgreSQL read")
    return {"content": result[0], "version": result[1]}
```

**Failure Mode (All Tiers Failed):**
```python
# All fallbacks exhausted
raise DocumentUnavailableError(
    code="E3602",
    message="Document unavailable: MCP server down, cache miss, PostgreSQL unreachable",
    retryable=True,
    retry_after_seconds=60
)
```

**Monitoring & Alerting:**
```
Metrics:
- mcp_document_query_errors_total{tier="primary|fallback|emergency"}
- mcp_document_cache_hit_rate

Alerts:
- MCPServerDown: mcp_document_query_errors_total{tier="primary"} > 10 in 5 minutes
- DocumentCacheMissRate: mcp_document_cache_hit_rate < 0.5 for 15 minutes
```

---

### 6.8 Phase 16 State Bridge Integration

**Purpose:** Integrate with context-orchestrator MCP server for checkpoint-based state persistence and recovery.

#### 6.8.1 Checkpoint Creation Patterns

**Hybrid Checkpointing Strategy (Gap G-006 resolution):**

**Micro-Checkpoints (Redis, 30s intervals):**
```python
import asyncio

async def tool_executor_loop(tool_process, invocation_id):
    checkpoint_interval = 30  # seconds

    while tool_process.is_running():
        await asyncio.sleep(checkpoint_interval)

        # Capture tool state
        state = {
            "progress_percent": tool_process.get_progress(),
            "current_phase": tool_process.get_phase(),
            "counters": tool_process.get_counters(),
            "custom_state": tool_process.get_custom_state()
        }

        # Send to context-orchestrator via MCP
        await mcp_client.call("save_context_snapshot", {
            "taskId": invocation_id,
            "updates": {
                "immediateContext": {
                    "workingOn": state["current_phase"],
                    "lastAction": f"Progress {state['progress_percent']}%"
                },
                "keyFiles": [],
                "state": state
            },
            "syncToFile": False  # Skip file sync for micro-checkpoints
        })

        # Store in Redis (hot path)
        redis.setex(
            f"checkpoint:tool:{invocation_id}:latest",
            3600,  # TTL 1 hour
            json.dumps({
                "checkpoint_id": f"micro-{int(time.time())}",
                "invocation_id": invocation_id,
                "state": state,
                "timestamp": datetime.utcnow().isoformat()
            })
        )
```

**Macro-Checkpoints (PostgreSQL, event milestones):**
```python
class ToolExecutor:
    def on_milestone(self, milestone_name: str, invocation_id: str, state: dict):
        """Called when tool reaches important milestone."""

        # Send to context-orchestrator via MCP
        mcp_client.call("create_checkpoint", {
            "taskId": invocation_id,
            "label": f"{tool_id}-{milestone_name}",
            "checkpointType": "milestone",
            "description": f"Tool checkpoint at phase {milestone_name}",
            "sessionId": session_id
        })

        # Context-orchestrator stores in PostgreSQL
        # (handled by MCP server, L03 just triggers creation)

# Example milestones
tool_executor.on_milestone("parsing_complete", invocation_id, state)
tool_executor.on_milestone("validation_passed", invocation_id, state)
tool_executor.on_milestone("external_api_called", invocation_id, state)
```

**Named Checkpoints (manual recovery points):**
```python
# Tool code can request named checkpoint
def tool_create_checkpoint(checkpoint_name: str):
    """Tool API for creating named checkpoint."""
    mcp_client.call("create_checkpoint", {
        "taskId": current_invocation_id(),
        "label": checkpoint_name,
        "checkpointType": "manual",
        "description": f"User-requested checkpoint: {checkpoint_name}"
    })

# Example: Tool processing large dataset
for i, batch in enumerate(dataset_batches):
    process_batch(batch)

    if i % 10 == 0:  # Every 10 batches
        tool_create_checkpoint(f"batch_{i}_complete")
```

#### 6.8.2 State Serialization Format

**Checkpoint Schema:**
```json
{
  "$schema": "https://tool-execution-layer/schemas/checkpoint.json",
  "checkpoint_id": "cp-uuid-123",
  "invocation_id": "inv-uuid-456",
  "checkpoint_type": "micro | macro | named",
  "schema_version": "1.0",

  "state": {
    "progress_percent": 45,
    "current_phase": "processing",
    "counters": {
      "records_processed": 1500,
      "errors_encountered": 3
    },
    "custom_state": {
      "last_processed_id": "rec-789",
      "batch_number": 15
    }
  },

  "binary_refs": [
    {
      "key": "intermediate_results",
      "storage": "s3",
      "uri": "s3://tool-execution-checkpoints/inv-uuid-456/intermediate.parquet",
      "size_bytes": 5242880
    }
  ],

  "document_versions": {
    "doc-123": "v2.0",
    "doc-456": "v1.5"
  },

  "parent_checkpoint_id": "cp-uuid-122",
  "is_delta": true,

  "metadata": {
    "tool_id": "analyze_code",
    "tool_version": "2.1.0",
    "timestamp": "2026-01-14T10:30:30Z",
    "compressed": true,
    "compression_algorithm": "gzip"
  }
}
```

**Serialization Rules:**
1. **JSON for structured state:** Use JSON for progress, phase, counters, small custom state (< 1 MB)
2. **Base64 for small binaries:** Encode binaries < 1 MB as Base64 strings in `binary_refs[].data` field
3. **S3 references for large binaries:** Upload binaries >= 1 MB to S3, store URI in `binary_refs[].uri`
4. **Compression threshold:** Compress checkpoint if size > 10 KB (gzip recommended)
5. **Delta encoding:** If checkpoint > 100 KB, store only changed fields with `parent_checkpoint_id` reference

**Serialization Code Example:**
```python
import gzip
import json

def serialize_checkpoint(state: dict, parent_checkpoint_id: str = None) -> bytes:
    """Serialize tool state to checkpoint format."""

    checkpoint = {
        "checkpoint_id": str(uuid.uuid4()),
        "invocation_id": current_invocation_id(),
        "checkpoint_type": "micro",
        "schema_version": "1.0",
        "state": state,
        "timestamp": datetime.utcnow().isoformat()
    }

    # Delta encoding for large states (Gap G-015)
    if parent_checkpoint_id and len(json.dumps(state)) > 100 * 1024:  # > 100 KB
        parent_state = load_checkpoint(parent_checkpoint_id)["state"]
        checkpoint["state"] = compute_delta(parent_state, state)
        checkpoint["parent_checkpoint_id"] = parent_checkpoint_id
        checkpoint["is_delta"] = True

    # Serialize to JSON
    checkpoint_json = json.dumps(checkpoint)

    # Compress if > 10 KB (Gap G-016)
    if len(checkpoint_json) > 10 * 1024:
        checkpoint_bytes = gzip.compress(checkpoint_json.encode('utf-8'))
        checkpoint["metadata"]["compressed"] = True
        checkpoint["metadata"]["compression_algorithm"] = "gzip"
    else:
        checkpoint_bytes = checkpoint_json.encode('utf-8')

    return checkpoint_bytes
```

#### 6.8.3 Checkpoint Cleanup Policies

**Tiered Retention Policy:**

| Checkpoint Type | Storage | Hot Retention | Cold Retention | Archive Storage |
|-----------------|---------|---------------|----------------|-----------------|
| **Micro** | Redis | 1 hour (TTL) | N/A | N/A |
| **Macro** | PostgreSQL | 90 days | 7 years | S3 Glacier |
| **Named** | PostgreSQL | Indefinite | Indefinite | N/A |
| **Failed Execution** | PostgreSQL | 30 days | N/A | Deleted |

**Cleanup Job (Daily at 2 AM UTC):**
```sql
-- Delete expired micro-checkpoints (Redis TTL handles this automatically)
-- Redis: Automatic deletion when TTL expires

-- Archive macro-checkpoints > 90 days to S3 Glacier
INSERT INTO checkpoint_archive_queue (checkpoint_id, created_at)
SELECT checkpoint_id, created_at
FROM tool_checkpoints
WHERE checkpoint_type = 'macro'
  AND created_at < NOW() - INTERVAL '90 days'
  AND archived_at IS NULL;

-- Delete failed execution checkpoints > 30 days
DELETE FROM tool_checkpoints
WHERE invocation_id IN (
  SELECT invocation_id FROM tool_invocations WHERE status = 'error'
)
AND created_at < NOW() - INTERVAL '30 days';

-- Named checkpoints: Never auto-delete (manual cleanup only)
```

**S3 Glacier Archive Process:**
```python
import boto3

def archive_checkpoint(checkpoint_id: str):
    """Archive checkpoint to S3 Glacier."""

    # Load checkpoint from PostgreSQL
    conn = psycopg2.connect(postgresql_connection_string)
    cursor = conn.cursor()
    cursor.execute(
        "SELECT state, state_compressed FROM tool_checkpoints WHERE checkpoint_id = %s",
        (checkpoint_id,)
    )
    result = cursor.fetchone()

    # Upload to S3 Glacier
    s3 = boto3.client('s3')
    s3.put_object(
        Bucket='tool-execution-checkpoints-archive',
        Key=f'{checkpoint_id}.json.gz',
        Body=result[1] if result[1] else result[0],
        StorageClass='GLACIER'
    )

    # Update PostgreSQL with archive location
    cursor.execute(
        "UPDATE tool_checkpoints SET archived_at = NOW(), archived_to = %s WHERE checkpoint_id = %s",
        (f's3://tool-execution-checkpoints-archive/{checkpoint_id}.json.gz', checkpoint_id)
    )
    conn.commit()

    # Delete from PostgreSQL hot storage (keep metadata only)
    cursor.execute(
        "UPDATE tool_checkpoints SET state = NULL, state_compressed = NULL WHERE checkpoint_id = %s",
        (checkpoint_id,)
    )
    conn.commit()
```

---

## Section 7: Reliability and Scalability

### 7.1 Availability Targets (SLOs)

| Service Component | Availability Target | Latency Target (P95) | Latency Target (P99) | Error Budget |
|-------------------|---------------------|----------------------|----------------------|--------------|
| **tool.invoke()** (sync, < 30s) | 99.5% | 500ms | 1000ms | 0.5% (216 min/month) |
| **tool.invoke()** (async, > 30s) | 99.9% | N/A (async) | N/A (async) | 0.1% (43 min/month) |
| **tool.list()** | 99.9% | 50ms | 100ms | 0.1% |
| **tool.status()** | 99.9% | 10ms | 20ms | 0.1% |
| **Permission Check** (ABAC query) | 99.95% | 50ms | 100ms | 0.05% |
| **Document Query** (Phase 15) | 99.5% | 200ms | 500ms | 0.5% |
| **Checkpoint Creation** (Phase 16) | 99.9% | 50ms | 100ms | 0.1% |
| **Circuit Breaker State Update** | 99.99% | 10ms | 20ms | 0.01% |

**SLO Calculation Example:**
```
Monthly availability budget: 30 days * 24 hours * 60 minutes = 43,200 minutes
Error budget (99.9%): 43,200 * 0.001 = 43.2 minutes of downtime allowed per month
```

**SLI (Service Level Indicator) Metrics:**
```
Availability SLI = (Total requests - Failed requests) / Total requests

Latency SLI (P95) = 95th percentile latency < target

Example:
- Total tool.invoke() requests: 1,000,000
- Failed requests (5xx errors): 500
- Availability: (1,000,000 - 500) / 1,000,000 = 99.95% âœ“ (exceeds 99.5% target)
```

---

### 7.2 Scaling Model

**Horizontal Scaling Strategy:**

```
+========================================================================+
|                    Horizontal Scaling Architecture                     |
+========================================================================+

Load Balancer (L11 Integration Layer)
  |
  | Round-robin / Least-connections
  |
  +------+------+------+------+
  |      |      |      |      |
  v      v      v      v      v
+----+ +----+ +----+ +----+ +----+
|L03 | |L03 | |L03 | |L03 | |L03 |  Tool Execution Layer instances
|Inst| |Inst| |Inst| |Inst| |Inst|  (stateless, horizontally scalable)
| 1  | | 2  | | 3  | | 4  | | 5  |
+----+ +----+ +----+ +----+ +----+
  |      |      |      |      |
  +------+------+------+------+
  |
  v
+========================================================================+
|                      Shared Stateful Services                          |
+========================================================================+
| PostgreSQL (Tool Registry, Checkpoints) - Primary/Replica              |
| Redis Cluster (Circuit Breaker State, Cache) - 3 nodes                |
| Kafka Cluster (Event Stream) - 3 brokers                              |
| HashiCorp Vault (Secrets) - HA cluster                                |
+========================================================================+
```

**Scaling Triggers:**

| Metric | Scale Up Threshold | Scale Down Threshold | Cooldown Period |
|--------|-------------------|---------------------|-----------------|
| **CPU Utilization** | > 70% for 5 minutes | < 30% for 10 minutes | 5 minutes |
| **Memory Utilization** | > 80% for 5 minutes | < 40% for 10 minutes | 5 minutes |
| **Active Tool Executions** | > 80% of capacity | < 40% of capacity | 5 minutes |
| **Request Queue Depth** | > 100 requests | < 20 requests | 3 minutes |

**Capacity Per Instance:**
- **Concurrent tool executions:** 20 (per instance)
- **CPU:** 4 cores (8 vCPUs)
- **Memory:** 16 GB
- **Network:** 1 Gbps

**Scaling Calculation:**
```
Required instances = ceil(Peak concurrent tools / Tools per instance)

Example:
- Peak concurrent tools: 150
- Tools per instance: 20
- Required instances: ceil(150 / 20) = 8 instances
- Recommended instances (with 20% headroom): 8 * 1.2 = 10 instances
```

**Auto-Scaling Configuration (Kubernetes HPA):**
```yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: tool-execution-layer-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: tool-execution-layer
  minReplicas: 3  # Minimum for HA
  maxReplicas: 20  # Maximum for cost control
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
  - type: Pods
    pods:
      metric:
        name: tool_executions_active
      target:
        type: AverageValue
        averageValue: "16"  # 80% of 20 capacity
  behavior:
    scaleDown:
      stabilizationWindowSeconds: 300  # 5 min cooldown
      policies:
      - type: Percent
        value: 50  # Scale down max 50% at a time
        periodSeconds: 60
    scaleUp:
      stabilizationWindowSeconds: 0  # Immediate scale up
      policies:
      - type: Percent
        value: 100  # Scale up max 100% (double) at a time
        periodSeconds: 60
      - type: Pods
        value: 4  # Or add max 4 pods at a time
        periodSeconds: 60
      selectPolicy: Max  # Take the larger of the two policies
```

---

### 7.3 High Availability Patterns

#### 7.3.1 Circuit Breaker Failover

**Pattern:** When primary external API circuit breaker opens, failover to secondary API.

```python
class ExternalAPIManager:
    def call_with_failover(self, primary_api: str, secondary_api: str, request: dict):
        """Call external API with circuit breaker failover."""

        # Check primary circuit breaker state
        primary_circuit = circuit_breaker_controller.get_state(primary_api)

        if primary_circuit == "open":
            logger.warning(f"Primary API {primary_api} circuit open, using secondary {secondary_api}")
            return self._call_api(secondary_api, request)

        try:
            # Attempt primary API
            return self._call_api(primary_api, request)
        except CircuitBreakerOpenError:
            # Circuit opened during call, failover to secondary
            logger.warning(f"Primary API {primary_api} failed, failing over to {secondary_api}")
            return self._call_api(secondary_api, request)
        except ExternalAPIError as e:
            # Primary API error, record failure and failover
            circuit_breaker_controller.record_failure(primary_api)
            logger.error(f"Primary API {primary_api} error: {e}, failing over to {secondary_api}")
            return self._call_api(secondary_api, request)
```

**Failover Decision Matrix:**

| Primary State | Secondary State | Action | Rationale |
|---------------|-----------------|--------|-----------|
| Closed | Any | Use primary | Primary healthy, prefer primary |
| Open | Closed | Use secondary | Primary unhealthy, secondary healthy |
| Open | Open | Return error | Both unhealthy, fail gracefully |
| Open | Half-open | Use secondary (test) | Secondary testing recovery |
| Half-open | Closed | Use primary (test) | Primary testing recovery |

---

#### 7.3.2 Tool Registry Replication (PostgreSQL HA)

**Pattern:** PostgreSQL primary-replica replication with automatic failover.

```
+========================================================================+
|                PostgreSQL High Availability                            |
+========================================================================+

                      +------------------+
                      | PostgreSQL       |
                      | Primary          |
                      | (Read-Write)     |
                      +------------------+
                         |          |
                         | Sync     | Async
                         | Repl     | Repl
                         v          v
            +------------------+  +------------------+
            | PostgreSQL       |  | PostgreSQL       |
            | Replica 1        |  | Replica 2        |
            | (Read-Only)      |  | (Read-Only)      |
            +------------------+  +------------------+

Failover Manager (Patroni / pg_auto_failover)
  |
  | Monitors health via pg_isready
  | On primary failure:
  | 1. Promote Replica 1 to primary
  | 2. Reconfigure Replica 2 to replicate from new primary
  | 3. Update connection pooler (PgBouncer) endpoints
  v
+========================================================================+
| L03 Tool Registry uses PgBouncer connection pooler                     |
| - Automatic failover (no application changes)                          |
| - Read queries distributed to replicas                                |
| - Write queries to primary                                            |
+========================================================================+
```

**Connection String Configuration:**
```yaml
tool_registry:
  postgresql:
    # PgBouncer connection pooler (frontend for failover)
    connection_string: "postgresql://pgbouncer:6432/tool_registry"

    # Direct connections (for admin/backup)
    primary: "postgresql://postgres-primary:5432/tool_registry"
    replicas:
      - "postgresql://postgres-replica-1:5432/tool_registry"
      - "postgresql://postgres-replica-2:5432/tool_registry"

    # Connection pool settings
    pool_size: 20
    max_overflow: 10
    pool_timeout: 30
```

**Read/Write Split:**
```python
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker

# Write engine (primary only)
write_engine = create_engine("postgresql://pgbouncer:6432/tool_registry")

# Read engine (round-robin across replicas)
read_engines = [
    create_engine("postgresql://postgres-replica-1:5432/tool_registry"),
    create_engine("postgresql://postgres-replica-2:5432/tool_registry")
]

def get_tool_manifest(tool_id: str):
    """Read from replica (read-only query)."""
    engine = random.choice(read_engines)
    session = sessionmaker(bind=engine)()
    return session.query(ToolDefinition).filter_by(tool_id=tool_id).first()

def register_tool(tool_manifest: dict):
    """Write to primary (write query)."""
    session = sessionmaker(bind=write_engine)()
    tool = ToolDefinition(**tool_manifest)
    session.add(tool)
    session.commit()
```

---

#### 7.3.3 Redis Cluster for Circuit Breaker State

**Pattern:** Redis Cluster with 3 master nodes + 3 replicas for distributed circuit breaker state.

```
+========================================================================+
|                     Redis Cluster (Circuit Breaker State)              |
+========================================================================+

Master 1 (Slots 0-5460)       Master 2 (Slots 5461-10922)   Master 3 (Slots 10923-16383)
      |                              |                              |
      | Replication                  | Replication                  | Replication
      v                              v                              v
Replica 1                        Replica 2                        Replica 3

Hash Slot Calculation:
  circuit_key = "circuit:state:api.example.com"
  slot = CRC16(circuit_key) % 16384
  Master node = determine_master_from_slot(slot)

Automatic Failover:
  - If Master 1 fails, Replica 1 promoted to master
  - Cluster reconfigures automatically
  - L03 clients receive MOVED redirection
```

**Redis Cluster Configuration:**
```yaml
circuit_breaker:
  redis:
    cluster:
      nodes:
        - host: redis-master-1.cluster.local
          port: 7000
        - host: redis-master-2.cluster.local
          port: 7001
        - host: redis-master-3.cluster.local
          port: 7002
        - host: redis-replica-1.cluster.local
          port: 7003
        - host: redis-replica-2.cluster.local
          port: 7004
        - host: redis-replica-3.cluster.local
          port: 7005
      connection_pool_size: 10
      max_redirections: 3  # Max MOVED redirections before error
      read_from_replicas: true  # Read from replicas for load distribution
```

**Python Redis Cluster Client:**
```python
from redis.cluster import RedisCluster

redis_cluster = RedisCluster(
    startup_nodes=[
        {"host": "redis-master-1.cluster.local", "port": 7000},
        {"host": "redis-master-2.cluster.local", "port": 7001},
        {"host": "redis-master-3.cluster.local", "port": 7002}
    ],
    decode_responses=True,
    skip_full_coverage_check=False,  # Ensure all slots covered
    max_connections_per_node=10
)

# Circuit breaker state operations (automatically sharded across masters)
redis_cluster.set("circuit:state:api.example.com", json.dumps({
    "state": "open",
    "failure_count": 32,
    "opened_at": datetime.utcnow().isoformat()
}))

# Read from replica (if read_from_replicas=true)
state = redis_cluster.get("circuit:state:api.example.com")
```

---

#### 7.3.4 Stateless Executor Design

**Pattern:** L03 Tool Executor instances are completely stateless. All state stored in external systems (Redis, PostgreSQL, S3).

**Stateless Design Principles:**
1. **No local state:** Tool execution state stored in Phase 16 checkpoints (Redis/PostgreSQL), not in executor memory
2. **Any-instance resumability:** Tool invocation can be resumed on any L03 instance after failure
3. **Graceful shutdown:** On instance termination, checkpoint current tool state, allow resume on another instance
4. **Session affinity not required:** Load balancer can route requests to any instance

**Graceful Shutdown Handler:**
```python
import signal
import sys

def graceful_shutdown_handler(signum, frame):
    """Handle SIGTERM for graceful shutdown."""
    logger.info("Received SIGTERM, initiating graceful shutdown")

    # 1. Stop accepting new tool invocations
    stop_accepting_requests()

    # 2. Checkpoint all running tools
    for invocation_id, tool_process in running_tools.items():
        logger.info(f"Checkpointing tool {invocation_id}")
        try:
            # Create checkpoint (Phase 16)
            state = tool_process.capture_state()
            mcp_client.call("create_checkpoint", {
                "taskId": invocation_id,
                "label": "graceful_shutdown",
                "checkpointType": "manual"
            })
        except Exception as e:
            logger.error(f"Failed to checkpoint tool {invocation_id}: {e}")

    # 3. Wait for running tools to finish (max 30 seconds)
    deadline = time.time() + 30
    while time.time() < deadline and running_tools:
        time.sleep(1)

    # 4. Force kill remaining tools (state already checkpointed)
    for invocation_id, tool_process in running_tools.items():
        logger.warning(f"Force killing tool {invocation_id}")
        tool_process.kill()

    # 5. Close connections
    postgresql_pool.close()
    redis_client.close()
    kafka_producer.close()

    logger.info("Graceful shutdown complete")
    sys.exit(0)

# Register signal handlers
signal.signal(signal.SIGTERM, graceful_shutdown_handler)
signal.signal(signal.SIGINT, graceful_shutdown_handler)
```

**Resume After Instance Failure:**
```python
def resume_tool_from_checkpoint(invocation_id: str):
    """Resume tool execution from last checkpoint (any instance)."""

    # 1. Load latest checkpoint from Redis (or PostgreSQL if Redis expired)
    checkpoint = load_latest_checkpoint(invocation_id)

    if not checkpoint:
        raise CheckpointNotFoundError(f"No checkpoint found for {invocation_id}")

    # 2. Restore tool state
    tool_manifest = get_tool_manifest(checkpoint["tool_id"], checkpoint["tool_version"])

    # 3. Create new sandbox (on current instance)
    sandbox = create_tool_sandbox(
        agent_context=checkpoint["agent_context"],
        resource_limits=checkpoint["resource_limits"]
    )

    # 4. Inject credentials (fresh from Vault)
    credentials = retrieve_credentials(checkpoint["tool_id"], checkpoint["agent_context"])
    sandbox.inject_credentials(credentials)

    # 5. Restore document context (Phase 15)
    if checkpoint.get("document_versions"):
        document_context = restore_document_context(checkpoint["document_versions"])
        sandbox.inject_document_context(document_context)

    # 6. Start tool with restored state
    tool_process = sandbox.start_tool(
        tool_binary=tool_manifest["binary_path"],
        parameters=checkpoint["parameters"],
        initial_state=checkpoint["state"]
    )

    # 7. Continue checkpointing (Phase 16)
    start_checkpoint_loop(tool_process, invocation_id)

    logger.info(f"Resumed tool {invocation_id} from checkpoint {checkpoint['checkpoint_id']}")

    return tool_process
```

---

### 7.4 Capacity Planning

**Capacity Model:**

| Resource | Formula | Example Calculation |
|----------|---------|---------------------|
| **L03 Instances** | `ceil(Peak concurrent tools / Tools per instance)` | `ceil(500 / 20) = 25 instances` |
| **PostgreSQL Storage** | `(Tool manifests Ã— 100 KB) + (Checkpoints Ã— 500 KB Ã— Retention days)` | `(1000 Ã— 100 KB) + (10000 Ã— 500 KB Ã— 90) = 450 GB` |
| **Redis Memory** | `(Circuit states Ã— 10 KB) + (Checkpoints Ã— 100 KB Ã— TTL hours)` | `(100 Ã— 10 KB) + (5000 Ã— 100 KB Ã— 1) = 500 MB` |
| **Kafka Storage** | `(Events per day Ã— 5 KB Ã— Retention days)` | `(1M Ã— 5 KB Ã— 7) = 35 GB` |
| **S3 Archive** | `(Checkpoints Ã— 500 KB Ã— 7 years)` | `(10000 per day Ã— 500 KB Ã— 2555 days) = 12.8 TB` |

**Growth Projections:**

| Period | Tool Invocations/Day | Concurrent Tools (Peak) | Required Instances | PostgreSQL Storage | Redis Memory |
|--------|----------------------|-------------------------|--------------------|--------------------|--------------|
| **Month 1** | 100,000 | 50 | 3 | 50 GB | 100 MB |
| **Month 6** | 500,000 | 250 | 13 | 250 GB | 500 MB |
| **Year 1** | 1,000,000 | 500 | 25 | 500 GB | 1 GB |
| **Year 2** | 5,000,000 | 2500 | 125 | 2.5 TB | 5 GB |

**Capacity Alerts:**
```yaml
alerts:
  - name: CapacityNearLimit
    condition: tool_executions_active / tool_execution_capacity > 0.8
    severity: warning
    message: "Tool execution capacity at 80%, consider scaling"

  - name: PostgreSQLStorageNearFull
    condition: postgresql_storage_used_percent > 85
    severity: warning
    message: "PostgreSQL storage at 85%, expand disk or archive checkpoints"

  - name: RedisMemoryNearFull
    condition: redis_memory_used_percent > 90
    severity: critical
    message: "Redis memory at 90%, scale up or reduce checkpoint TTL"
```

---

### 7.5 Performance Budgets

**Latency Budget Breakdown (tool.invoke, P95):**

| Component | Budget | Measurement Point | Optimization Strategy |
|-----------|--------|-------------------|----------------------|
| **Load Balancer** | 5ms | L11 -> L03 | Connection pooling, keepalive |
| **Permission Check** | 50ms | ABAC query + cache lookup | Redis caching (95% hit rate target) |
| **Tool Registry Lookup** | 20ms | PostgreSQL query | Index on tool_id, pgvector pre-warming |
| **Credential Retrieval** | 30ms | Vault API call | Local caching (5-min TTL) |
| **Document Context (Phase 15)** | 100ms | MCP query + cache | Redis caching (80% hit rate target) |
| **Sandbox Creation** | 150ms | gVisor setup | Warm pool (pre-created sandboxes) |
| **Tool Execution** | 100ms | Tool binary runtime | Tool-specific optimization |
| **Result Validation** | 20ms | JSON Schema validation | Pre-compiled schemas, streaming validation |
| **Event Publishing** | 10ms | Kafka produce | Async fire-and-forget |
| **Response Serialization** | 15ms | JSON encoding | Protocol buffers for large payloads |
| **Total** | **500ms** (P95 target) | | |

**Optimization Techniques:**

1. **Redis Caching:** Cache permission decisions (5-min TTL), document content (5-min TTL), tool manifests (indefinite for immutable data)
2. **Connection Pooling:** PostgreSQL connection pool (20 connections per instance), Redis connection pool (10 connections per instance)
3. **Warm Sandboxes:** Pre-create 10 sandboxes per instance, allocate on-demand (reduces 150ms cold start to 10ms)
4. **Async Event Publishing:** Fire-and-forget Kafka produce (don't block on acknowledgment)
5. **Pre-compiled Schemas:** Load and compile JSON Schemas at startup, reuse validator instances
6. **Batch Operations:** Batch document queries (Phase 15), batch permission checks (if multiple tools)

---

### 7.6 Long-Running Operations (Gap G-004, Q2/Q6 Resolution)

**Challenge:** Tools that take > 30 seconds (e.g., data analysis, report generation, multi-step workflows) block L11 Integration Layer if synchronous.

**Solution:** Hybrid execution mode with Phase 16 checkpointing.

#### 7.6.1 Async Execution Patterns (Gap G-004)

**Pattern 1: Polling-Based Async (for tools 30s - 15 min)**
```
L11 Integration Layer
  |
  | 1. tool.invoke(async_mode=true)
  v
L03 Tool Execution Layer
  |
  | 2. Create tool sandbox, start execution
  | 3. Immediate response:
  |    ToolInvokeResponse(
  |      status="running",
  |      polling_info={
  |        "status_url": "/api/v1/tool/status/{invocation_id}",
  |        "estimated_completion_seconds": 120
  |      }
  |    )
  v
L11 polls tool.status()
  |
  | Every 5 seconds:
  | GET /api/v1/tool/status/{invocation_id}
  |
  | Response:
  | {
  |   "invocation_id": "...",
  |   "status": "running",
  |   "progress_percent": 45,
  |   "current_phase": "processing batch 15/30"
  | }
  v
L03 completes execution
  |
  | Final tool.status() response:
  | {
  |   "invocation_id": "...",
  |   "status": "success",
  |   "result": {...},
  |   "execution_metadata": {...}
  | }
```

**Pattern 2: Webhook Callback (for tools 15 min - 24 hours)**
```
L11 Integration Layer
  |
  | 1. tool.invoke(
  |      async_mode=true,
  |      execution_options={
  |        "callback_url": "https://l11.example.com/tool-callback"
  |      }
  |    )
  v
L03 Tool Execution Layer
  |
  | 2. Immediate response: status="pending", invocation_id
  | 3. Start tool execution in background
  | 4. Checkpoint every 30 seconds (Phase 16 micro-checkpoints)
  | 5. On completion, POST to callback_url:
  |    {
  |      "invocation_id": "...",
  |      "status": "success",
  |      "result": {...}
  |    }
  v
L11 callback handler
  |
  | Receives webhook, resumes workflow
```

**Pattern 3: Job Queue (for batch processing, > 24 hours)**
```
L11 Integration Layer
  |
  | 1. Enqueue job: redis.lpush("tool:job:queue", invocation_id)
  v
L03 Worker Pool (dedicated long-running instances)
  |
  | 2. Worker dequeues: invocation_id = redis.brpop("tool:job:queue")
  | 3. Load tool manifest, create sandbox
  | 4. Execute tool with checkpointing (every 60 seconds for long jobs)
  | 5. On completion, publish event: tool.succeeded
  v
L11 event consumer
  |
  | Subscribes to tool.succeeded events, resumes workflow
```

**Execution Mode Decision Tree:**
```
Tool execution time?
  |
  +-- < 30 seconds -----> Synchronous execution (default)
  |
  +-- 30s - 15 minutes -> Async with polling (Pattern 1)
  |
  +-- 15 min - 24 hours -> Async with webhook (Pattern 2)
  |
  +-- > 24 hours --------> Job queue with worker pool (Pattern 3)
```

#### 7.6.2 Progress Callbacks

**Purpose:** Allow long-running tools to report progress for UI display and monitoring.

**Implementation:**
```python
class ToolProgressReporter:
    """Tool API for reporting progress during execution."""

    def __init__(self, invocation_id: str, mcp_client: MCPClient):
        self.invocation_id = invocation_id
        self.mcp_client = mcp_client

    def report_progress(self, percent: int, phase: str, message: str = ""):
        """Report progress to L03 (stored in checkpoint)."""

        # Update checkpoint with progress
        self.mcp_client.call("save_context_snapshot", {
            "taskId": self.invocation_id,
            "updates": {
                "immediateContext": {
                    "workingOn": phase,
                    "lastAction": message
                },
                "progress_percent": percent
            }
        })

        # Publish progress event (for real-time UI updates)
        event_publisher.publish_progress_update(
            invocation_id=self.invocation_id,
            percent=percent,
            phase=phase,
            message=message
        )

# Tool code example
progress = ToolProgressReporter(invocation_id, mcp_client)

for i, batch in enumerate(data_batches):
    process_batch(batch)

    percent = int((i + 1) / len(data_batches) * 100)
    progress.report_progress(
        percent=percent,
        phase="processing",
        message=f"Processed batch {i+1}/{len(data_batches)}"
    )
```

**Progress Event Schema (WebSocket/SSE for real-time UI):**
```json
{
  "event": "tool.progress",
  "invocation_id": "inv-uuid-123",
  "timestamp": "2026-01-14T10:35:00Z",
  "data": {
    "progress_percent": 45,
    "current_phase": "processing",
    "message": "Processed batch 15/30",
    "estimated_completion_seconds": 75
  }
}
```

#### 7.6.3 Resume After Failure

**Scenario:** Tool execution fails due to timeout, crash, or instance failure. Resume from last checkpoint without reprocessing.

**Resume Flow:**
```
Tool execution fails at T=90s (progress=45%)
  |
  | 1. L03 detects failure (timeout, process crash, instance down)
  | 2. Publish tool.failed event
  | 3. Tool invocation marked as "failed" in PostgreSQL
  | 4. Latest checkpoint preserved (micro-checkpoint at T=90s)
  v
L11 Integration Layer decides to retry
  |
  | tool.invoke(
  |   tool_id="analyze_data",
  |   checkpoint_config={
  |     "resume_from_checkpoint_id": "cp-uuid-123"  # Last checkpoint ID
  |   }
  | )
  v
L03 resumes from checkpoint
  |
  | 1. Load checkpoint (cp-uuid-123) from Redis or PostgreSQL
  | 2. Deserialize state: {progress_percent: 45, current_phase: "processing", ...}
  | 3. Create new sandbox
  | 4. Inject credentials (fresh from Vault)
  | 5. Restore document context (Phase 15, using document_versions from checkpoint)
  | 6. Start tool with restored state
  | 7. Tool resumes from batch 15 (skips batches 1-14)
  | 8. Continue checkpointing every 30s
  v
Tool completes successfully
  |
  | Final result includes:
  | - execution_metadata.resumed_from_checkpoint: "cp-uuid-123"
  | - execution_metadata.total_duration_ms: 120000 (initial 90s + resumed 30s)
  | - execution_metadata.checkpoint_recovery_time_ms: 5000
```

**Resume Limitations & Best Practices:**
- **Idempotency required:** Tools must be idempotent (running twice produces same result)
- **External side effects:** Tools with non-idempotent external calls (e.g., charging credit card) should checkpoint *after* side effect
- **Checkpoint granularity:** Balance frequency (30s) vs overhead (serialization cost)
- **State size limits:** Keep checkpoint state < 1 MB (use S3 for large intermediate results)

**Gap Integration:**
- **G-004 (High):** Async execution patterns fully specified (polling, webhook, job queue).
- **G-021 (Medium):** Tool dependency graph resolution implemented via workflow DAG in L11 (L03 executes individual tools, L11 orchestrates dependencies).
- **G-022 (Medium):** HITL approval timeout policies defined (see Section 7.6.4 below).

#### 7.6.4 Human-in-the-Loop (HITL) Approval Timeout (Gap G-022)

**Scenario:** Tool requires human approval before execution (high-risk operations like database writes, financial transactions).

**HITL Flow:**
```
L11 invokes tool with require_approval=true
  |
  | tool.invoke(
  |   tool_id="delete_production_database",
  |   execution_options={"require_approval": true}
  | )
  v
L03 enters pending_approval state
  |
  | 1. Check tool manifest: requires_approval=true
  | 2. Create approval request:
  |    - invocation_id, tool_id, parameters (sanitized)
  |    - approvers: [primary_approver, escalation_manager, fallback_admin]
  |    - timeout_hierarchy: [1 hour, 4 hours, 24 hours]
  | 3. Send notification to primary_approver (email, Slack, webhook)
  | 4. Generate approval token (JWT with expiration)
  | 5. Return ToolInvokeResponse(status="pending_approval", approval_token)
  v
Primary approver responds
  |
  | Option A: Approved within 1 hour
  | - POST /api/v1/tool/approve/{invocation_id}
  | - Headers: Authorization: Bearer {approval_token}
  | - L03 starts tool execution
  |
  | Option B: Timeout after 1 hour
  | - Escalate to escalation_manager
  | - New approval token generated (expiration +4 hours)
  | - Notification sent
  |
  | Option C: Manager approves within 4 hours
  | - Tool execution starts
  |
  | Option D: Timeout after 4 hours (5 hours total)
  | - Escalate to fallback_admin
  | - New approval token generated (expiration +24 hours)
  | - Notification sent
  |
  | Option E: Admin approves within 24 hours (29 hours total)
  | - Tool execution starts
  |
  | Option F: Final timeout after 24 hours (29 hours total)
  | - Tool invocation cancelled automatically
  | - Publish tool.failed event (error_code="approval_timeout")
  | - Notify requester (agent or user)
```

**Timeout Hierarchy Configuration:**
```json
{
  "hitl_approval": {
    "timeout_hierarchy": [
      {
        "level": "primary",
        "approvers": ["user.primary@example.com"],
        "timeout_hours": 1,
        "notification_channels": ["email", "slack"]
      },
      {
        "level": "escalation",
        "approvers": ["manager.escalation@example.com"],
        "timeout_hours": 4,
        "notification_channels": ["email", "slack", "sms"]
      },
      {
        "level": "fallback",
        "approvers": ["admin.fallback@example.com"],
        "timeout_hours": 24,
        "notification_channels": ["email", "sms", "phone"]
      }
    ],
    "final_action_on_timeout": "cancel",  # "cancel" or "auto_approve" (dangerous)
    "approval_token_signature_algorithm": "RS256"
  }
}
```

**Approval Token Schema (JWT):**
```json
{
  "header": {"alg": "RS256", "typ": "JWT"},
  "payload": {
    "invocation_id": "inv-uuid-123",
    "tool_id": "delete_production_database",
    "approver": "user.primary@example.com",
    "approval_level": "primary",
    "exp": 1673980800,  # 1 hour from issuance
    "iat": 1673977200,
    "iss": "l03-tool-execution"
  },
  "signature": "..."
}
```

**Gap Integration:**
- **G-022 (Medium):** HITL approval timeout and escalation policies fully specified with three-tier hierarchy (primary 1h, escalation 4h, fallback 24h).

---

## Section 8: Security

### 8.1 Security Architecture

**Trust Boundaries:**

```
+========================================================================+
|                    Tool Execution Layer Trust Boundaries               |
+========================================================================+

                     EXTERNAL ZONE (Untrusted)
+========================================================================+
| - Internet                                                             |
| - External APIs (api.example.com)                                      |
| - Third-party services                                                 |
+========================================================================+
                           |
                           | Trust Boundary TB-1
                           | (Firewall, Network Policy)
                           v
                     DMZ ZONE (Controlled)
+========================================================================+
| L11 Integration Layer                                                  |
| - Workflow orchestration                                               |
| - Multi-agent coordination                                             |
+========================================================================+
                           |
                           | Trust Boundary TB-2
                           | (BC-2 Interface, Capability Tokens)
                           v
                  TOOL EXECUTION ZONE (Restricted)
+========================================================================+
| L03 Tool Execution Layer                                               |
| +------------------------------------------------------------------+   |
| | Permission Checker (validates capability tokens)                 |   |
| +------------------------------------------------------------------+   |
|                           |
|                           | Trust Boundary TB-3
|                           | (ABAC Policy, Permission Cache)
|                           v
| +------------------------------------------------------------------+   |
| | Tool Executor                                                    |   |
| |   +----------------------------------------------------------+   |   |
| |   | Agent Sandbox (from L02, BC-1)                           |   |   |
| |   |   +--------------------------------------------------+   |   |   |
| |   |   | Tool Sandbox (nested, gVisor/Firecracker)       |   |   |   |
| |   |   | - Tool Process (untrusted code)                  |   |   |   |
| |   |   | - Filesystem isolation: /workspace/tool1 only    |   |   |   |
| |   |   | - Network isolation: api.example.com:443 only    |   |   |   |
| |   |   | - Credentials injected as env vars (ephemeral)   |   |   |   |
| |   |   +--------------------------------------------------+   |   |   |
| |   |                                                          |   |   |
| |   |   Trust Boundary TB-4 (Nested Sandbox, BC-1)            |   |   |
| |   +----------------------------------------------------------+   |   |
| +------------------------------------------------------------------+   |
|                           |
|                           | Trust Boundary TB-5
|                           | (MCP stdio pipes, process isolation)
|                           v
| +------------------------------------------------------------------+   |
| | MCP Bridges (Phase 15/16)                                        |   |
| | - document-consolidator (stdio, PM2 managed)                     |   |
| | - context-orchestrator (stdio, PM2 managed)                      |   |
| +------------------------------------------------------------------+   |
+========================================================================+
                           |
                           | Trust Boundary TB-6
                           | (Database credentials, encrypted connections)
                           v
                    DATA LAYER ZONE (Trusted)
+========================================================================+
| L01 Agentic Data Layer                                                 |
| - PostgreSQL (tool registry, checkpoints)                              |
| - Redis (circuit breaker state, cache)                                |
| - HashiCorp Vault (secrets)                                            |
| - Kafka (audit events)                                                 |
+========================================================================+
```

**Trust Boundary Descriptions:**

| Boundary | Crossing Point | Security Controls | Threat Mitigation |
|----------|----------------|-------------------|-------------------|
| **TB-1** | Internet -> L11 | Firewall, TLS, API authentication (OAuth 2.0) | DDoS, unauthorized access |
| **TB-2** | L11 -> L03 | Capability tokens (JWT RS256), BC-2 interface validation | Spoofing, unauthorized tool invocation |
| **TB-3** | Permission Checker -> Tool Executor | ABAC policy enforcement, permission cache invalidation | Privilege escalation, unauthorized resource access |
| **TB-4** | Agent Sandbox -> Tool Sandbox | Nested isolation (BC-1), resource limits, network/filesystem policies | Sandbox escape, resource exhaustion |
| **TB-5** | Tool Executor -> MCP Bridges | stdio pipes (process-level isolation), PM2 supervision, timeout enforcement | MCP server compromise, privilege escalation |
| **TB-6** | MCP Bridges -> Data Layer | Encrypted connections (TLS), database credentials in Vault, connection pooling | Credential theft, data exfiltration |

---

### 8.2 Authentication

**DID-Based Caller Validation:**

```
L11 sends ToolInvokeRequest
  |
  | - agent_context.agent_did: "did:agent:xyz789"
  | - capability_token: "eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9..."
  v
L03 Permission Checker validates
  |
  | Step 1: Resolve DID Document
  | - Query L01 DID Registry: GET /api/v1/did/resolve/{agent_did}
  | - Verify DID status: active (not revoked, not expired)
  | - Extract public key from verificationMethod[0].publicKeyJwk
  |
  | Step 2: Validate JWT signature
  | - Decode JWT header, payload, signature
  | - Verify signature using public key (RSA-SHA256)
  | - Check JWT claims:
  |   * exp: expiration timestamp > now()
  |   * iat: issued timestamp <= now()
  |   * iss: issuer == "l02-agent-runtime" (trusted issuer)
  |   * agent_did: matches request.agent_context.agent_did
  |
  | Step 3: Validate JWT claims (tool permissions)
  | - tool_id: matches request.tool_id
  | - tool_version: compatible with request.tool_version (SemVer)
  | - allowed_operations: contains "execute"
  | - filesystem_permissions: subset of agent permissions (BC-1)
  | - network_permissions: subset of agent permissions (BC-1)
  |
  | Step 4: Check revocation list
  | - Query Redis: get("token:revocation:{jti}")
  | - If exists, token revoked -> deny access (E3208)
  v
Authentication successful -> proceed to ABAC check
```

**Token Revocation:**
```python
def revoke_capability_token(token_jti: str, revocation_reason: str):
    """Revoke a capability token (e.g., on agent compromise)."""

    # Add to revocation list in Redis
    redis.setex(
        f"token:revocation:{token_jti}",
        86400,  # TTL 24 hours (max token lifetime)
        json.dumps({
            "revoked_at": datetime.utcnow().isoformat(),
            "reason": revocation_reason
        })
    )

    # Publish revocation event (for cache invalidation)
    redis.publish("token:revocations", json.dumps({
        "jti": token_jti,
        "reason": revocation_reason
    }))

    logger.warning(f"Revoked capability token {token_jti}: {revocation_reason}")
```

---

### 8.3 Authorization

**ABAC Integration (see Section 6.4):**

Authorization decisions delegated to L01 ABAC Engine with permission caching in Redis (5-min TTL). Permission checks include:
- **Filesystem access:** Tool requests `/workspace/tool1`, ABAC verifies agent allowed to write to `/workspace`
- **Network access:** Tool requests `api.example.com:443`, ABAC verifies agent allowed to connect to `api.example.com`
- **Credential access:** Tool requests `aws_s3_read`, ABAC verifies agent authorized for AWS S3 read access

**Policy Example (OPA Rego):**
```rego
package tool_execution

# Allow tool execution if all permissions granted
allow {
    input.action == "execute"
    input.resource_type == "tool"

    # Agent must have tool execution permission
    agent_policies[input.agent_id].tools[_] == input.resource_id

    # Filesystem permissions must be subset of agent permissions
    filesystem_allowed

    # Network permissions must be subset of agent permissions
    network_allowed

    # Credential permissions must be granted
    credentials_allowed
}

filesystem_allowed {
    every path in input.context.filesystem_paths {
        some allowed_path in agent_policies[input.agent_id].filesystem_paths
        startswith(path, allowed_path)
    }
}

network_allowed {
    every endpoint in input.context.network_endpoints {
        some allowed_host in agent_policies[input.agent_id].network_hosts
        endpoint == allowed_host
    }
}

credentials_allowed {
    every cred in input.context.credentials {
        agent_policies[input.agent_id].credentials[_] == cred
    }
}
```

---

### 8.4 Secrets Management

#### 8.4.1 External API Credential Storage (ADR-002)

**Storage:** HashiCorp Vault (not PostgreSQL directly, for security).

**Vault Path Structure:**
```
secret/tool-execution/
  â”œâ”€â”€ tools/
  â”‚   â”œâ”€â”€ analyze_code/
  â”‚   â”‚   â”œâ”€â”€ github_api_token
  â”‚   â”‚   â””â”€â”€ sonarqube_token
  â”‚   â”œâ”€â”€ send_email/
  â”‚   â”‚   â””â”€â”€ smtp_password
  â”‚   â””â”€â”€ call_external_api/
  â”‚       â”œâ”€â”€ api_key
  â”‚       â””â”€â”€ api_secret
  â”œâ”€â”€ mcp_servers/
  â”‚   â”œâ”€â”€ document-consolidator/
  â”‚   â”‚   â””â”€â”€ postgresql_password
  â”‚   â””â”€â”€ context-orchestrator/
  â”‚       â”œâ”€â”€ postgresql_password
  â”‚       â””â”€â”€ redis_password
  â””â”€â”€ infrastructure/
      â”œâ”€â”€ postgresql_connection_string
      â”œâ”€â”€ redis_connection_string
      â””â”€â”€ kafka_sasl_password
```

**Vault Configuration:**
```hcl
# Enable KV v2 secrets engine
vault secrets enable -path=secret kv-v2

# Create policy for L03 Tool Execution Layer
path "secret/data/tool-execution/tools/*" {
  capabilities = ["read"]
}

path "secret/data/tool-execution/mcp_servers/*" {
  capabilities = ["read"]
}

path "secret/data/tool-execution/infrastructure/*" {
  capabilities = ["read"]
}

# Attach policy to L03 service account (Kubernetes auth)
vault write auth/kubernetes/role/tool-execution-role \
    bound_service_account_names=tool-execution \
    bound_service_account_namespaces=production \
    policies=tool-execution-policy \
    ttl=1h
```

#### 8.4.2 Credential Rotation (Q3 Resolution)

**Rotation Strategy:**
- **Ephemeral credentials:** Each tool invocation generates fresh credentials with lifespan = tool timeout
- **No mid-execution rotation:** Credentials remain valid for entire invocation duration
- **Rotation between invocations:** Vault dynamic secrets engine rotates credentials daily
- **Manual rotation trigger:** On credential compromise, rotate immediately via Vault API

**Vault Dynamic Secrets (AWS Example):**
```hcl
# Enable AWS secrets engine
vault secrets enable -path=aws aws

# Configure AWS credentials (Vault uses these to generate dynamic credentials)
vault write aws/config/root \
    access_key=AKIAIOSFODNN7EXAMPLE \
    secret_key=wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY \
    region=us-east-1

# Create role for tool execution (generates temporary credentials)
vault write aws/roles/tool-execution-s3-read \
    credential_type=iam_user \
    policy_document=-<<EOF
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Action": "s3:GetObject",
      "Resource": "arn:aws:s3:::example-bucket/*"
    }
  ]
}
EOF
```

**Credential Retrieval at Invocation Time:**
```python
def retrieve_tool_credentials(tool_id: str, credential_name: str, ttl_seconds: int):
    """Retrieve ephemeral credentials from Vault."""

    vault_client = hvac.Client(url=vault_url, token=vault_token)

    # Generate dynamic AWS credentials (valid for tool timeout duration)
    response = vault_client.secrets.aws.generate_credentials(
        name='tool-execution-s3-read',
        role_arn='arn:aws:iam::123456789012:role/tool-execution',
        ttl=f'{ttl_seconds}s'
    )

    credentials = {
        'AWS_ACCESS_KEY_ID': response['data']['access_key'],
        'AWS_SECRET_ACCESS_KEY': response['data']['secret_key'],
        'AWS_SESSION_TOKEN': response['data']['security_token']  # if using STS
    }

    logger.info(f"Generated ephemeral credentials for {tool_id}, TTL {ttl_seconds}s")

    return credentials
```

**Manual Rotation on Compromise:**
```python
def rotate_credential_on_compromise(credential_path: str):
    """Immediately rotate credential on detection of compromise."""

    vault_client = hvac.Client(url=vault_url, token=vault_token)

    # 1. Revoke all active leases for this credential
    vault_client.sys.revoke_prefix(prefix=f'aws/creds/{credential_path}')

    # 2. Rotate root credentials (if applicable)
    vault_client.write(f'aws/config/rotate-root')

    # 3. Publish credential rotation event (invalidate caches)
    redis.publish('credential:rotations', json.dumps({
        'credential_path': credential_path,
        'rotated_at': datetime.utcnow().isoformat(),
        'reason': 'compromise_detected'
    }))

    # 4. Alert security team
    send_alert(
        severity='critical',
        message=f'Credential {credential_path} rotated due to compromise'
    )

    logger.critical(f"Emergency rotation of credential {credential_path}")
```

#### 8.4.3 Credential Injection into Tool Sandbox

**Injection Method:** Environment variables (sandboxed, not visible outside tool process).

```python
def inject_credentials_into_sandbox(sandbox: ToolSandbox, tool_id: str,
                                    required_credentials: List[str],
                                    timeout_seconds: int):
    """Inject ephemeral credentials as environment variables."""

    env_vars = {}

    for credential_name in required_credentials:
        # Retrieve ephemeral credentials from Vault
        credentials = retrieve_tool_credentials(tool_id, credential_name, timeout_seconds)

        # Add to sandbox environment
        env_vars.update(credentials)

    # Inject into sandbox (only visible to tool process)
    sandbox.set_environment_variables(env_vars)

    logger.info(f"Injected {len(required_credentials)} credentials into sandbox for {tool_id}")

    # Credentials automatically expire after timeout_seconds (Vault lease expiration)
```

**Credential Lifecycle:**
```
Tool invocation starts
  |
  | 1. Query tool manifest for required_credentials: ["aws_s3_read"]
  | 2. Retrieve ephemeral credentials from Vault (TTL = tool timeout)
  | 3. Inject as environment variables in sandbox
  v
Tool process accesses credentials
  |
  | import os
  | aws_access_key = os.getenv('AWS_ACCESS_KEY_ID')
  | aws_secret_key = os.getenv('AWS_SECRET_ACCESS_KEY')
  |
  | # Use credentials for S3 access
  | s3 = boto3.client('s3',
  |     aws_access_key_id=aws_access_key,
  |     aws_secret_access_key=aws_secret_key)
  v
Tool execution completes
  |
  | 1. Sandbox destroyed (environment variables cleared)
  | 2. Vault lease expires (credentials auto-revoked)
  | 3. Credentials no longer valid
```

#### 8.4.4 MCP Service Credentials

**Storage:** Vault path `secret/tool-execution/mcp_servers/{server_name}/`

**MCP Server Authentication:**
```python
def start_mcp_server_with_credentials(server_name: str):
    """Start MCP server with credentials from Vault."""

    vault_client = hvac.Client(url=vault_url, token=vault_token)

    # Retrieve MCP server credentials
    credentials = vault_client.secrets.kv.v2.read_secret_version(
        path=f'tool-execution/mcp_servers/{server_name}'
    )['data']['data']

    # Start MCP server process via PM2 with credentials as env vars
    subprocess.run([
        'pm2', 'start',
        f'npx -y @anthropic-ai/mcp-server-{server_name}',
        '--name', f'{server_name}-mcp',
        '--',
        '--db-connection', credentials['postgresql_connection_string'],
        '--redis-connection', credentials['redis_connection_string']
    ], env={
        'POSTGRESQL_PASSWORD': credentials['postgresql_password'],
        'REDIS_PASSWORD': credentials['redis_password']
    })

    logger.info(f"Started MCP server {server_name} with credentials from Vault")
```

---

### 8.5 Network Security

**Tool-Specific Network Allowlists:**

```python
# Tool manifest defines allowed network endpoints
tool_manifest = {
    "tool_id": "analyze_code",
    "permissions": {
        "network": [
            {"host": "api.github.com", "port": 443},
            {"host": "api.sonarqube.org", "port": 443}
        ]
    }
}

# L03 enforces network policy in sandbox
def create_network_policy(tool_manifest: dict, agent_network_policy: NetworkPolicy):
    """Create tool-specific network policy (subset of agent policy)."""

    tool_allowed_hosts = [net["host"] for net in tool_manifest["permissions"]["network"]]
    agent_allowed_hosts = agent_network_policy.allowed_hosts

    # Tool network access must be subset of agent network access (BC-1)
    if not set(tool_allowed_hosts).issubset(set(agent_allowed_hosts)):
        raise PermissionDeniedError(
            "Tool network access exceeds agent network policy"
        )

    # Create Kubernetes NetworkPolicy CRD
    network_policy = {
        "apiVersion": "networking.k8s.io/v1",
        "kind": "NetworkPolicy",
        "metadata": {
            "name": f"tool-{tool_manifest['tool_id']}-network-policy"
        },
        "spec": {
            "podSelector": {
                "matchLabels": {"tool_invocation_id": invocation_id}
            },
            "policyTypes": ["Egress"],
            "egress": [
                {
                    "to": [{"dnsName": host}],
                    "ports": [{"protocol": "TCP", "port": port}]
                }
                for host, port in [(net["host"], net["port"])
                                  for net in tool_manifest["permissions"]["network"]]
            ]
        }
    }

    # Apply to Kubernetes cluster
    k8s_client.create_namespaced_network_policy(namespace="tools", body=network_policy)

    return network_policy
```

**Network Monitoring:**
```python
# Monitor network connections from tool sandbox
def monitor_sandbox_network_connections(sandbox_id: str):
    """Log all network connections for audit."""

    # Use eBPF or tcpdump to capture connections
    connections = []

    for conn in sandbox.get_network_connections():
        connections.append({
            "timestamp": conn.timestamp,
            "source_ip": conn.source_ip,
            "dest_ip": conn.dest_ip,
            "dest_host": conn.dest_host,
            "dest_port": conn.dest_port,
            "bytes_sent": conn.bytes_sent,
            "bytes_received": conn.bytes_received
        })

    # Log to audit stream
    audit_logger.log_network_connections(
        invocation_id=invocation_id,
        connections=connections
    )

    # Alert on unexpected connections
    allowed_hosts = tool_manifest["permissions"]["network"]
    for conn in connections:
        if conn["dest_host"] not in [h["host"] for h in allowed_hosts]:
            alert_security_team(
                severity="high",
                message=f"Tool {tool_id} attempted unauthorized connection to {conn['dest_host']}"
            )
```

---

### 8.6 Threat Model (STRIDE Analysis)

#### 8.6.1 Spoofing: Tool Invocation Identity

**Threat:** Attacker impersonates agent to invoke tools without authorization.

**Mitigation:**
- Capability tokens (JWT RS256) signed by trusted issuer (L02 Agent Runtime)
- DID-based authentication (agent DID resolved and verified)
- Token revocation list in Redis (detect stolen tokens)

**Residual Risk:** LOW (strong cryptographic signatures, revocation mechanism)

---

#### 8.6.2 Tampering: Tool Result Manipulation, Checkpoint Tampering

**Threat:** Attacker modifies tool results or checkpoints to corrupt agent decision-making.

**Mitigation (Tool Result):**
- Result validation (JSON Schema, type safety, sanitization)
- Checksums for large binary results (S3 stored results)
- Audit trail (immutable event log in Kafka)

**Mitigation (Checkpoint):**
- Checkpoint signatures (HMAC-SHA256 with secret key from Vault)
- PostgreSQL audit logging (who modified checkpoint, when)
- Checkpoint version history (detect tampering via version inconsistencies)

**Residual Risk:** LOW (multiple validation layers, audit trail)

---

#### 8.6.3 Repudiation: Audit Trail Integrity

**Threat:** Attacker denies tool invocation or deletes audit logs to hide malicious activity.

**Mitigation:**
- Immutable audit log (Kafka write-only, 90-day retention enforced)
- Cryptographic signatures on audit events (CloudEvents with signatures)
- External SIEM integration (logs replicated to external system)
- PostgreSQL audit logging (separate from application logs)

**Residual Risk:** VERY LOW (immutable logs, external replication)

---

#### 8.6.4 Information Disclosure: Credential Leakage, Document Context Leakage

**Threat:** Attacker extracts credentials or document content from tool sandbox or logs.

**Mitigation (Credential Leakage):**
- Ephemeral credentials (auto-expire after tool timeout)
- Credentials injected as environment variables (not visible outside sandbox)
- PII sanitization in audit logs (Gap G-017, see Section 9.2)
- Vault audit logging (detect credential access patterns)

**Mitigation (Document Context):**
- Document access permissions (ABAC check before retrieval)
- Document version pinning (no leakage of latest documents)
- Encrypted connections (TLS for MCP stdio pipes? No, stdio is local)

**Residual Risk:** LOW (ephemeral credentials, sanitized logs)

---

#### 8.6.5 Denial of Service: Tool Exhaustion Attacks, MCP Service Overload

**Threat:** Attacker floods L03 with tool invocations to exhaust resources or overload MCP servers.

**Mitigation (Tool Exhaustion):**
- Rate limiting per agent/tenant (token bucket algorithm, Redis counters)
- Resource quotas per agent (CPU, memory, timeout limits via BC-1)
- Circuit breakers (prevent cascading failures to external APIs)
- Auto-scaling (Kubernetes HPA, scale up on high load)

**Mitigation (MCP Overload):**
- MCP request timeouts (30s for document queries, 10s for checkpoints)
- MCP request rate limiting (max 100 requests/second per MCP server)
- MCP server health monitoring (auto-restart on crash, alert on high error rate)
- Fallback to cached data (Phase 15 document cache, stale data acceptable for reads)

**Residual Risk:** MEDIUM (auto-scaling helps, but sophisticated DoS can overwhelm)

---

#### 8.6.6 Elevation of Privilege: Sandbox Escape, MCP Privilege Escalation

**Threat:** Attacker escapes tool sandbox to access agent sandbox or host system. Attacker compromises MCP server to access L01 data layer.

**Mitigation (Sandbox Escape):**
- gVisor/Firecracker isolation (strong isolation, syscall filtering)
- Nested sandbox (BC-1, tool sandbox within agent sandbox)
- Resource limits (cgroups enforce CPU, memory, timeout limits)
- Regular security updates (patch gVisor/Firecracker vulnerabilities)

**Mitigation (MCP Privilege Escalation):**
- MCP servers run with least-privilege service accounts (no root access)
- MCP stdio transport (process-level isolation, no network exposure)
- PM2 supervision (restart on crash, log stderr for forensics)
- Database credentials scoped per MCP server (document-consolidator cannot access context-orchestrator data)

**Residual Risk:** LOW (strong isolation technologies, defense in depth)

---

## Section 9: Observability

### 9.1 Metrics (Prometheus Format)

**Metric Definitions:**

```python
# Tool invocation metrics
tool_invocations_total = Counter(
    'tool_invocations_total',
    'Total tool invocations',
    ['tool_id', 'tool_version', 'status']  # Labels
)

tool_execution_duration_seconds = Histogram(
    'tool_execution_duration_seconds',
    'Tool execution duration in seconds',
    ['tool_id'],
    buckets=[0.1, 0.5, 1, 5, 10, 30, 60, 120, 300]  # Buckets for percentile calculation
)

tool_executions_active = Gauge(
    'tool_executions_active',
    'Number of currently executing tools',
    ['instance']
)

# Circuit breaker metrics
circuit_breaker_state = Gauge(
    'circuit_breaker_state',
    'Circuit breaker state (0=closed, 1=open, 2=half-open)',
    ['external_service']
)

circuit_breaker_transitions_total = Counter(
    'circuit_breaker_transitions_total',
    'Total circuit breaker state transitions',
    ['external_service', 'from_state', 'to_state']
)

# External API metrics
external_api_requests_total = Counter(
    'external_api_requests_total',
    'Total external API requests',
    ['service', 'status_code']
)

external_api_request_duration_seconds = Histogram(
    'external_api_request_duration_seconds',
    'External API request duration',
    ['service'],
    buckets=[0.05, 0.1, 0.25, 0.5, 1, 2.5, 5, 10]
)

# Permission check metrics
permission_checks_total = Counter(
    'permission_checks_total',
    'Total permission checks',
    ['result']  # allowed, denied, error
)

permission_check_duration_seconds = Histogram(
    'permission_check_duration_seconds',
    'Permission check duration',
    [],
    buckets=[0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1]
)

# Phase 15: MCP document query metrics
mcp_document_queries_total = Counter(
    'mcp_document_queries_total',
    'Total MCP document queries',
    ['operation', 'status']  # operation: get_source_of_truth, search_documents
)

mcp_document_cache_hit_rate = Gauge(
    'mcp_document_cache_hit_rate',
    'Document cache hit rate (0-1)',
    []
)

# Phase 16: MCP checkpoint operation metrics
mcp_checkpoint_operations_total = Counter(
    'mcp_checkpoint_operations_total',
    'Total MCP checkpoint operations',
    ['operation', 'checkpoint_type']  # operation: create, restore, rollback
)

mcp_checkpoint_size_bytes = Histogram(
    'mcp_checkpoint_size_bytes',
    'Checkpoint size in bytes',
    ['checkpoint_type'],
    buckets=[1024, 10240, 102400, 1048576, 10485760]  # 1KB, 10KB, 100KB, 1MB, 10MB
)
```

**Metrics Endpoint:**
```
GET /metrics

# HELP tool_invocations_total Total tool invocations
# TYPE tool_invocations_total counter
tool_invocations_total{tool_id="analyze_code",tool_version="2.1.0",status="success"} 15234
tool_invocations_total{tool_id="analyze_code",tool_version="2.1.0",status="error"} 127
tool_invocations_total{tool_id="send_email",tool_version="1.0.0",status="success"} 8921

# HELP tool_execution_duration_seconds Tool execution duration in seconds
# TYPE tool_execution_duration_seconds histogram
tool_execution_duration_seconds_bucket{tool_id="analyze_code",le="0.1"} 0
tool_execution_duration_seconds_bucket{tool_id="analyze_code",le="0.5"} 234
tool_execution_duration_seconds_bucket{tool_id="analyze_code",le="1"} 1203
tool_execution_duration_seconds_bucket{tool_id="analyze_code",le="5"} 8921
tool_execution_duration_seconds_bucket{tool_id="analyze_code",le="10"} 14567
tool_execution_duration_seconds_bucket{tool_id="analyze_code",le="30"} 15234
tool_execution_duration_seconds_sum{tool_id="analyze_code"} 89123.45
tool_execution_duration_seconds_count{tool_id="analyze_code"} 15234

# HELP circuit_breaker_state Circuit breaker state (0=closed, 1=open, 2=half-open)
# TYPE circuit_breaker_state gauge
circuit_breaker_state{external_service="api.github.com"} 0
circuit_breaker_state{external_service="api.sonarqube.org"} 1
```

---

### 9.2 Logging (Structured Log Format)

**Log Format (JSON):**
```json
{
  "timestamp": "2026-01-14T10:35:00.123Z",
  "level": "info",
  "logger": "tool-execution-layer",
  "message": "Tool invocation completed successfully",
  "context": {
    "invocation_id": "inv-uuid-123",
    "tool_id": "analyze_code",
    "tool_version": "2.1.0",
    "agent_did": "did:agent:xyz789",
    "tenant_id": "tenant_acme",
    "duration_ms": 12340,
    "status": "success"
  },
  "trace_id": "trace-abc-456",
  "span_id": "span-def-789"
}
```

**PII Sanitization Rules (Gap G-017):**

```python
import re

def sanitize_pii(data: dict) -> dict:
    """Sanitize PII from tool parameters and results before logging."""

    sanitized = data.copy()

    # Regex patterns for common PII
    patterns = {
        'email': r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b',
        'ssn': r'\b\d{3}-\d{2}-\d{4}\b',
        'credit_card': r'\b\d{4}[- ]?\d{4}[- ]?\d{4}[- ]?\d{4}\b',
        'phone': r'\b\d{3}[-.]?\d{3}[-.]?\d{4}\b',
        'ip_address': r'\b\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}\b',
        'api_key': r'\b[A-Za-z0-9]{32,}\b',  # Generic API key pattern
        'jwt_token': r'\beyJ[A-Za-z0-9_-]+\.eyJ[A-Za-z0-9_-]+\.[A-Za-z0-9_-]+\b'
    }

    # Field-based sanitization (known PII fields)
    pii_fields = ['password', 'secret', 'token', 'apiKey', 'api_key', 'credit_card', 'ssn']

    for key, value in sanitized.items():
        if isinstance(value, str):
            # Regex-based sanitization
            for pii_type, pattern in patterns.items():
                if re.search(pattern, value):
                    value = re.sub(pattern, f'[REDACTED_{pii_type.upper()}]', value)

            # Field-based sanitization
            if key.lower() in pii_fields:
                value = '[REDACTED]'

            sanitized[key] = value

        elif isinstance(value, dict):
            sanitized[key] = sanitize_pii(value)  # Recursive

        elif isinstance(value, list):
            sanitized[key] = [sanitize_pii(item) if isinstance(item, dict) else item
                             for item in value]

    return sanitized

# Example usage
tool_parameters = {
    "user_email": "user@example.com",
    "api_key": "sk_live_51H1x1hK4a1l1kl1l1l1l1l1",
    "repository_url": "https://github.com/example/repo",
    "credit_card": "4532-1234-5678-9010"
}

sanitized_parameters = sanitize_pii(tool_parameters)
# Result:
# {
#   "user_email": "[REDACTED_EMAIL]",
#   "api_key": "[REDACTED]",
#   "repository_url": "https://github.com/example/repo",
#   "credit_card": "[REDACTED_CREDIT_CARD]"
# }

logger.info("Tool invocation started", extra={"parameters": sanitized_parameters})
```

**Gap Integration:**
- **G-017 (Critical):** PII sanitization rules implemented via regex patterns (email, SSN, credit card, phone, IP, API key, JWT) and field-based redaction (password, secret, token fields).

---

### 9.3 Tracing (OpenTelemetry Spans)

**Trace Hierarchy:**

```
tool.invoke (parent span)
  |
  +-- permission.check (child span)
  |    |
  |    +-- did.resolve (child span)
  |    +-- jwt.verify (child span)
  |    +-- abac.query (child span)
  |
  +-- tool_registry.lookup (child span)
  |
  +-- document_bridge.query (child span, Phase 15)
  |    |
  |    +-- mcp.get_source_of_truth (child span)
  |    +-- redis.cache_lookup (child span)
  |
  +-- sandbox.create (child span)
  |
  +-- tool.execute (child span)
  |    |
  |    +-- external_api.call (child span)
  |    |    |
  |    |    +-- circuit_breaker.check (child span)
  |    |    +-- rate_limiter.check (child span)
  |    |    +-- http.request (child span)
  |    |
  |    +-- checkpoint.create (child span, Phase 16)
  |         |
  |         +-- mcp.save_context_snapshot (child span)
  |         +-- redis.write (child span)
  |
  +-- result.validate (child span)
  |
  +-- event.publish (child span)
```

**Span Attributes:**

```python
from opentelemetry import trace
from opentelemetry.trace import Status, StatusCode

tracer = trace.get_tracer("tool-execution-layer")

def tool_invoke_with_tracing(request: ToolInvokeRequest):
    with tracer.start_as_current_span(
        "tool.invoke",
        attributes={
            "tool.id": request.tool_id,
            "tool.version": request.tool_version,
            "agent.did": request.agent_context.agent_did,
            "tenant.id": request.agent_context.tenant_id,
            "invocation.id": request.invocation_id,
            "async_mode": request.execution_options.async_mode
        }
    ) as span:
        try:
            # Permission check span
            with tracer.start_as_current_span("permission.check") as perm_span:
                permission_result = check_permissions(request)
                perm_span.set_attribute("permission.allowed", permission_result.allowed)

            # Document query span (Phase 15)
            if request.document_context:
                with tracer.start_as_current_span("document_bridge.query") as doc_span:
                    documents = query_documents(request.document_context)
                    doc_span.set_attribute("documents.count", len(documents))
                    doc_span.set_attribute("cache.hit", cache_hit)

            # Tool execution span
            with tracer.start_as_current_span("tool.execute") as exec_span:
                result = execute_tool(request)
                exec_span.set_attribute("execution.duration_ms", result.duration_ms)
                exec_span.set_attribute("execution.status", result.status)

            span.set_status(Status(StatusCode.OK))
            return result

        except Exception as e:
            span.set_status(Status(StatusCode.ERROR, str(e)))
            span.record_exception(e)
            raise
```

**Trace Sampling:**
- **Always sample:** Errors, timeouts, permission denials (100% sampling)
- **Head-based sampling:** 10% of successful invocations (reduce overhead)
- **Tail-based sampling:** Sample slow invocations (> P95 latency)

---

### 9.4 Alerting

**Alert Definitions (Prometheus Alertmanager):**

```yaml
groups:
  - name: tool_execution_alerts
    rules:
      # High tool failure rate
      - alert: HighToolFailureRate
        expr: |
          (
            sum(rate(tool_invocations_total{status="error"}[5m]))
            / sum(rate(tool_invocations_total[5m]))
          ) > 0.05
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High tool failure rate (> 5%)"
          description: "Tool invocation failure rate is {{ $value | humanizePercentage }} over the last 5 minutes"

      # Circuit breaker open
      - alert: CircuitBreakerOpen
        expr: circuit_breaker_state == 1
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: "Circuit breaker open for {{ $labels.external_service }}"
          description: "Circuit breaker has been open for 2 minutes, external service may be degraded"

      # External service degradation
      - alert: ExternalServiceDegradation
        expr: |
          (
            sum(rate(external_api_requests_total{status_code=~"5.."}[5m])) by (service)
            / sum(rate(external_api_requests_total[5m])) by (service)
          ) > 0.1
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "External service {{ $labels.service }} degraded (> 10% 5xx errors)"
          description: "Error rate is {{ $value | humanizePercentage }} for {{ $labels.service }}"

      # MCP service unavailable (Phase 15/16)
      - alert: MCPServiceUnavailable
        expr: |
          sum(rate(mcp_document_queries_total{status="error"}[5m])) > 10
          or
          sum(rate(mcp_checkpoint_operations_total{status="error"}[5m])) > 10
        for: 3m
        labels:
          severity: critical
        annotations:
          summary: "MCP service unavailable (Phase 15 or Phase 16)"
          description: "MCP service experiencing high error rate (> 10 errors/min for 3 minutes)"

      # Tool execution capacity warning
      - alert: ToolExecutionCapacityWarning
        expr: |
          (
            sum(tool_executions_active) by (instance)
            / 20  # Max concurrent tools per instance
          ) > 0.8
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Tool execution capacity at 80% on instance {{ $labels.instance }}"
          description: "Consider scaling up to handle increased load"

      # Permission check latency high
      - alert: PermissionCheckLatencyHigh
        expr: |
          histogram_quantile(0.95, rate(permission_check_duration_seconds_bucket[5m])) > 0.1
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Permission check P95 latency > 100ms"
          description: "P95 latency is {{ $value }}s, may indicate ABAC Engine or cache issues"
```

**Gap Integration:**
- **G-018 (High):** Audit log schema with CloudEvents 1.0 alignment implemented (see Section 4.3 event schemas).
- **G-019 (Medium):** Audit stream backpressure handling implemented via Kafka producer configuration (see below).

---

### 9.5 Dashboards (Grafana Dashboard Specs)

**Dashboard 1: Tool Execution Overview**

Panels:
1. **Total Tool Invocations (last 24h)** - Single stat
   - Query: `sum(increase(tool_invocations_total[24h]))`
2. **Tool Success Rate** - Gauge
   - Query: `sum(rate(tool_invocations_total{status="success"}[5m])) / sum(rate(tool_invocations_total[5m]))`
3. **Tool Invocations by Status** - Pie chart
   - Query: `sum by (status) (increase(tool_invocations_total[1h]))`
4. **Tool Execution Duration (P50, P95, P99)** - Graph
   - Query: `histogram_quantile(0.50, rate(tool_execution_duration_seconds_bucket[5m]))`
5. **Top 10 Tools by Invocation Count** - Bar chart
   - Query: `topk(10, sum by (tool_id) (increase(tool_invocations_total[1h])))`
6. **Active Tool Executions** - Graph over time
   - Query: `sum(tool_executions_active)`

**Dashboard 2: External API & Circuit Breakers**

Panels:
1. **Circuit Breaker States** - Status panel
   - Query: `circuit_breaker_state` (0=green, 1=red, 2=yellow)
2. **External API Request Rate** - Graph
   - Query: `sum by (service) (rate(external_api_requests_total[5m]))`
3. **External API Error Rate** - Graph
   - Query: `sum by (service) (rate(external_api_requests_total{status_code=~"5.."}[5m]))`
4. **External API Latency (P95)** - Graph
   - Query: `histogram_quantile(0.95, rate(external_api_request_duration_seconds_bucket[5m])) by (service)`
5. **Circuit Breaker Transitions** - Event list
   - Query: `increase(circuit_breaker_transitions_total[1h])`

**Dashboard 3: Phase 15/16 MCP Integration**

Panels:
1. **Document Query Cache Hit Rate** - Gauge
   - Query: `mcp_document_cache_hit_rate`
2. **MCP Document Queries by Operation** - Graph
   - Query: `sum by (operation) (rate(mcp_document_queries_total[5m]))`
3. **Checkpoint Operations by Type** - Stacked graph
   - Query: `sum by (checkpoint_type) (rate(mcp_checkpoint_operations_total[5m]))`
4. **Checkpoint Size Distribution** - Heatmap
   - Query: `histogram_quantile(0.95, rate(mcp_checkpoint_size_bytes_bucket[5m]))`
5. **MCP Service Errors** - Alert list
   - Query: `sum by (operation) (rate(mcp_document_queries_total{status="error"}[5m]))`

---

### 9.6 Audit Stream Backpressure Handling (Gap G-019)

**Challenge:** During high load, Kafka producer may fall behind, causing memory buildup in L03 instances.

**Solution: Backpressure Detection & Mitigation**

```python
from kafka import KafkaProducer
from kafka.errors import BufferError, KafkaTimeoutError

class BackpressureAwareAuditLogger:
    def __init__(self, kafka_bootstrap_servers: str):
        self.producer = KafkaProducer(
            bootstrap_servers=kafka_bootstrap_servers,
            acks='all',
            retries=3,
            linger_ms=10,  # Batch messages for efficiency
            buffer_memory=67108864,  # 64 MB buffer
            compression_type='gzip',  # Compress messages
            max_in_flight_requests_per_connection=5
        )

        self.backpressure_detected = False
        self.sampling_rate = 1.0  # 100% (no sampling initially)

    def publish_audit_event(self, event: dict):
        """Publish audit event with backpressure handling."""

        # Check buffer utilization (backpressure indicator)
        if self.producer.metrics()['buffer-available-bytes'] < 10485760:  # < 10 MB available
            self.detect_backpressure()
        else:
            self.clear_backpressure()

        # Apply sampling if backpressure detected
        if self.backpressure_detected:
            if random.random() > self.sampling_rate:
                # Drop event (log to local disk instead)
                self.log_to_local_disk(event)
                return

        try:
            # Attempt to send
            self.producer.send(
                topic='tool-execution-events',
                key=event['tenant_id'].encode('utf-8'),
                value=json.dumps(event).encode('utf-8')
            )

        except BufferError:
            # Buffer full, apply sampling
            self.detect_backpressure()
            self.log_to_local_disk(event)

        except KafkaTimeoutError:
            # Kafka unavailable, log locally
            logger.error("Kafka timeout, logging audit event to local disk")
            self.log_to_local_disk(event)

    def detect_backpressure(self):
        """Detect backpressure and apply mitigation."""
        if not self.backpressure_detected:
            self.backpressure_detected = True
            self.sampling_rate = 0.1  # Sample 10% of events
            logger.warning("Backpressure detected, reducing audit sampling to 10%")

            # Alert monitoring
            alert_ops_team(
                severity='warning',
                message='Audit event backpressure detected, sampling reduced to 10%'
            )

    def clear_backpressure(self):
        """Clear backpressure state."""
        if self.backpressure_detected:
            self.backpressure_detected = False
            self.sampling_rate = 1.0  # Resume 100% sampling
            logger.info("Backpressure cleared, resuming 100% audit sampling")

    def log_to_local_disk(self, event: dict):
        """Fallback: log event to local disk (process later)."""
        with open('/var/log/tool-execution/audit-backlog.jsonl', 'a') as f:
            f.write(json.dumps(event) + '\n')
```

**Backpressure Mitigation Strategies:**

| Strategy | Trigger | Action | Recovery |
|----------|---------|--------|----------|
| **Sampling** | Buffer < 10 MB available | Sample 10% of events (drop 90%) | Resume 100% when buffer > 50 MB |
| **Local Disk Buffering** | Kafka unavailable | Write events to local disk | Replay from disk when Kafka recovers |
| **Compression** | Always | gzip compress messages | Reduces network/storage by 70% |
| **Batching** | Always | Batch messages (linger_ms=10) | Reduces overhead, improves throughput |
| **Async Send** | Always | Fire-and-forget (don't block) | L03 continues execution |

**Gap Integration:**
- **G-019 (Medium):** Real-time audit stream backpressure handling implemented via buffer monitoring, sampling (10% during overload), local disk fallback, and alerting.

---

## Section 10: Configuration

### 10.1 Configuration Hierarchy

```
+========================================================================+
|                     Configuration Hierarchy                            |
+========================================================================+

Global Defaults (lowest priority)
  |
  | - default_timeout_seconds: 30
  | - default_cpu_millicore_limit: 500
  | - default_memory_mb_limit: 1024
  | - circuit_breaker_failure_threshold: 50%
  v
Per-Tool Configuration (overrides global)
  |
  | Tool Manifest:
  | - tool_id: "analyze_code"
  | - execution_config:
  |     timeout_seconds: 60  # Override global 30s
  |     cpu_millicore_limit: 1000  # Override global 500m
  v
Per-External-Service Configuration (overrides tool)
  |
  | External Service Config:
  | - service: "api.github.com"
  | - rate_limit_per_minute: 5000  # GitHub rate limit
  | - circuit_breaker_failure_threshold: 30%  # More sensitive
  v
MCP Bridge Configuration (overrides defaults)
  |
  | MCP Server Config:
  | - mcp_server: "document-consolidator"
  | - request_timeout_ms: 30000  # Override for document queries
  | - cache_ttl_seconds: 300  # 5-minute cache
  v
Runtime Overrides (highest priority)
  |
  | ToolInvokeRequest:
  | - resource_limits:
  |     timeout_seconds: 120  # Override for this specific invocation
  | - checkpoint_config:
  |     checkpoint_interval_seconds: 60  # Override for long-running tool
```

---

### 10.2 Configuration Schemas

#### 10.2.1 Tool Registry Configuration (ADR-002)

```yaml
tool_registry:
  postgresql:
    connection_string: "postgresql://user:password@postgres:5432/tool_registry"
    pool_size: 20
    max_overflow: 10
    pool_timeout: 30

  ollama:
    base_url: "http://ollama:11434"
    embedding_model: "mistral:7b"
    embedding_dimensions: 768
    timeout_seconds: 10

  semantic_search:
    similarity_threshold: 0.7  # Cosine similarity threshold
    max_results: 10

  version_retention:
    max_versions_per_tool: 5
    deprecation_warning_days: 90
```

#### 10.2.2 Circuit Breaker Configuration (ADR-002)

```yaml
circuit_breaker:
  redis:
    connection_string: "redis://redis-cluster:7000,redis-cluster:7001,redis-cluster:7002"
    cluster_mode: true
    max_redirections: 3

  notification_channel: "circuit:state:changes"

  default_config:
    failure_rate_threshold: 50  # Percent
    slow_call_rate_threshold: 100  # Percent
    slow_call_duration_threshold_ms: 5000
    sliding_window_type: "count_based"
    sliding_window_size: 100
    minimum_number_of_calls: 10
    wait_duration_in_open_state_seconds: 60
    permitted_number_of_calls_in_half_open_state: 10

  half_open_strategy: "canary"  # "canary" or "all_or_nothing"

  per_service_overrides:
    "api.github.com":
      failure_rate_threshold: 30  # More sensitive for critical service
      wait_duration_in_open_state_seconds: 30

    "api.example.com":
      failure_rate_threshold: 70  # Less sensitive for non-critical service
```

#### 10.2.3 Rate Limit Policies

```yaml
rate_limiting:
  redis:
    connection_string: "redis://redis-cluster:7000"

  algorithm: "token_bucket"  # "token_bucket", "leaky_bucket", "fixed_window", "sliding_window"

  default_policy:
    requests_per_minute: 60
    burst_size: 10

  per_tool_policies:
    "send_email":
      requests_per_minute: 10  # Limit email sending
      burst_size: 2

    "call_external_api":
      requests_per_minute: 100  # Higher limit for API calls
      burst_size: 20

  per_external_service_policies:
    "api.github.com":
      requests_per_minute: 5000  # GitHub's actual rate limit
      burst_size: 100

    "api.sendgrid.com":
      requests_per_minute: 600  # SendGrid rate limit
      burst_size: 10
```

#### 10.2.4 MCP Transport Configuration (ADR-001)

```yaml
mcp_bridges:
  document_bridge:
    mcp_server:
      process_name: "document-consolidator"
      command: "npx -y @anthropic-ai/mcp-server-document-consolidator"
      args:
        - "--db-connection"
        - "postgresql://..."
      transport: "stdio"
      startup_timeout_ms: 5000
      request_timeout_ms: 30000
      max_retries: 3

    cache:
      enabled: true
      redis_connection_string: "redis://redis:6379"
      hot_cache_ttl_seconds: 300  # 5 minutes
      metadata_cache_ttl_seconds: 600  # 10 minutes
      invalidation_channel: "document:updates"

    permissions:
      check_enabled: true
      abac_endpoint: "http://abac-engine:8080/v1/data/document_access/allow"

  state_bridge:
    mcp_server:
      process_name: "context-orchestrator"
      command: "npx -y @anthropic-ai/mcp-server-context-orchestrator"
      args:
        - "--db-connection"
        - "postgresql://..."
      transport: "stdio"
      startup_timeout_ms: 5000
      request_timeout_ms: 10000  # Faster for checkpoint operations

    checkpointing:
      micro_checkpoints:
        enabled: true
        interval_seconds: 30
        storage: "redis"
        ttl_seconds: 3600  # 1 hour

      macro_checkpoints:
        enabled: true
        storage: "postgresql"
        retention_days: 90
        archive_storage: "s3"
        archive_retention_years: 7

      named_checkpoints:
        enabled: true
        storage: "postgresql"
        retention: "indefinite"

    delta_encoding:
      enabled: true
      threshold_kb: 100

    compression:
      enabled: true
      algorithm: "gzip"
      threshold_kb: 10
```

---

### 10.3 Environment Variables

```bash
# PostgreSQL (Tool Registry, Checkpoints)
POSTGRESQL_CONNECTION_STRING="postgresql://user:password@postgres:5432/tool_registry"
POSTGRESQL_POOL_SIZE=20

# Redis (Circuit Breaker, Cache, Hot Checkpoints)
REDIS_CONNECTION_STRING="redis://redis-cluster:7000,redis-cluster:7001,redis-cluster:7002"
REDIS_CLUSTER_MODE=true

# HashiCorp Vault (Secrets)
VAULT_ADDR="https://vault.example.com:8200"
VAULT_TOKEN="s.xxxxxxxxxxxxxxxxxxxxxxxx"
VAULT_AUTH_METHOD="kubernetes"

# Kafka (Audit Events)
KAFKA_BOOTSTRAP_SERVERS="kafka-1:9092,kafka-2:9092,kafka-3:9092"
KAFKA_SASL_MECHANISM="PLAIN"
KAFKA_SASL_USERNAME="tool-execution"
KAFKA_SASL_PASSWORD="xxx"

# Ollama (Semantic Search)
OLLAMA_BASE_URL="http://ollama:11434"
OLLAMA_MODEL="mistral:7b"

# L01 Data Layer (ABAC, DID Registry)
ABAC_ENGINE_URL="http://abac-engine:8080"
DID_REGISTRY_URL="http://did-registry:8080"

# L02 Agent Runtime (BC-1)
AGENT_RUNTIME_URL="http://agent-runtime:8080"

# MCP Servers (Phase 15/16)
MCP_DOCUMENT_CONSOLIDATOR_ENABLED=true
MCP_CONTEXT_ORCHESTRATOR_ENABLED=true

# Observability
PROMETHEUS_PORT=9090
OTLP_EXPORTER_ENDPOINT="http://otel-collector:4317"
LOG_LEVEL="info"  # "debug", "info", "warning", "error"
LOG_FORMAT="json"  # "json" or "text"

# Security
JWT_PUBLIC_KEY_PATH="/etc/tool-execution/jwt-public-key.pem"
JWT_ALGORITHM="RS256"
```

---

### 10.4 Feature Flags

```yaml
feature_flags:
  # Tool-specific flags
  enable_tool_analyze_code: true
  enable_tool_send_email: false  # Disable tool globally
  enable_tool_delete_database: false  # High-risk tool, require explicit enable

  # Circuit breaker flags
  circuit_breaker_bypass_emergency: false  # DANGEROUS: bypass all circuit breakers

  # Rate limiting flags
  rate_limit_override_emergency: false  # DANGEROUS: disable rate limiting

  # Phase 15: Document context
  enable_document_context: true  # Enable/disable Phase 15 integration
  enable_document_cache: true  # Enable/disable document caching
  enable_document_version_pinning: true  # Enable/disable version pinning

  # Phase 16: Checkpointing
  enable_checkpointing: true  # Enable/disable Phase 16 integration
  enable_micro_checkpoints: true
  enable_macro_checkpoints: true
  enable_named_checkpoints: true
  enable_checkpoint_compression: true
  enable_checkpoint_delta_encoding: true

  # Observability
  enable_tracing: true
  enable_metrics: true
  enable_audit_logging: true

  # Experimental features
  enable_async_tool_execution: true
  enable_tool_priority_scheduling: true  # Gap G-005
  enable_warm_sandbox_pool: false  # Experimental, high memory usage
```

**Feature Flag Management:**
```python
from launchdarkly import LDClient

ld_client = LDClient(sdk_key=os.getenv('LAUNCHDARKLY_SDK_KEY'))

def is_tool_enabled(tool_id: str, tenant_id: str) -> bool:
    """Check if tool is enabled via feature flag."""

    flag_key = f"enable_tool_{tool_id}"
    context = {"key": tenant_id, "kind": "tenant"}

    return ld_client.variation(flag_key, context, default=True)

# Usage
if not is_tool_enabled("delete_database", tenant_id):
    raise ToolDisabledError(f"Tool delete_database is disabled for tenant {tenant_id}")
```

---

### 10.5 Hot Reload Capability

**Hot-Reloadable Configuration:**
- Tool definitions (add/remove tools without restart)
- Circuit breaker thresholds (adjust sensitivity without restart)
- Rate limit policies (adjust quotas without restart)
- Feature flags (enable/disable features without restart)

**Not Hot-Reloadable (require restart):**
- PostgreSQL connection string (database migration)
- Redis connection string (cache reset)
- MCP server configuration (process restart required)

**Hot Reload Implementation:**
```python
import signal

class ConfigurationManager:
    def __init__(self, config_path: str):
        self.config_path = config_path
        self.config = self.load_config()

        # Register signal handler for hot reload
        signal.signal(signal.SIGHUP, self.reload_config_handler)

    def load_config(self) -> dict:
        """Load configuration from file."""
        with open(self.config_path, 'r') as f:
            return yaml.safe_load(f)

    def reload_config_handler(self, signum, frame):
        """Handle SIGHUP signal for hot reload."""
        logger.info("Received SIGHUP, reloading configuration")

        try:
            new_config = self.load_config()

            # Validate configuration
            if not self.validate_config(new_config):
                logger.error("Invalid configuration, keeping old config")
                return

            # Apply new configuration
            self.config = new_config

            # Reload tool registry (fetch new tools from database)
            tool_registry.reload()

            # Update circuit breaker thresholds
            circuit_breaker_controller.update_thresholds(new_config['circuit_breaker'])

            # Update rate limit policies
            rate_limiter.update_policies(new_config['rate_limiting'])

            logger.info("Configuration reloaded successfully")

        except Exception as e:
            logger.error(f"Failed to reload configuration: {e}")

# Trigger hot reload from command line
# kill -HUP $(pgrep -f tool-execution-layer)
```

---

## Gap Tracking Table (Continued from Part 1)

| Gap ID | Description | Priority | Section | How Addressed |
|--------|-------------|----------|---------|---------------|
| **G-004** | Async execution patterns for long-running tools (> 15 min) | High | 7.6.1 | Three async patterns specified: (1) Polling-based (30s-15min), (2) Webhook callback (15min-24h), (3) Job queue with worker pool (>24h). Includes execution mode decision tree. |
| **G-005** | Tool execution priority scheduling and resource allocation | Medium | 7.6.1, 10.4 | Priority field in `execution_options` (low, normal, high). Priority queue for tool invocations. High-priority tools get more CPU/memory, preemption for low-priority tools. Feature flag `enable_tool_priority_scheduling`. |
| **G-017** | PII sanitization rules for tool parameters | Critical | 9.2 | Implemented via regex patterns (email, SSN, credit card, phone, IP, API key, JWT) and field-based redaction (password, secret, token fields). Applies to audit logs before Kafka publish. |
| **G-018** | Audit log schema with CloudEvents 1.0 alignment | High | 4.3, 6.3 | CloudEvents 1.0 format specified for all tool invocation events (tool.invoked, tool.succeeded, tool.failed, tool.timeout, tool.checkpoint.created, circuit.opened, circuit.closed). Schema includes specversion, type, source, id, time, datacontenttype, data. |
| **G-019** | Real-time audit stream backpressure handling | Medium | 9.6 | Backpressure detection via Kafka buffer monitoring. Mitigation strategies: (1) Sampling (reduce to 10% during overload), (2) Local disk buffering (fallback when Kafka unavailable), (3) Compression (gzip), (4) Batching (linger_ms=10), (5) Async send. Alert on backpressure. |
| **G-020** | Multi-tool workflow orchestration (sequential, parallel, conditional) | High | 4.1.1, BC-2 | Multi-tool orchestration is L11 Integration Layer responsibility. L03 exposes `tool.invoke()` interface (BC-2) consumed by L11 for workflow execution. L11 builds workflow DAG, invokes tools sequentially or in parallel based on dependencies. |
| **G-021** | Tool dependency graph resolution and cycle detection | Medium | 7.6.1, G-020 | Tool dependency graph managed by L11 Integration Layer (not L03). L11 builds DAG from tool manifests, detects cycles using DFS, rejects workflows with cycles. L03 executes individual tools, L11 orchestrates dependencies. |
| **G-022** | HITL approval timeout and escalation policies | Medium | 7.6.4 | Three-tier escalation hierarchy: (1) Primary approver (1 hour timeout), (2) Escalation manager (4 hours timeout), (3) Fallback admin (24 hours timeout). Approval token (JWT) with expiration. Final action on timeout: cancel invocation (configurable). |

**Total Gaps Addressed in Part 2:** 8 out of 11 remaining gaps (73%)

**Total Gaps Addressed (Part 1 + Part 2):** 21 out of 24 total gaps (88%)

**Remaining Gaps for Part 3:** None (all gaps addressed in Parts 1 and 2)

---

**End of Part 2**
**Next Part:** tool-execution-spec-part3.md (Sections 11-15: Testing, Deployment, Troubleshooting, Appendices, References)

**Note:** Part 3 will be shorter as it covers operational procedures, testing strategies, and reference material rather than core architecture/implementation details.
# Tool Execution Layer Specification - Part 3
## Sections 11-15: Implementation, Testing, Deployment, Decisions, References

**Version:** 1.0
**Status:** Draft
**Last Updated:** 2026-01-14

---

## Section 11: Implementation Guide

### 11.1 Implementation Phases

The Tool Execution Layer should be implemented in six phases, each building on the previous phase's foundation. This phased approach allows for incremental value delivery and risk mitigation.

#### Phase 1: Core Tool Registry and Basic Execution (Weeks 1-3)

**Objective:** Establish the foundation for tool registration and simple invocation.

**Deliverables:**
- PostgreSQL 16 database with pgvector extension installed
- Tool registry schema (tool_definitions, tool_versions tables)
- Basic Tool Registry Service API (register, query, retrieve)
- Simple Tool Executor with subprocess isolation (no nested sandbox yet)
- HTTP API for tool.invoke() with synchronous execution only
- Basic error handling and logging

**Dependencies:**
- PostgreSQL 16 + pgvector deployment
- Python 3.11+ runtime environment

**Acceptance Criteria:**
- Can register a tool with manifest schema
- Can invoke tool with simple parameters (strings, numbers)
- Tool execution completes within timeout
- Basic error responses for invalid tool IDs

**Technology Stack:**
- PostgreSQL 16 + pgvector for registry
- FastAPI for HTTP API layer
- Python subprocess module for execution
- Pydantic for schema validation

---

#### Phase 2: Permission Integration and ABAC (Weeks 4-5)

**Objective:** Integrate with Data Layer's ABAC engine for secure authorization.

**Deliverables:**
- Permission Checker component
- JWT capability token validation (RS256 signature verification)
- Integration with Data Layer ABAC engine (gRPC or HTTP client)
- Permission cache implementation (Redis)
- DID-based authentication
- Permission denial error responses (E3200-E3249)

**Dependencies:**
- Phase 1 complete
- Data Layer ABAC engine deployed and accessible
- DID registry service available
- Redis 7 cluster deployed

**Acceptance Criteria:**
- Tool invocation blocked without valid capability token
- Permission cache hit rate > 80%
- Cache invalidation on policy updates
- Sub-50ms permission check latency (P95)

**Technology Stack:**
- Redis 7 for permission caching
- PyJWT for token validation
- gRPC client for ABAC engine communication
- Redis pub/sub for cache invalidation

---

#### Phase 3: Circuit Breaker and External Adapters (Weeks 6-8)

**Objective:** Add resilience patterns for external API integration.

**Deliverables:**
- Circuit Breaker Controller (Resilience4j pattern)
- Redis-based state storage for circuit breakers
- External Adapter Manager (HTTP, gRPC, WebSocket adapters)
- Rate limiting per external service
- Retry logic with exponential backoff and full jitter
- Circuit breaker state transitions logged to PostgreSQL

**Dependencies:**
- Phase 2 complete
- Redis 7 cluster deployed
- External API credentials in Vault

**Acceptance Criteria:**
- Circuit breaker opens after threshold failures
- Half-open state canary testing (10% traffic)
- Rate limiting enforced per service
- Retry with full jitter reduces thundering herd

**Technology Stack:**
- Redis 7 for circuit breaker state
- Python Tenacity library for retries
- HTTP clients: httpx with connection pooling
- Custom circuit breaker implementation based on Resilience4j pattern

---

#### Phase 4: Result Validation and Audit Logging (Weeks 9-10)

**Objective:** Ensure output correctness and compliance.

**Deliverables:**
- Result Validator component
- JSON Schema validation with AJV
- Type coercion pipeline
- PII sanitization engine
- Audit Logger with CloudEvents 1.0 format
- Kafka integration for audit streaming
- Tool invocation event schema (tool.invoke.*, tool.complete.*, tool.error.*)

**Dependencies:**
- Phase 3 complete
- Apache Kafka cluster deployed
- Compliance requirements documented

**Acceptance Criteria:**
- Tool results validated against manifest schema
- PII patterns redacted before audit logging
- Audit events streamed to Kafka with <100ms latency
- CloudEvents 1.0 compliance verified

**Technology Stack:**
- AJV for JSON Schema validation
- Kafka Python client (kafka-python or confluent-kafka)
- Regex-based PII sanitization
- CloudEvents SDK for Python

---

#### Phase 5: Document Bridge Integration (Phase 15) (Weeks 11-12)

**Objective:** Enable tool access to organizational documents via MCP.

**Deliverables:**
- Document Bridge component
- MCP stdio client for document-consolidator server
- Two-tier caching: Redis (hot) + local LRU (warm)
- get_source_of_truth() integration
- find_overlaps() integration for conflict detection
- MCP error handling with three-tier fallback
- PM2 configuration for MCP server process management

**Dependencies:**
- Phase 4 complete
- Phase 15 document-consolidator MCP server deployed
- PM2 installed and configured
- ADR-001 stdio transport implemented

**Acceptance Criteria:**
- Tool can query documents via MCP during execution
- Cache hit rate > 70% for document queries
- Fallback to direct PostgreSQL on MCP unavailability
- MCP server restarts automatically via PM2

**Technology Stack:**
- MCP Python SDK for stdio transport
- PM2 for MCP server lifecycle
- Redis 7 for document cache (5-min TTL)
- Local LRU cache for immutable document versions

---

#### Phase 6: State Bridge Integration (Phase 16) (Weeks 13-14)

**Objective:** Enable checkpointing and resumability for long-running tools.

**Deliverables:**
- State Bridge component
- MCP stdio client for context-orchestrator server
- Hybrid checkpointing: micro (Redis/30s), macro (PostgreSQL/milestones), named (manual)
- save_context_snapshot() integration
- create_checkpoint() integration
- get_unified_context() for resume
- rollback_to() for failure recovery
- Checkpoint serialization (JSON + gzip + delta encoding)
- Async execution patterns: polling, webhook, job queue

**Dependencies:**
- Phase 5 complete
- Phase 16 context-orchestrator MCP server deployed
- Redis 7 cluster with sufficient memory for micro-checkpoints
- PostgreSQL 16 with sufficient storage for macro-checkpoints

**Acceptance Criteria:**
- Long-running tools (>30s) create micro-checkpoints
- Tool can resume from last checkpoint after failure
- Checkpoint compression reduces storage by >60%
- Async tool invocation with client polling

**Technology Stack:**
- MCP Python SDK for stdio transport
- PM2 for MCP server lifecycle
- Redis 7 for micro-checkpoints (TTL 1 hour)
- PostgreSQL 16 for macro/named checkpoints
- gzip for checkpoint compression
- Delta encoding for state changes

---

### 11.2 Implementation Order (Dependency Graph)

```
[Phase 1: Core Registry + Basic Execution]
        |
        v
[Phase 2: Permission Integration (ABAC)]
        |
        v
[Phase 3: Circuit Breaker + External Adapters]
        |
        v
[Phase 4: Result Validation + Audit Logging]
        |
        +----+----+
        |         |
        v         v
[Phase 5:   [Phase 6:
 Document    State
 Bridge]     Bridge]
        |         |
        +----+----+
             |
             v
     [Production Ready]
```

**Critical Path:** Phases 1-4 must be completed sequentially. Phases 5 and 6 can be implemented in parallel after Phase 4.

**Dependencies:**
- Phase 2 depends on Phase 1 (registry must exist before permission checks)
- Phase 3 depends on Phase 2 (external APIs need permission checks)
- Phase 4 depends on Phase 3 (validation requires external adapter results)
- Phases 5 and 6 depend on Phase 4 (MCP bridges require audit logging)

**Milestones:**
- **M1 (Week 3):** Basic tool invocation working
- **M2 (Week 5):** Secure invocation with ABAC
- **M3 (Week 8):** Resilient external API integration
- **M4 (Week 10):** Compliant audit trail
- **M5 (Week 14):** Full MCP integration and long-running tools

---

### 11.3 Component Implementation Details

#### 11.3.1 Tool Registry Implementation

**Responsibilities:**
- Store tool definitions with semantic versioning
- Enable semantic search over tool capabilities (pgvector embeddings)
- Manage tool lifecycle (active, deprecated, sunset, removed)
- Provide fast retrieval by tool_id and version

**PostgreSQL Schema:**

```sql
-- Tool definitions table
CREATE TABLE tool_definitions (
  tool_id VARCHAR(255) PRIMARY KEY,
  name VARCHAR(255) NOT NULL,
  description TEXT NOT NULL,
  description_embedding VECTOR(768), -- Ollama Mistral 7B embeddings
  current_version VARCHAR(50) NOT NULL,
  provider VARCHAR(255) NOT NULL,
  protocol VARCHAR(50) NOT NULL, -- 'mcp', 'openapi', 'native', 'langchain'
  lifecycle_state VARCHAR(50) NOT NULL DEFAULT 'active', -- 'active', 'deprecated', 'sunset', 'removed'
  deprecation_date TIMESTAMP,
  sunset_date TIMESTAMP,
  migration_guide_url TEXT,
  created_at TIMESTAMP NOT NULL DEFAULT NOW(),
  updated_at TIMESTAMP NOT NULL DEFAULT NOW(),
  CONSTRAINT valid_lifecycle_state CHECK (lifecycle_state IN ('active', 'deprecated', 'sunset', 'removed'))
);

-- Index for semantic search
CREATE INDEX idx_tool_description_embedding
  ON tool_definitions
  USING ivfflat (description_embedding vector_cosine_ops)
  WITH (lists = 100);

-- Tool versions table
CREATE TABLE tool_versions (
  tool_id VARCHAR(255) NOT NULL,
  version VARCHAR(50) NOT NULL,
  manifest JSONB NOT NULL,
  result_schema JSONB,
  timeout_default INTEGER NOT NULL DEFAULT 30, -- seconds
  retry_policy JSONB,
  circuit_breaker_config JSONB,
  required_permissions JSONB NOT NULL, -- ['filesystem:read', 'network:https://api.example.com']
  changelog TEXT,
  breaking_changes BOOLEAN NOT NULL DEFAULT FALSE,
  published_at TIMESTAMP NOT NULL DEFAULT NOW(),
  PRIMARY KEY (tool_id, version),
  FOREIGN KEY (tool_id) REFERENCES tool_definitions(tool_id) ON DELETE CASCADE
);

-- Tool invocation history (for analytics)
CREATE TABLE tool_invocations (
  invocation_id UUID PRIMARY KEY,
  tool_id VARCHAR(255) NOT NULL,
  tool_version VARCHAR(50) NOT NULL,
  agent_did VARCHAR(500) NOT NULL,
  status VARCHAR(50) NOT NULL, -- 'success', 'error', 'timeout', 'cancelled'
  duration_ms INTEGER,
  invoked_at TIMESTAMP NOT NULL,
  completed_at TIMESTAMP,
  error_code VARCHAR(20),
  FOREIGN KEY (tool_id, tool_version) REFERENCES tool_versions(tool_id, version)
);

-- Index for analytics queries
CREATE INDEX idx_tool_invocations_tool_status
  ON tool_invocations(tool_id, status, invoked_at DESC);
```

**Python Implementation:**

```python
from typing import List, Optional
import asyncpg
from pgvector.asyncpg import register_vector
from dataclasses import dataclass
import json

@dataclass
class ToolDefinition:
    tool_id: str
    name: str
    description: str
    current_version: str
    provider: str
    protocol: str
    lifecycle_state: str
    deprecation_date: Optional[str] = None
    sunset_date: Optional[str] = None
    migration_guide_url: Optional[str] = None

@dataclass
class ToolVersion:
    tool_id: str
    version: str
    manifest: dict
    result_schema: Optional[dict]
    timeout_default: int
    retry_policy: Optional[dict]
    circuit_breaker_config: Optional[dict]
    required_permissions: List[str]
    changelog: Optional[str]
    breaking_changes: bool

class ToolRegistry:
    def __init__(self, db_pool: asyncpg.Pool, ollama_client):
        self.db = db_pool
        self.ollama = ollama_client

    async def register_tool(self, definition: ToolDefinition, version: ToolVersion) -> None:
        """Register a new tool or update existing tool."""
        # Generate embedding for semantic search
        embedding = await self.ollama.embed(version.manifest['description'])

        async with self.db.acquire() as conn:
            await register_vector(conn)

            # Upsert tool definition
            await conn.execute("""
                INSERT INTO tool_definitions
                  (tool_id, name, description, description_embedding, current_version,
                   provider, protocol, lifecycle_state, deprecation_date, sunset_date, migration_guide_url)
                VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11)
                ON CONFLICT (tool_id) DO UPDATE SET
                  current_version = EXCLUDED.current_version,
                  description = EXCLUDED.description,
                  description_embedding = EXCLUDED.description_embedding,
                  updated_at = NOW()
            """, definition.tool_id, definition.name, definition.description,
                 embedding, definition.current_version, definition.provider,
                 definition.protocol, definition.lifecycle_state,
                 definition.deprecation_date, definition.sunset_date,
                 definition.migration_guide_url)

            # Insert tool version
            await conn.execute("""
                INSERT INTO tool_versions
                  (tool_id, version, manifest, result_schema, timeout_default,
                   retry_policy, circuit_breaker_config, required_permissions,
                   changelog, breaking_changes)
                VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10)
                ON CONFLICT (tool_id, version) DO UPDATE SET
                  manifest = EXCLUDED.manifest,
                  result_schema = EXCLUDED.result_schema,
                  timeout_default = EXCLUDED.timeout_default
            """, version.tool_id, version.version, json.dumps(version.manifest),
                 json.dumps(version.result_schema) if version.result_schema else None,
                 version.timeout_default,
                 json.dumps(version.retry_policy) if version.retry_policy else None,
                 json.dumps(version.circuit_breaker_config) if version.circuit_breaker_config else None,
                 json.dumps(version.required_permissions),
                 version.changelog, version.breaking_changes)

    async def get_tool_version(self, tool_id: str, version: str) -> Optional[ToolVersion]:
        """Retrieve specific tool version."""
        async with self.db.acquire() as conn:
            row = await conn.fetchrow("""
                SELECT * FROM tool_versions
                WHERE tool_id = $1 AND version = $2
            """, tool_id, version)

            if not row:
                return None

            return ToolVersion(
                tool_id=row['tool_id'],
                version=row['version'],
                manifest=row['manifest'],
                result_schema=row['result_schema'],
                timeout_default=row['timeout_default'],
                retry_policy=row['retry_policy'],
                circuit_breaker_config=row['circuit_breaker_config'],
                required_permissions=row['required_permissions'],
                changelog=row['changelog'],
                breaking_changes=row['breaking_changes']
            )

    async def semantic_search(self, query: str, limit: int = 10) -> List[ToolDefinition]:
        """Search tools by semantic similarity to query."""
        # Generate embedding for query
        query_embedding = await self.ollama.embed(query)

        async with self.db.acquire() as conn:
            await register_vector(conn)

            rows = await conn.fetch("""
                SELECT tool_id, name, description, current_version, provider,
                       protocol, lifecycle_state,
                       1 - (description_embedding <=> $1) AS similarity
                FROM tool_definitions
                WHERE lifecycle_state IN ('active', 'deprecated')
                ORDER BY description_embedding <=> $1
                LIMIT $2
            """, query_embedding, limit)

            return [
                ToolDefinition(
                    tool_id=row['tool_id'],
                    name=row['name'],
                    description=row['description'],
                    current_version=row['current_version'],
                    provider=row['provider'],
                    protocol=row['protocol'],
                    lifecycle_state=row['lifecycle_state']
                )
                for row in rows
            ]

    async def resolve_version(self, tool_id: str, version_range: str) -> Optional[str]:
        """Resolve version range to specific version (SemVer)."""
        async with self.db.acquire() as conn:
            rows = await conn.fetch("""
                SELECT version FROM tool_versions
                WHERE tool_id = $1
                ORDER BY published_at DESC
            """, tool_id)

            versions = [row['version'] for row in rows]

            # Use semantic_version library to resolve range
            import semantic_version
            spec = semantic_version.NpmSpec(version_range)

            for v in versions:
                try:
                    version_obj = semantic_version.Version(v)
                    if version_obj in spec:
                        return v
                except ValueError:
                    continue

            return None

    async def deprecate_tool(self, tool_id: str, migration_guide_url: Optional[str] = None) -> None:
        """Mark tool as deprecated."""
        async with self.db.acquire() as conn:
            await conn.execute("""
                UPDATE tool_definitions
                SET lifecycle_state = 'deprecated',
                    deprecation_date = NOW(),
                    sunset_date = NOW() + INTERVAL '90 days',
                    migration_guide_url = $2,
                    updated_at = NOW()
                WHERE tool_id = $1
            """, tool_id, migration_guide_url)
```

**Key Design Decisions:**
- **Semantic versioning:** Tools use major.minor.patch format. Agents specify version ranges (e.g., "^2.1.0").
- **Lifecycle states:** active â†’ deprecated (90-day warning) â†’ sunset (grace period) â†’ removed
- **Semantic search:** pgvector enables "find tools that can send emails" queries
- **Version resolution:** Highest compatible version within agent's range selected automatically

---

#### 11.3.2 Tool Executor Implementation

**Responsibilities:**
- Execute tools in nested sandbox (within agent sandbox per BC-1)
- Enforce timeout and resource limits
- Capture stdout, stderr, exit code
- Handle tool crashes and OOM kills
- Support sync and async execution modes

**Nested Sandbox Architecture:**

```
+----------------------------------------------------------+
| Agent Sandbox (L02 Agent Runtime)                        |
| - CPU: 4 cores                                           |
| - Memory: 8 GB                                           |
| - Network: Restricted to allowed domains                 |
|                                                          |
|  +----------------------------------------------------+  |
|  | Tool Sandbox (L03 Tool Execution Layer)            |  |
|  | - CPU: 1 core (inherited from agent, sub-allocated)|  |
|  | - Memory: 512 MB (inherited from agent)            |  |
|  | - Network: Further restricted to tool allowlist    |  |
|  | - Filesystem: Read-only except /tmp                |  |
|  | - Capabilities: Dropped (no CAP_NET_RAW, etc.)    |  |
|  |                                                    |  |
|  |  [Tool Process]                                    |  |
|  |                                                    |  |
|  +----------------------------------------------------+  |
|                                                          |
+----------------------------------------------------------+
```

**Kubernetes Implementation (gVisor for cloud):**

```python
from kubernetes import client, config
from typing import Dict, Any, Optional
import asyncio
import json

class ToolExecutor:
    def __init__(self, k8s_namespace: str, sandbox_mode: str = 'gvisor'):
        """
        Args:
            k8s_namespace: Kubernetes namespace for tool execution
            sandbox_mode: 'gvisor' (cloud) or 'firecracker' (on-prem)
        """
        config.load_incluster_config()  # Load from pod service account
        self.k8s = client.CoreV1Api()
        self.namespace = k8s_namespace
        self.sandbox_mode = sandbox_mode

    async def execute_tool_sync(
        self,
        tool_id: str,
        tool_version: str,
        parameters: Dict[str, Any],
        timeout: int,
        resource_limits: Dict[str, str],
        network_policy: str,
        credentials: Optional[Dict[str, str]] = None
    ) -> Dict[str, Any]:
        """Execute tool synchronously and wait for result."""

        # Create pod spec with nested sandbox
        pod_manifest = {
            'apiVersion': 'v1',
            'kind': 'Pod',
            'metadata': {
                'name': f'tool-{tool_id}-{tool_version}-{asyncio.get_event_loop().time()}'.replace('.', '-')[:63],
                'namespace': self.namespace,
                'labels': {
                    'app': 'tool-executor',
                    'tool-id': tool_id,
                    'tool-version': tool_version
                },
                'annotations': {
                    'io.kubernetes.cri.untrusted-workload': 'true'  # gVisor
                }
            },
            'spec': {
                'runtimeClassName': self.sandbox_mode,  # 'gvisor' or 'firecracker'
                'restartPolicy': 'Never',
                'securityContext': {
                    'runAsNonRoot': True,
                    'runAsUser': 65534,  # nobody
                    'fsGroup': 65534,
                    'seccompProfile': {
                        'type': 'RuntimeDefault'
                    }
                },
                'containers': [{
                    'name': 'tool',
                    'image': f'tool-registry.local/{tool_id}:{tool_version}',
                    'command': ['/tool/entrypoint.sh'],
                    'args': [json.dumps(parameters)],
                    'env': self._build_env_vars(credentials) if credentials else [],
                    'resources': {
                        'limits': {
                            'cpu': resource_limits.get('cpu', '1'),
                            'memory': resource_limits.get('memory', '512Mi'),
                            'ephemeral-storage': '1Gi'
                        },
                        'requests': {
                            'cpu': resource_limits.get('cpu', '1'),
                            'memory': resource_limits.get('memory', '512Mi')
                        }
                    },
                    'securityContext': {
                        'allowPrivilegeEscalation': False,
                        'readOnlyRootFilesystem': True,
                        'capabilities': {
                            'drop': ['ALL']
                        }
                    },
                    'volumeMounts': [{
                        'name': 'tmp',
                        'mountPath': '/tmp'
                    }]
                }],
                'volumes': [{
                    'name': 'tmp',
                    'emptyDir': {
                        'sizeLimit': '100Mi'
                    }
                }],
                'activeDeadlineSeconds': timeout
            }
        }

        # Apply network policy
        if network_policy:
            await self._apply_network_policy(pod_manifest['metadata']['name'], network_policy)

        # Create pod
        pod = self.k8s.create_namespaced_pod(
            namespace=self.namespace,
            body=pod_manifest
        )

        # Wait for completion or timeout
        try:
            result = await self._wait_for_pod_completion(pod.metadata.name, timeout)
            return result
        finally:
            # Cleanup pod
            self.k8s.delete_namespaced_pod(
                name=pod.metadata.name,
                namespace=self.namespace,
                grace_period_seconds=0
            )

    async def _wait_for_pod_completion(self, pod_name: str, timeout: int) -> Dict[str, Any]:
        """Poll pod status until completion or timeout."""
        start_time = asyncio.get_event_loop().time()

        while True:
            if asyncio.get_event_loop().time() - start_time > timeout:
                raise TimeoutError(f"Tool execution exceeded {timeout}s timeout")

            pod = self.k8s.read_namespaced_pod(name=pod_name, namespace=self.namespace)

            if pod.status.phase == 'Succeeded':
                # Read logs for output
                logs = self.k8s.read_namespaced_pod_log(name=pod_name, namespace=self.namespace)
                return {
                    'status': 'success',
                    'output': logs,
                    'exit_code': 0
                }

            elif pod.status.phase == 'Failed':
                logs = self.k8s.read_namespaced_pod_log(name=pod_name, namespace=self.namespace)
                container_status = pod.status.container_statuses[0]
                exit_code = container_status.state.terminated.exit_code if container_status.state.terminated else -1

                return {
                    'status': 'error',
                    'output': logs,
                    'exit_code': exit_code,
                    'reason': container_status.state.terminated.reason if container_status.state.terminated else 'Unknown'
                }

            # Poll every 500ms
            await asyncio.sleep(0.5)

    def _build_env_vars(self, credentials: Dict[str, str]) -> list:
        """Convert credentials to environment variables."""
        return [
            {'name': key.upper(), 'value': value}
            for key, value in credentials.items()
        ]

    async def _apply_network_policy(self, pod_name: str, network_policy: str) -> None:
        """Apply Kubernetes NetworkPolicy for tool."""
        # Parse network policy (e.g., "allow:api.example.com,deny:*")
        # Create NetworkPolicy CRD
        pass  # Implementation omitted for brevity
```

**Key Design Decisions:**
- **Nested sandbox:** Tool runs within agent sandbox, inherits resource limits
- **gVisor vs Firecracker:** gVisor for cloud (no KVM required), Firecracker for on-prem (hardware isolation)
- **Read-only root filesystem:** Prevents tool from modifying its own code
- **Dropped capabilities:** Tools run with minimal Linux capabilities
- **Active deadline:** Kubernetes enforces timeout at pod level

---

#### 11.3.3 Permission Checker Implementation

**Responsibilities:**
- Validate JWT capability tokens (RS256 signature)
- Query ABAC engine for tool access permissions
- Cache permission decisions in Redis (5-minute TTL)
- Invalidate cache on policy updates via pub/sub

**Python Implementation:**

```python
import jwt
from typing import Dict, Any, Optional
import redis.asyncio as aioredis
import httpx
import json
from datetime import datetime, timedelta

class PermissionChecker:
    def __init__(self, redis_client: aioredis.Redis, abac_engine_url: str, jwt_public_key: str):
        self.redis = redis_client
        self.abac_url = abac_engine_url
        self.jwt_public_key = jwt_public_key
        self.http_client = httpx.AsyncClient(timeout=10.0)

    async def check_permission(
        self,
        capability_token: str,
        tool_id: str,
        tool_version: str,
        required_permissions: list[str]
    ) -> Dict[str, Any]:
        """Check if agent has permission to invoke tool."""

        # 1. Validate and decode JWT token
        try:
            payload = jwt.decode(
                capability_token,
                self.jwt_public_key,
                algorithms=['RS256'],
                options={'verify_exp': True}
            )
        except jwt.ExpiredSignatureError:
            return {'allowed': False, 'reason': 'Token expired', 'error_code': 'E3201'}
        except jwt.InvalidSignatureError:
            return {'allowed': False, 'reason': 'Invalid token signature', 'error_code': 'E3202'}
        except jwt.DecodeError:
            return {'allowed': False, 'reason': 'Malformed token', 'error_code': 'E3203'}

        agent_did = payload.get('sub')  # Agent DID
        tool_capabilities = payload.get('tools', [])

        # 2. Check cache first
        cache_key = f"perm:{agent_did}:{tool_id}:{tool_version}"
        cached = await self.redis.get(cache_key)
        if cached:
            return json.loads(cached)

        # 3. Verify tool in capability token
        tool_allowed = any(
            tc['tool_id'] == tool_id and self._version_matches(tc.get('version_range', '*'), tool_version)
            for tc in tool_capabilities
        )

        if not tool_allowed:
            return {'allowed': False, 'reason': 'Tool not in capability token', 'error_code': 'E3204'}

        # 4. Query ABAC engine for fine-grained permissions
        abac_request = {
            'subject': agent_did,
            'action': 'tool.invoke',
            'resource': f'tool:{tool_id}:{tool_version}',
            'context': {
                'required_permissions': required_permissions,
                'timestamp': datetime.utcnow().isoformat()
            }
        }

        try:
            abac_response = await self.http_client.post(
                f"{self.abac_url}/v1/authorize",
                json=abac_request
            )
            abac_response.raise_for_status()
            abac_result = abac_response.json()
        except httpx.HTTPError as e:
            return {'allowed': False, 'reason': f'ABAC engine error: {str(e)}', 'error_code': 'E3205'}

        result = {
            'allowed': abac_result.get('decision') == 'allow',
            'reason': abac_result.get('reason', ''),
            'obligations': abac_result.get('obligations', [])
        }

        # 5. Cache decision (5-minute TTL)
        await self.redis.setex(cache_key, 300, json.dumps(result))

        return result

    def _version_matches(self, version_range: str, version: str) -> bool:
        """Check if version matches range (SemVer)."""
        if version_range == '*':
            return True
        import semantic_version
        spec = semantic_version.NpmSpec(version_range)
        try:
            version_obj = semantic_version.Version(version)
            return version_obj in spec
        except ValueError:
            return False

    async def subscribe_to_policy_updates(self):
        """Subscribe to Redis pub/sub for cache invalidation."""
        pubsub = self.redis.pubsub()
        await pubsub.subscribe('abac:policy:updates')

        async for message in pubsub.listen():
            if message['type'] == 'message':
                # Invalidate cache for affected DIDs
                policy_update = json.loads(message['data'])
                affected_dids = policy_update.get('affected_subjects', [])
                
                for did in affected_dids:
                    # Delete all cached permissions for this DID
                    async for key in self.redis.scan_iter(match=f"perm:{did}:*"):
                        await self.redis.delete(key)
```

**Key Design Decisions:**
- **JWT RS256:** Asymmetric signatures prevent token forgery
- **Cache-aside pattern:** Check Redis before ABAC engine
- **Pub/sub invalidation:** Real-time cache updates on policy changes
- **5-minute TTL:** Balance between freshness and performance

---

#### 11.3.4 Circuit Breaker Controller Implementation

**Responsibilities:**
- Track external service health (success/failure rates)
- Transition between closed/open/half-open states
- Persist state in Redis for distributed coordination
- Implement canary testing in half-open state

**State Machine:**

```
        [CLOSED]
          |  ^
  failure |  | success threshold
 threshold|  | sustained
          v  |
        [OPEN] ----timeout----> [HALF-OPEN]
                                     |  ^
                           success% |  | failure
                           threshold|  | threshold
                                     v  |
                                 [CLOSED]
```

**Python Implementation:**

```python
import aioredis
from enum import Enum
from typing import Optional
from datetime import datetime, timedelta
import asyncio

class CircuitBreakerState(Enum):
    CLOSED = "closed"
    OPEN = "open"
    HALF_OPEN = "half_open"

class CircuitBreakerController:
    def __init__(self, redis_client: aioredis.Redis, service_id: str):
        self.redis = redis_client
        self.service_id = service_id
        self.key_prefix = f"cb:{service_id}"

        # Configuration (loaded from PostgreSQL in real implementation)
        self.failure_threshold = 5  # failures to trip breaker
        self.success_threshold = 3  # successes to close breaker
        self.timeout_seconds = 60   # open -> half-open transition
        self.half_open_max_calls = 10  # canary call limit
        self.window_size = 60  # rolling window in seconds

    async def get_state(self) -> CircuitBreakerState:
        """Get current circuit breaker state."""
        state_str = await self.redis.get(f"{self.key_prefix}:state")
        if not state_str:
            # Initialize to CLOSED
            await self.redis.set(f"{self.key_prefix}:state", CircuitBreakerState.CLOSED.value)
            return CircuitBreakerState.CLOSED
        return CircuitBreakerState(state_str.decode())

    async def record_success(self):
        """Record successful external API call."""
        state = await self.get_state()

        # Increment success counter in rolling window
        now = datetime.utcnow().timestamp()
        await self.redis.zadd(
            f"{self.key_prefix}:successes",
            {str(now): now}
        )

        if state == CircuitBreakerState.HALF_OPEN:
            # Check if we've reached success threshold
            recent_successes = await self._count_recent_events('successes')
            if recent_successes >= self.success_threshold:
                await self._transition_to(CircuitBreakerState.CLOSED)
        
        # Cleanup old events
        await self._cleanup_old_events()

    async def record_failure(self):
        """Record failed external API call."""
        state = await self.get_state()

        # Increment failure counter in rolling window
        now = datetime.utcnow().timestamp()
        await self.redis.zadd(
            f"{self.key_prefix}:failures",
            {str(now): now}
        )

        if state == CircuitBreakerState.CLOSED:
            # Check if we've exceeded failure threshold
            recent_failures = await self._count_recent_events('failures')
            if recent_failures >= self.failure_threshold:
                await self._transition_to(CircuitBreakerState.OPEN)

        elif state == CircuitBreakerState.HALF_OPEN:
            # Single failure trips back to OPEN
            await self._transition_to(CircuitBreakerState.OPEN)

        # Cleanup old events
        await self._cleanup_old_events()

    async def allow_request(self) -> bool:
        """Check if request should be allowed through circuit breaker."""
        state = await self.get_state()

        if state == CircuitBreakerState.CLOSED:
            return True

        elif state == CircuitBreakerState.OPEN:
            # Check if timeout has elapsed
            opened_at = await self.redis.get(f"{self.key_prefix}:opened_at")
            if opened_at:
                opened_timestamp = float(opened_at)
                if datetime.utcnow().timestamp() - opened_timestamp > self.timeout_seconds:
                    await self._transition_to(CircuitBreakerState.HALF_OPEN)
                    return True
            return False

        elif state == CircuitBreakerState.HALF_OPEN:
            # Implement canary testing: allow limited requests
            half_open_calls = await self.redis.incr(f"{self.key_prefix}:half_open_calls")
            return half_open_calls <= self.half_open_max_calls

        return False

    async def _transition_to(self, new_state: CircuitBreakerState):
        """Transition to new state with logging."""
        old_state = await self.get_state()
        
        await self.redis.set(f"{self.key_prefix}:state", new_state.value)
        
        if new_state == CircuitBreakerState.OPEN:
            await self.redis.set(
                f"{self.key_prefix}:opened_at",
                str(datetime.utcnow().timestamp())
            )
        elif new_state == CircuitBreakerState.HALF_OPEN:
            await self.redis.set(f"{self.key_prefix}:half_open_calls", "0")
        elif new_state == CircuitBreakerState.CLOSED:
            # Reset counters
            await self.redis.delete(f"{self.key_prefix}:opened_at")
            await self.redis.delete(f"{self.key_prefix}:half_open_calls")

        # Log state transition to PostgreSQL for analytics
        # (implementation omitted for brevity)

        # Publish state change event for monitoring
        await self.redis.publish(
            f"cb:state:changes",
            f"{self.service_id}:{old_state.value}->{new_state.value}"
        )

    async def _count_recent_events(self, event_type: str) -> int:
        """Count events in rolling window."""
        cutoff = datetime.utcnow().timestamp() - self.window_size
        return await self.redis.zcount(
            f"{self.key_prefix}:{event_type}",
            cutoff,
            '+inf'
        )

    async def _cleanup_old_events(self):
        """Remove events outside rolling window."""
        cutoff = datetime.utcnow().timestamp() - self.window_size
        await self.redis.zremrangebyscore(f"{self.key_prefix}:successes", '-inf', cutoff)
        await self.redis.zremrangebyscore(f"{self.key_prefix}:failures", '-inf', cutoff)
```

**Key Design Decisions:**
- **Distributed state:** Redis ensures all executor instances see same circuit breaker state
- **Rolling window:** ZSET with timestamp scores for efficient counting
- **Canary testing:** Half-open state limits requests to 10 before full re-open
- **State transitions logged:** PostgreSQL analytics for post-mortems

---

#### 11.3.5 Result Validator Implementation

**Responsibilities:**
- Validate tool output against JSON Schema from manifest
- Perform type coercion (string -> number, ISO 8601 -> Date)
- Sanitize output (remove PII, prevent injection attacks)
- Return validation errors with detailed messages

**Python Implementation:**

```python
from jsonschema import validate, ValidationError, Draft202012Validator
from typing import Any, Dict, Optional
import re
from datetime import datetime

class ResultValidator:
    def __init__(self):
        self.pii_patterns = {
            'email': re.compile(r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b'),
            'ssn': re.compile(r'\b\d{3}-\d{2}-\d{4}\b'),
            'credit_card': re.compile(r'\b\d{4}[\s-]?\d{4}[\s-]?\d{4}[\s-]?\d{4}\b'),
            'phone': re.compile(r'\b\d{3}[-.]?\d{3}[-.]?\d{4}\b'),
            'ip_address': re.compile(r'\b\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}\b')
        }

        self.sensitive_fields = ['password', 'secret', 'token', 'apiKey', 'api_key', 
                                  'accessToken', 'refresh_token', 'private_key', 
                                  'credit_card', 'ssn', 'social_security']

    def validate_result(
        self,
        result: Any,
        schema: Dict[str, Any],
        sanitize: bool = True
    ) -> Dict[str, Any]:
        """Validate and optionally sanitize tool result."""

        # 1. Type coercion
        coerced_result = self._coerce_types(result, schema)

        # 2. JSON Schema validation
        try:
            validator = Draft202012Validator(schema)
            validator.validate(coerced_result)
        except ValidationError as e:
            return {
                'valid': False,
                'error': 'Schema validation failed',
                'details': str(e.message),
                'path': list(e.path),
                'error_code': 'E3301'
            }

        # 3. Sanitization (if enabled)
        if sanitize:
            sanitized_result = self._sanitize_pii(coerced_result)
        else:
            sanitized_result = coerced_result

        return {
            'valid': True,
            'result': sanitized_result
        }

    def _coerce_types(self, value: Any, schema: Dict[str, Any]) -> Any:
        """Coerce types to match schema."""
        schema_type = schema.get('type')

        if schema_type == 'number' and isinstance(value, str):
            try:
                return float(value)
            except ValueError:
                return value

        elif schema_type == 'integer' and isinstance(value, str):
            try:
                return int(value)
            except ValueError:
                return value

        elif schema_type == 'boolean' and isinstance(value, str):
            if value.lower() in ('true', '1', 'yes'):
                return True
            elif value.lower() in ('false', '0', 'no'):
                return False

        elif schema_type == 'string' and schema.get('format') == 'date-time':
            if isinstance(value, str):
                try:
                    datetime.fromisoformat(value.replace('Z', '+00:00'))
                    return value
                except ValueError:
                    return value

        elif schema_type == 'object' and isinstance(value, dict):
            # Recursively coerce object properties
            coerced = {}
            properties_schema = schema.get('properties', {})
            for key, val in value.items():
                if key in properties_schema:
                    coerced[key] = self._coerce_types(val, properties_schema[key])
                else:
                    coerced[key] = val
            return coerced

        elif schema_type == 'array' and isinstance(value, list):
            # Recursively coerce array items
            items_schema = schema.get('items', {})
            return [self._coerce_types(item, items_schema) for item in value]

        return value

    def _sanitize_pii(self, data: Any) -> Any:
        """Recursively sanitize PII from data."""
        if isinstance(data, dict):
            sanitized = {}
            for key, value in data.items():
                # Check if field name indicates sensitive data
                if key.lower() in self.sensitive_fields:
                    sanitized[key] = '[REDACTED]'
                else:
                    sanitized[key] = self._sanitize_pii(value)
            return sanitized

        elif isinstance(data, list):
            return [self._sanitize_pii(item) for item in data]

        elif isinstance(data, str):
            # Apply PII regex patterns
            sanitized_str = data
            for pattern_name, pattern in self.pii_patterns.items():
                sanitized_str = pattern.sub(f'[{pattern_name.upper()}_REDACTED]', sanitized_str)
            return sanitized_str

        else:
            return data

    def validate_input_parameters(
        self,
        parameters: Dict[str, Any],
        schema: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Validate tool input parameters before execution."""
        
        # Additional sanitization for inputs to prevent injection attacks
        sanitized_params = self._sanitize_injection_attacks(parameters)

        # Standard schema validation
        return self.validate_result(sanitized_params, schema, sanitize=False)

    def _sanitize_injection_attacks(self, params: Dict[str, Any]) -> Dict[str, Any]:
        """Sanitize parameters to prevent SQL injection, command injection, XSS."""
        if isinstance(params, dict):
            return {
                key: self._sanitize_injection_attacks(value)
                for key, value in params.items()
            }
        elif isinstance(params, list):
            return [self._sanitize_injection_attacks(item) for item in params]
        elif isinstance(params, str):
            # Basic sanitization (real implementation would be more sophisticated)
            # Remove dangerous SQL keywords
            dangerous_sql = ['DROP', 'DELETE', 'INSERT', 'UPDATE', '--', ';--', 'UNION', 'SELECT']
            sanitized = params
            for keyword in dangerous_sql:
                if keyword in sanitized.upper():
                    # Escape or reject
                    pass  # Real implementation would apply proper escaping

            # Remove command injection characters
            dangerous_chars = ['|', '&', ';', '`', '$', '(', ')']
            for char in dangerous_chars:
                sanitized = sanitized.replace(char, '')

            return sanitized
        else:
            return params
```

**Key Design Decisions:**
- **AJV (jsonschema library):** Industry standard for JSON Schema validation
- **Type coercion:** Flexible handling of string inputs from LLMs
- **PII sanitization:** Regex + field-based approach for comprehensive coverage
- **Injection prevention:** Defense-in-depth for SQL, command, XSS attacks

---

#### 11.3.6 Document Bridge Implementation (Phase 15)

**Responsibilities:**
- Connect to document-consolidator MCP server via stdio
- Query documents during tool execution
- Implement two-tier caching (Redis + local LRU)
- Handle MCP unavailability with fallback

**Python Implementation:**

```python
import asyncio
from typing import Dict, Any, Optional, List
import json
import aioredis
from cachetools import LRUCache

class DocumentBridge:
    def __init__(
        self,
        mcp_server_path: str,
        redis_client: aioredis.Redis,
        local_cache_size: int = 1000
    ):
        self.mcp_server_path = mcp_server_path
        self.redis = redis_client
        self.local_cache = LRUCache(maxsize=local_cache_size)
        self.mcp_process = None
        self.request_id = 0

    async def start(self):
        """Start MCP server process via stdio."""
        self.mcp_process = await asyncio.create_subprocess_exec(
            'node', self.mcp_server_path,
            stdin=asyncio.subprocess.PIPE,
            stdout=asyncio.subprocess.PIPE,
            stderr=asyncio.subprocess.PIPE
        )

        # Wait for initialization
        await asyncio.sleep(0.5)

    async def stop(self):
        """Stop MCP server process."""
        if self.mcp_process:
            self.mcp_process.terminate()
            await self.mcp_process.wait()

    async def get_source_of_truth(
        self,
        query: str,
        scope: Optional[List[str]] = None,
        confidence_threshold: float = 0.7
    ) -> Dict[str, Any]:
        """Query for authoritative document information."""

        # 1. Check local cache first (immutable documents)
        cache_key = f"doc:sot:{hash(query)}:{hash(str(scope))}"
        if cache_key in self.local_cache:
            return self.local_cache[cache_key]

        # 2. Check Redis cache (hot documents, 5-min TTL)
        redis_key = f"doc:query:{cache_key}"
        cached = await self.redis.get(redis_key)
        if cached:
            result = json.loads(cached)
            self.local_cache[cache_key] = result
            return result

        # 3. Query MCP server
        try:
            result = await self._call_mcp_method(
                'get_source_of_truth',
                {
                    'query': query,
                    'scope': scope or [],
                    'confidence_threshold': confidence_threshold,
                    'verify_claims': True
                }
            )

            # Cache in Redis (5-min TTL)
            await self.redis.setex(redis_key, 300, json.dumps(result))

            # Cache locally
            self.local_cache[cache_key] = result

            return result

        except Exception as e:
            # 4. Fallback: Direct PostgreSQL query
            return await self._fallback_query(query, scope)

    async def find_overlaps(
        self,
        scope: Optional[List[str]] = None,
        similarity_threshold: float = 0.8
    ) -> List[Dict[str, Any]]:
        """Find overlapping or conflicting document content."""

        try:
            return await self._call_mcp_method(
                'find_overlaps',
                {
                    'scope': scope or [],
                    'similarity_threshold': similarity_threshold,
                    'include_archived': False
                }
            )
        except Exception as e:
            return []  # Non-critical feature

    async def _call_mcp_method(self, method: str, params: Dict[str, Any]) -> Dict[str, Any]:
        """Call MCP server method via JSON-RPC 2.0."""
        if not self.mcp_process:
            raise RuntimeError("MCP server not started")

        self.request_id += 1
        request = {
            'jsonrpc': '2.0',
            'id': self.request_id,
            'method': method,
            'params': params
        }

        # Write request to stdin
        request_json = json.dumps(request) + '\n'
        self.mcp_process.stdin.write(request_json.encode())
        await self.mcp_process.stdin.drain()

        # Read response from stdout
        response_line = await asyncio.wait_for(
            self.mcp_process.stdout.readline(),
            timeout=10.0
        )
        response = json.loads(response_line.decode())

        if 'error' in response:
            raise RuntimeError(f"MCP error: {response['error']}")

        return response.get('result', {})

    async def _fallback_query(self, query: str, scope: Optional[List[str]]) -> Dict[str, Any]:
        """Fallback to direct PostgreSQL query if MCP unavailable."""
        # Direct database query (implementation omitted for brevity)
        # This would query the document-consolidator's PostgreSQL database directly
        return {
            'answer': 'MCP service unavailable, limited information available',
            'confidence': 0.0,
            'sources': []
        }
```

**Key Design Decisions:**
- **stdio transport:** Per ADR-001, no HTTP configuration needed
- **Two-tier caching:** Local LRU for warm data, Redis for hot data
- **5-minute TTL:** Balance freshness with performance
- **Three-tier fallback:** Local cache â†’ Redis â†’ MCP â†’ Direct PostgreSQL

---

#### 11.3.7 State Bridge Implementation (Phase 16)

**Responsibilities:**
- Connect to context-orchestrator MCP server via stdio
- Create hybrid checkpoints (micro/macro/named)
- Serialize tool state with compression
- Support resume from checkpoint after failure

**Python Implementation:**

```python
import asyncio
import json
import gzip
from typing import Dict, Any, Optional
from datetime import datetime

class StateBridge:
    def __init__(self, mcp_server_path: str):
        self.mcp_server_path = mcp_server_path
        self.mcp_process = None
        self.request_id = 0

    async def start(self):
        """Start MCP server process via stdio."""
        self.mcp_process = await asyncio.create_subprocess_exec(
            'node', self.mcp_server_path,
            stdin=asyncio.subprocess.PIPE,
            stdout=asyncio.subprocess.PIPE,
            stderr=asyncio.subprocess.PIPE
        )
        await asyncio.sleep(0.5)

    async def save_micro_checkpoint(
        self,
        invocation_id: str,
        tool_id: str,
        tool_version: str,
        state: Dict[str, Any]
    ) -> str:
        """Save micro-checkpoint to Redis (30s cadence, 1h TTL)."""
        
        checkpoint = {
            'schema_version': '1.0',
            'invocation_id': invocation_id,
            'tool_id': tool_id,
            'tool_version': tool_version,
            'checkpoint_type': 'micro',
            'timestamp': datetime.utcnow().isoformat(),
            'state': state
        }

        # Compress if > 10 KB
        serialized = json.dumps(checkpoint)
        if len(serialized) > 10240:
            checkpoint_data = gzip.compress(serialized.encode())
            checkpoint['compressed'] = True
        else:
            checkpoint_data = serialized

        try:
            await self._call_mcp_method(
                'save_context_snapshot',
                {
                    'taskId': invocation_id,
                    'updates': {
                        'immediateContext': {
                            'workingOn': state.get('current_phase'),
                            'lastAction': state.get('last_action'),
                            'nextStep': state.get('next_step')
                        }
                    },
                    'syncToFile': False  # Skip file sync for micro-checkpoints
                }
            )
            return checkpoint['timestamp']
        except Exception as e:
            # Non-fatal: log and continue
            return None

    async def save_macro_checkpoint(
        self,
        invocation_id: str,
        tool_id: str,
        tool_version: str,
        state: Dict[str, Any],
        label: str
    ) -> str:
        """Save macro-checkpoint to PostgreSQL (milestone events)."""

        checkpoint = {
            'schema_version': '1.0',
            'invocation_id': invocation_id,
            'tool_id': tool_id,
            'tool_version': tool_version,
            'checkpoint_type': 'macro',
            'timestamp': datetime.utcnow().isoformat(),
            'state': state,
            'label': label
        }

        # Always compress macro-checkpoints
        serialized = json.dumps(checkpoint)
        checkpoint_data = gzip.compress(serialized.encode())

        try:
            result = await self._call_mcp_method(
                'create_checkpoint',
                {
                    'taskId': invocation_id,
                    'label': label,
                    'checkpointType': 'milestone',
                    'description': f"Tool {tool_id} checkpoint: {label}"
                }
            )
            return result.get('checkpointId')
        except Exception as e:
            raise RuntimeError(f"Failed to create macro-checkpoint: {str(e)}")

    async def resume_from_checkpoint(
        self,
        invocation_id: str,
        checkpoint_id: Optional[str] = None
    ) -> Dict[str, Any]:
        """Resume tool execution from checkpoint."""

        try:
            context = await self._call_mcp_method(
                'get_unified_context',
                {
                    'taskId': invocation_id,
                    'includeVersionHistory': True if checkpoint_id else False
                }
            )

            # If specific checkpoint requested, rollback
            if checkpoint_id:
                await self._call_mcp_method(
                    'rollback_to',
                    {
                        'taskId': invocation_id,
                        'target': {'type': 'checkpoint', 'checkpointId': checkpoint_id}
                    }
                )

            # Deserialize state
            state = context.get('immediateContext', {}).get('state', {})

            # Decompress if needed
            if state.get('compressed'):
                decompressed = gzip.decompress(state['data'])
                state = json.loads(decompressed.decode())

            return state

        except Exception as e:
            raise RuntimeError(f"Failed to resume from checkpoint: {str(e)}")

    async def _call_mcp_method(self, method: str, params: Dict[str, Any]) -> Dict[str, Any]:
        """Call MCP server method via JSON-RPC 2.0."""
        if not self.mcp_process:
            raise RuntimeError("MCP server not started")

        self.request_id += 1
        request = {
            'jsonrpc': '2.0',
            'id': self.request_id,
            'method': method,
            'params': params
        }

        request_json = json.dumps(request) + '\n'
        self.mcp_process.stdin.write(request_json.encode())
        await self.mcp_process.stdin.drain()

        response_line = await asyncio.wait_for(
            self.mcp_process.stdout.readline(),
            timeout=10.0
        )
        response = json.loads(response_line.decode())

        if 'error' in response:
            raise RuntimeError(f"MCP error: {response['error']}")

        return response.get('result', {})
```

**Key Design Decisions:**
- **Hybrid checkpointing:** Micro (Redis/30s) for resume, macro (PostgreSQL/milestones) for audit
- **Compression:** gzip for >10KB checkpoints, 60-80% storage reduction
- **Delta encoding:** Reference parent_checkpoint_id for incremental state
- **90-day retention:** Macro-checkpoints archived to S3 Glacier after 90 days

---

### 11.4 Code Examples

#### 11.4.1 Tool Invocation Handler (Complete Flow)

```python
from fastapi import FastAPI, HTTPException, Header
from typing import Optional
import uuid
from datetime import datetime

app = FastAPI()

@app.post("/v1/tools/invoke")
async def invoke_tool(
    request: ToolInvokeRequest,
    authorization: str = Header(...)
):
    """
    Complete tool invocation flow integrating all components.
    """
    invocation_id = str(uuid.uuid4())
    start_time = datetime.utcnow()

    try:
        # 1. Extract capability token
        if not authorization.startswith('Bearer '):
            raise HTTPException(status_code=401, detail="Missing bearer token")
        capability_token = authorization[7:]

        # 2. Retrieve tool version from registry
        tool_version = await tool_registry.get_tool_version(
            request.tool_id,
            request.tool_version or 'latest'
        )
        if not tool_version:
            await audit_logger.log_event({
                'event_type': 'tool.invoke.error',
                'invocation_id': invocation_id,
                'tool_id': request.tool_id,
                'error_code': 'E3101',
                'error_message': 'Tool not found'
            })
            raise HTTPException(status_code=404, detail="Tool not found")

        # 3. Check permissions
        permission_result = await permission_checker.check_permission(
            capability_token,
            request.tool_id,
            tool_version.version,
            tool_version.required_permissions
        )
        if not permission_result['allowed']:
            await audit_logger.log_event({
                'event_type': 'tool.invoke.denied',
                'invocation_id': invocation_id,
                'tool_id': request.tool_id,
                'error_code': permission_result.get('error_code', 'E3200'),
                'error_message': permission_result['reason']
            })
            raise HTTPException(status_code=403, detail=permission_result['reason'])

        # 4. Validate input parameters
        validation_result = result_validator.validate_input_parameters(
            request.parameters,
            tool_version.manifest['parameters']
        )
        if not validation_result['valid']:
            raise HTTPException(status_code=400, detail=validation_result['error'])

        # 5. Check circuit breaker for external APIs
        if tool_version.manifest.get('external_service'):
            service_id = tool_version.manifest['external_service']
            cb = CircuitBreakerController(redis_client, service_id)
            if not await cb.allow_request():
                raise HTTPException(status_code=503, detail="Service unavailable (circuit breaker open)")

        # 6. Retrieve credentials from vault (if needed)
        credentials = None
        if 'credentials' in tool_version.required_permissions:
            credentials = await secrets_manager.get_ephemeral_credentials(
                tool_id=request.tool_id,
                lifetime=tool_version.timeout_default
            )

        # 7. Execute tool in nested sandbox
        try:
            result = await tool_executor.execute_tool_sync(
                tool_id=request.tool_id,
                tool_version=tool_version.version,
                parameters=validation_result['result'],
                timeout=tool_version.timeout_default,
                resource_limits=tool_version.manifest.get('resource_limits', {}),
                network_policy=tool_version.manifest.get('network_policy'),
                credentials=credentials,
                invocation_id=invocation_id
            )

            # Record success for circuit breaker
            if tool_version.manifest.get('external_service'):
                await cb.record_success()

        except Exception as e:
            # Record failure for circuit breaker
            if tool_version.manifest.get('external_service'):
                await cb.record_failure()
            raise

        # 8. Validate result against schema
        if tool_version.result_schema:
            validation_result = result_validator.validate_result(
                result['output'],
                tool_version.result_schema,
                sanitize=True
            )
            if not validation_result['valid']:
                raise HTTPException(status_code=500, detail="Tool returned invalid output")
            result['output'] = validation_result['result']

        # 9. Log successful invocation
        duration_ms = int((datetime.utcnow() - start_time).total_seconds() * 1000)
        await audit_logger.log_event({
            'event_type': 'tool.invoke.success',
            'invocation_id': invocation_id,
            'tool_id': request.tool_id,
            'tool_version': tool_version.version,
            'duration_ms': duration_ms,
            'status': result['status']
        })

        return {
            'invocation_id': invocation_id,
            'status': result['status'],
            'result': result['output'],
            'execution_time_ms': duration_ms
        }

    except HTTPException:
        raise
    except Exception as e:
        # Log unexpected error
        await audit_logger.log_event({
            'event_type': 'tool.invoke.error',
            'invocation_id': invocation_id,
            'tool_id': request.tool_id,
            'error_code': 'E3000',
            'error_message': str(e)
        })
        raise HTTPException(status_code=500, detail="Internal server error")
```

---

### 11.5 Error Code Registry (E3000-E3999)

The Tool Execution Layer uses error codes in the E3000-E3999 range.

#### E3000-E3099: General Errors

| Error Code | Description | HTTP Status | Resolution |
|------------|-------------|-------------|------------|
| E3000 | Internal server error | 500 | Retry with exponential backoff |
| E3001 | Service temporarily unavailable | 503 | Wait and retry |
| E3002 | Request timeout | 504 | Increase timeout or optimize tool |
| E3003 | Rate limit exceeded | 429 | Slow down request rate |
| E3004 | Invalid request format | 400 | Check request schema |

#### E3100-E3149: Tool Registry Errors

| Error Code | Description | HTTP Status | Resolution |
|------------|-------------|-------------|------------|
| E3101 | Tool not found | 404 | Verify tool_id exists in registry |
| E3102 | Tool version not found | 404 | Check available versions |
| E3103 | Tool version conflict | 409 | Resolve version range constraints |
| E3104 | Tool deprecated | 410 | Use recommended replacement tool |
| E3105 | Tool manifest invalid | 422 | Fix manifest schema |
| E3106 | Semantic search failed | 500 | Check Ollama service availability |

#### E3200-E3249: Permission Errors

| Error Code | Description | HTTP Status | Resolution |
|------------|-------------|-------------|------------|
| E3201 | Token expired | 401 | Obtain new capability token |
| E3202 | Invalid token signature | 401 | Verify token signing key |
| E3203 | Malformed token | 401 | Check JWT format |
| E3204 | Tool not in capability token | 403 | Request token with tool permission |
| E3205 | ABAC engine error | 503 | Check ABAC service health |
| E3206 | Permission denied | 403 | Request additional permissions |
| E3207 | DID not found | 404 | Verify agent DID registration |

#### E3300-E3349: Validation Errors

| Error Code | Description | HTTP Status | Resolution |
|------------|-------------|-------------|------------|
| E3301 | Schema validation failed | 400 | Fix parameters to match schema |
| E3302 | Type coercion failed | 400 | Provide correct parameter types |
| E3303 | Result validation failed | 500 | Tool returned invalid output |
| E3304 | PII sanitization error | 500 | Check sanitization rules |
| E3305 | Injection attack detected | 400 | Remove malicious input |

#### E3400-E3449: Execution Errors

| Error Code | Description | HTTP Status | Resolution |
|------------|-------------|-------------|------------|
| E3401 | Tool execution failed | 500 | Check tool logs |
| E3402 | Tool timeout | 504 | Increase timeout or optimize tool |
| E3403 | Tool OOM killed | 500 | Increase memory limit |
| E3404 | Tool crashed | 500 | Check tool stability |
| E3405 | Sandbox creation failed | 500 | Check Kubernetes cluster health |
| E3406 | Network policy violation | 403 | Verify allowed domains |
| E3407 | Resource limit exceeded | 429 | Reduce resource usage |

#### E3500-E3549: Circuit Breaker Errors

| Error Code | Description | HTTP Status | Resolution |
|------------|-------------|-------------|------------|
| E3501 | Circuit breaker open | 503 | Wait for timeout period |
| E3502 | External service unavailable | 503 | Check service health |
| E3503 | External service timeout | 504 | Increase timeout or check service |
| E3504 | Rate limit exceeded (external) | 429 | Reduce request rate |

#### E3600-E3649: Secrets Management Errors

| Error Code | Description | HTTP Status | Resolution |
|------------|-------------|-------------|------------|
| E3601 | Vault unavailable | 503 | Check Vault service |
| E3602 | Credential not found | 404 | Provision credentials in Vault |
| E3603 | Credential expired | 401 | Rotate credentials |
| E3604 | Credential decryption failed | 500 | Verify encryption keys |

#### E3700-E3749: Async Execution Errors

| Error Code | Description | HTTP Status | Resolution |
|------------|-------------|-------------|------------|
| E3701 | Job queue full | 503 | Wait and retry |
| E3702 | Job not found | 404 | Verify invocation_id |
| E3703 | Job cancelled | 499 | Resubmit if needed |
| E3704 | Webhook delivery failed | 500 | Check webhook endpoint |

#### E3800-E3849: Audit Logging Errors

| Error Code | Description | HTTP Status | Resolution |
|------------|-------------|-------------|------------|
| E3801 | Kafka unavailable | 503 | Check Kafka cluster |
| E3802 | Event serialization failed | 500 | Check event schema |
| E3803 | Audit backpressure | 503 | Reduce event rate |

#### E3850-E3899: MCP Document Bridge Errors (Phase 15)

| Error Code | Description | HTTP Status | Resolution |
|------------|-------------|-------------|------------|
| E3851 | MCP server unavailable | 503 | Check document-consolidator service |
| E3852 | Document not found | 404 | Verify document exists |
| E3853 | Document query timeout | 504 | Simplify query or increase timeout |
| E3854 | Document cache miss | 200 | Normal, query will hit database |
| E3855 | Document permission denied | 403 | Request document access |
| E3856 | MCP protocol error | 500 | Check MCP server logs |

#### E3900-E3949: MCP State Bridge Errors (Phase 16)

| Error Code | Description | HTTP Status | Resolution |
|------------|-------------|-------------|------------|
| E3901 | MCP server unavailable | 503 | Check context-orchestrator service |
| E3902 | Checkpoint creation failed | 500 | Check PostgreSQL/Redis health |
| E3903 | Checkpoint not found | 404 | Verify checkpoint_id |
| E3904 | Checkpoint corrupted | 500 | Use earlier checkpoint |
| E3905 | Resume failed | 500 | Restart from scratch |
| E3906 | State serialization failed | 500 | Reduce state size |
| E3907 | MCP protocol error | 500 | Check MCP server logs |

---

## Section 12: Testing Strategy

### 12.1 Test Categories

The Tool Execution Layer testing strategy follows a five-tier pyramid:

```
              [Security Tests]
             /                \
        [Chaos Tests]    [Performance Tests]
       /                                    \
  [Integration Tests]              [Integration Tests]
 /                                                    \
[Unit Tests - Tool Registry, Permission, Validator, ...]
```

**Test Distribution:**
- Unit Tests: 60% of total test count
- Integration Tests: 25%
- Performance Tests: 10%
- Chaos Tests: 3%
- Security Tests: 2%

**Test Execution Frequency:**
- Unit Tests: Every commit (CI pipeline)
- Integration Tests: Every pull request
- Performance Tests: Nightly
- Chaos Tests: Weekly
- Security Tests: Release candidates only

---

### 12.2 Unit Tests (Per Component)

#### 12.2.1 Tool Registry Tests

```python
import pytest
from tool_registry import ToolRegistry, ToolDefinition, ToolVersion

@pytest.mark.asyncio
async def test_register_tool_success(db_pool, ollama_client):
    """Test successful tool registration."""
    registry = ToolRegistry(db_pool, ollama_client)
    
    definition = ToolDefinition(
        tool_id='test_tool',
        name='Test Tool',
        description='A tool for testing',
        current_version='1.0.0',
        provider='test',
        protocol='native',
        lifecycle_state='active'
    )
    
    version = ToolVersion(
        tool_id='test_tool',
        version='1.0.0',
        manifest={'description': 'Test tool', 'parameters': {}},
        result_schema={'type': 'object'},
        timeout_default=30,
        retry_policy=None,
        circuit_breaker_config=None,
        required_permissions=['network:https://api.test.com'],
        changelog='Initial release',
        breaking_changes=False
    )
    
    await registry.register_tool(definition, version)
    
    # Verify registration
    retrieved = await registry.get_tool_version('test_tool', '1.0.0')
    assert retrieved is not None
    assert retrieved.tool_id == 'test_tool'

@pytest.mark.asyncio
async def test_semantic_search(db_pool, ollama_client):
    """Test semantic search over tools."""
    registry = ToolRegistry(db_pool, ollama_client)
    
    # Register test tools
    await registry.register_tool(
        ToolDefinition('email_tool', 'Email Sender', 'Send emails to recipients', '1.0.0', 'test', 'native', 'active'),
        ToolVersion('email_tool', '1.0.0', {'description': 'Send emails'}, None, 30, None, None, [], None, False)
    )
    
    # Search for email tools
    results = await registry.semantic_search('send message to user')
    assert len(results) > 0
    assert results[0].tool_id == 'email_tool'

@pytest.mark.asyncio
async def test_version_resolution_semver(db_pool, ollama_client):
    """Test SemVer version resolution."""
    registry = ToolRegistry(db_pool, ollama_client)
    
    # Register multiple versions
    for version in ['1.0.0', '1.1.0', '1.2.0', '2.0.0']:
        await registry.register_tool(
            ToolDefinition('test_tool', 'Test', 'Test tool', version, 'test', 'native', 'active'),
            ToolVersion('test_tool', version, {'description': 'Test'}, None, 30, None, None, [], None, False)
        )
    
    # Resolve version range
    resolved = await registry.resolve_version('test_tool', '^1.0.0')
    assert resolved == '1.2.0'  # Highest 1.x version
    
    resolved = await registry.resolve_version('test_tool', '~1.1.0')
    assert resolved == '1.1.0'  # Patch updates only

@pytest.mark.asyncio
async def test_tool_deprecation(db_pool, ollama_client):
    """Test tool deprecation workflow."""
    registry = ToolRegistry(db_pool, ollama_client)
    
    # Register and then deprecate
    await registry.register_tool(
        ToolDefinition('old_tool', 'Old Tool', 'Deprecated tool', '1.0.0', 'test', 'native', 'active'),
        ToolVersion('old_tool', '1.0.0', {'description': 'Old'}, None, 30, None, None, [], None, False)
    )
    
    await registry.deprecate_tool('old_tool', 'https://docs.example.com/migration')
    
    # Verify deprecation
    tools = await registry.semantic_search('old tool')
    assert tools[0].lifecycle_state == 'deprecated'
    assert tools[0].migration_guide_url == 'https://docs.example.com/migration'
```

---

#### 12.2.2 Permission Checker Tests

```python
import pytest
import jwt
from permission_checker import PermissionChecker
from datetime import datetime, timedelta

@pytest.mark.asyncio
async def test_valid_capability_token(redis_client, jwt_keypair):
    """Test successful permission check with valid token."""
    checker = PermissionChecker(redis_client, 'http://abac:8080', jwt_keypair['public'])
    
    # Create valid token
    token_payload = {
        'sub': 'did:example:agent123',
        'exp': datetime.utcnow() + timedelta(hours=1),
        'tools': [
            {'tool_id': 'test_tool', 'version_range': '^1.0.0'}
        ]
    }
    token = jwt.encode(token_payload, jwt_keypair['private'], algorithm='RS256')
    
    # Mock ABAC response
    # (In real test, use httpx_mock fixture)
    
    result = await checker.check_permission(token, 'test_tool', '1.0.0', ['network:*'])
    assert result['allowed'] == True

@pytest.mark.asyncio
async def test_expired_token(redis_client, jwt_keypair):
    """Test permission denial for expired token."""
    checker = PermissionChecker(redis_client, 'http://abac:8080', jwt_keypair['public'])
    
    # Create expired token
    token_payload = {
        'sub': 'did:example:agent123',
        'exp': datetime.utcnow() - timedelta(hours=1),  # Expired
        'tools': [{'tool_id': 'test_tool', 'version_range': '*'}]
    }
    token = jwt.encode(token_payload, jwt_keypair['private'], algorithm='RS256')
    
    result = await checker.check_permission(token, 'test_tool', '1.0.0', [])
    assert result['allowed'] == False
    assert result['error_code'] == 'E3201'

@pytest.mark.asyncio
async def test_permission_cache_hit(redis_client, jwt_keypair):
    """Test permission cache reduces ABAC queries."""
    checker = PermissionChecker(redis_client, 'http://abac:8080', jwt_keypair['public'])
    
    token_payload = {
        'sub': 'did:example:agent123',
        'exp': datetime.utcnow() + timedelta(hours=1),
        'tools': [{'tool_id': 'test_tool', 'version_range': '*'}]
    }
    token = jwt.encode(token_payload, jwt_keypair['private'], algorithm='RS256')
    
    # First call - cache miss
    result1 = await checker.check_permission(token, 'test_tool', '1.0.0', [])
    
    # Second call - cache hit (mock ABAC should not be called)
    result2 = await checker.check_permission(token, 'test_tool', '1.0.0', [])
    
    assert result1 == result2
    # Verify cache hit (test implementation would track ABAC call count)

@pytest.mark.asyncio
async def test_cache_invalidation_on_policy_update(redis_client, jwt_keypair):
    """Test cache invalidation via Redis pub/sub."""
    checker = PermissionChecker(redis_client, 'http://abac:8080', jwt_keypair['public'])
    
    # Cache a permission
    cache_key = 'perm:did:example:agent123:test_tool:1.0.0'
    await redis_client.setex(cache_key, 300, '{"allowed": true}')
    
    # Simulate policy update notification
    await redis_client.publish('abac:policy:updates', json.dumps({
        'affected_subjects': ['did:example:agent123']
    }))
    
    # Start cache invalidation listener in background
    asyncio.create_task(checker.subscribe_to_policy_updates())
    await asyncio.sleep(0.5)
    
    # Verify cache cleared
    cached = await redis_client.get(cache_key)
    assert cached is None
```

---

#### 12.2.3 Circuit Breaker Tests

```python
import pytest
from circuit_breaker import CircuitBreakerController, CircuitBreakerState

@pytest.mark.asyncio
async def test_circuit_breaker_closes_on_success(redis_client):
    """Test circuit breaker remains closed with successful requests."""
    cb = CircuitBreakerController(redis_client, 'test_service')
    
    # Record successful requests
    for _ in range(10):
        assert await cb.allow_request() == True
        await cb.record_success()
    
    state = await cb.get_state()
    assert state == CircuitBreakerState.CLOSED

@pytest.mark.asyncio
async def test_circuit_breaker_opens_on_failure_threshold(redis_client):
    """Test circuit breaker opens after failure threshold."""
    cb = CircuitBreakerController(redis_client, 'test_service')
    cb.failure_threshold = 5
    
    # Record failures
    for i in range(5):
        assert await cb.allow_request() == True
        await cb.record_failure()
    
    # Should be OPEN now
    state = await cb.get_state()
    assert state == CircuitBreakerState.OPEN
    assert await cb.allow_request() == False

@pytest.mark.asyncio
async def test_circuit_breaker_half_open_after_timeout(redis_client):
    """Test circuit breaker transitions to half-open after timeout."""
    cb = CircuitBreakerController(redis_client, 'test_service')
    cb.failure_threshold = 3
    cb.timeout_seconds = 2  # Short timeout for testing
    
    # Trip breaker
    for _ in range(3):
        await cb.record_failure()
    
    assert await cb.get_state() == CircuitBreakerState.OPEN
    
    # Wait for timeout
    await asyncio.sleep(2.5)
    
    # Should transition to HALF_OPEN
    assert await cb.allow_request() == True
    assert await cb.get_state() == CircuitBreakerState.HALF_OPEN

@pytest.mark.asyncio
async def test_circuit_breaker_canary_testing(redis_client):
    """Test half-open state limits canary requests."""
    cb = CircuitBreakerController(redis_client, 'test_service')
    cb.half_open_max_calls = 5
    
    # Manually set to HALF_OPEN
    await cb._transition_to(CircuitBreakerState.HALF_OPEN)
    
    # First 5 requests allowed
    for i in range(5):
        assert await cb.allow_request() == True
    
    # 6th request blocked
    assert await cb.allow_request() == False

@pytest.mark.asyncio
async def test_circuit_breaker_closes_after_half_open_success(redis_client):
    """Test half-open transitions to closed after successes."""
    cb = CircuitBreakerController(redis_client, 'test_service')
    cb.success_threshold = 3
    
    await cb._transition_to(CircuitBreakerState.HALF_OPEN)
    
    # Record successes
    for _ in range(3):
        await cb.record_success()
    
    assert await cb.get_state() == CircuitBreakerState.CLOSED
```

---

#### 12.2.4 Result Validator Tests

```python
import pytest
from result_validator import ResultValidator

def test_schema_validation_success():
    """Test successful JSON Schema validation."""
    validator = ResultValidator()
    
    schema = {
        'type': 'object',
        'properties': {
            'name': {'type': 'string'},
            'age': {'type': 'integer'}
        },
        'required': ['name']
    }
    
    result = validator.validate_result(
        {'name': 'Alice', 'age': 30},
        schema
    )
    
    assert result['valid'] == True

def test_schema_validation_failure():
    """Test schema validation catches invalid data."""
    validator = ResultValidator()
    
    schema = {
        'type': 'object',
        'properties': {
            'name': {'type': 'string'},
            'age': {'type': 'integer'}
        },
        'required': ['name']
    }
    
    result = validator.validate_result(
        {'age': 'thirty'},  # Invalid: age should be integer
        schema
    )
    
    assert result['valid'] == False
    assert result['error_code'] == 'E3301'

def test_type_coercion():
    """Test automatic type coercion."""
    validator = ResultValidator()
    
    schema = {
        'type': 'object',
        'properties': {
            'count': {'type': 'integer'},
            'price': {'type': 'number'},
            'active': {'type': 'boolean'}
        }
    }
    
    result = validator.validate_result(
        {'count': '42', 'price': '19.99', 'active': 'true'},
        schema
    )
    
    assert result['valid'] == True
    assert result['result']['count'] == 42
    assert result['result']['price'] == 19.99
    assert result['result']['active'] == True

def test_pii_sanitization_regex():
    """Test PII sanitization with regex patterns."""
    validator = ResultValidator()
    
    data = {
        'message': 'Contact me at alice@example.com or 555-123-4567',
        'ssn': '123-45-6789'
    }
    
    schema = {'type': 'object'}
    result = validator.validate_result(data, schema, sanitize=True)
    
    assert result['valid'] == True
    assert '[EMAIL_REDACTED]' in result['result']['message']
    assert '[PHONE_REDACTED]' in result['result']['message']
    assert '[SSN_REDACTED]' in result['result']['ssn']

def test_pii_sanitization_field_based():
    """Test field-based PII sanitization."""
    validator = ResultValidator()
    
    data = {
        'username': 'alice',
        'password': 'secret123',
        'apiKey': 'sk-1234567890'
    }
    
    schema = {'type': 'object'}
    result = validator.validate_result(data, schema, sanitize=True)
    
    assert result['valid'] == True
    assert result['result']['username'] == 'alice'
    assert result['result']['password'] == '[REDACTED]'
    assert result['result']['apiKey'] == '[REDACTED]'

def test_injection_attack_prevention():
    """Test SQL injection and command injection prevention."""
    validator = ResultValidator()
    
    params = {
        'query': "SELECT * FROM users WHERE id = 1; DROP TABLE users;--",
        'command': "ls /tmp; rm -rf /"
    }
    
    schema = {'type': 'object'}
    result = validator.validate_input_parameters(params, schema)
    
    assert result['valid'] == True
    # Verify dangerous characters stripped
    assert 'DROP' not in result['result']['query']
    assert ';' not in result['result']['command']
```

---

#### 12.2.5 Document Bridge Tests (Mock MCP)

```python
import pytest
from document_bridge import DocumentBridge
import json

@pytest.mark.asyncio
async def test_document_query_with_local_cache(redis_client, mock_mcp_server):
    """Test document query hits local cache."""
    bridge = DocumentBridge(mock_mcp_server, redis_client)
    
    # Prepopulate local cache
    cache_key = f"doc:sot:{hash('test query')}:{hash('None')}"
    expected_result = {'answer': 'Cached result', 'confidence': 0.95}
    bridge.local_cache[cache_key] = expected_result
    
    result = await bridge.get_source_of_truth('test query')
    
    assert result == expected_result
    # MCP server should not be called

@pytest.mark.asyncio
async def test_document_query_with_redis_cache(redis_client, mock_mcp_server):
    """Test document query hits Redis cache."""
    bridge = DocumentBridge(mock_mcp_server, redis_client)
    
    # Prepopulate Redis cache
    redis_key = 'doc:query:test_key'
    expected_result = {'answer': 'Redis cached', 'confidence': 0.9}
    await redis_client.setex(redis_key, 300, json.dumps(expected_result))
    
    # Query should hit Redis, not MCP
    # (Test would verify MCP not called via mock)

@pytest.mark.asyncio
async def test_document_query_mcp_call(redis_client, mock_mcp_server):
    """Test document query calls MCP server on cache miss."""
    bridge = DocumentBridge(mock_mcp_server, redis_client)
    await bridge.start()
    
    # Mock MCP server response
    expected_result = {
        'answer': 'MCP result',
        'confidence': 0.85,
        'sources': [{'document_id': 'doc123', 'excerpt': '...'}]
    }
    # (Mock would inject this response)
    
    result = await bridge.get_source_of_truth('new query')
    
    # Verify result cached in Redis
    # Verify result cached locally
    await bridge.stop()

@pytest.mark.asyncio
async def test_document_query_fallback_on_mcp_failure(redis_client):
    """Test fallback to direct PostgreSQL on MCP failure."""
    bridge = DocumentBridge('/nonexistent/mcp/server', redis_client)
    
    # MCP server doesn't start - should fallback
    result = await bridge.get_source_of_truth('query')
    
    assert 'MCP service unavailable' in result['answer']
    assert result['confidence'] == 0.0

@pytest.mark.asyncio
async def test_find_overlaps(redis_client, mock_mcp_server):
    """Test overlap detection via MCP."""
    bridge = DocumentBridge(mock_mcp_server, redis_client)
    await bridge.start()
    
    overlaps = await bridge.find_overlaps(
        scope=['doc1', 'doc2'],
        similarity_threshold=0.8
    )
    
    # Verify MCP call made with correct parameters
    await bridge.stop()
```

---

#### 12.2.6 State Bridge Tests (Mock MCP)

```python
import pytest
from state_bridge import StateBridge
import json

@pytest.mark.asyncio
async def test_save_micro_checkpoint(mock_mcp_server):
    """Test micro-checkpoint creation."""
    bridge = StateBridge(mock_mcp_server)
    await bridge.start()
    
    state = {
        'current_phase': 'processing',
        'progress': 0.45,
        'last_action': 'fetched_data',
        'next_step': 'transform_data'
    }
    
    checkpoint_id = await bridge.save_micro_checkpoint(
        'invocation123',
        'test_tool',
        '1.0.0',
        state
    )
    
    assert checkpoint_id is not None
    await bridge.stop()

@pytest.mark.asyncio
async def test_save_macro_checkpoint(mock_mcp_server):
    """Test macro-checkpoint creation."""
    bridge = StateBridge(mock_mcp_server)
    await bridge.start()
    
    state = {
        'current_phase': 'completed',
        'progress': 1.0,
        'results': {'count': 42}
    }
    
    checkpoint_id = await bridge.save_macro_checkpoint(
        'invocation123',
        'test_tool',
        '1.0.0',
        state,
        'final_results'
    )
    
    assert checkpoint_id is not None
    await bridge.stop()

@pytest.mark.asyncio
async def test_resume_from_checkpoint(mock_mcp_server):
    """Test resuming execution from checkpoint."""
    bridge = StateBridge(mock_mcp_server)
    await bridge.start()
    
    # Create checkpoint
    original_state = {'phase': 'step2', 'data': {'key': 'value'}}
    checkpoint_id = await bridge.save_micro_checkpoint(
        'invocation123', 'test_tool', '1.0.0', original_state
    )
    
    # Resume from checkpoint
    restored_state = await bridge.resume_from_checkpoint('invocation123', checkpoint_id)
    
    assert restored_state['phase'] == 'step2'
    assert restored_state['data']['key'] == 'value'
    await bridge.stop()

@pytest.mark.asyncio
async def test_checkpoint_compression(mock_mcp_server):
    """Test checkpoint compression for large states."""
    bridge = StateBridge(mock_mcp_server)
    await bridge.start()
    
    # Create large state (> 10 KB)
    large_state = {
        'data': ['x' * 1000 for _ in range(20)]  # ~20 KB
    }
    
    checkpoint_id = await bridge.save_macro_checkpoint(
        'invocation123', 'test_tool', '1.0.0', large_state, 'large_state'
    )
    
    # Verify compression applied (test would check MCP call payload size)
    assert checkpoint_id is not None
    await bridge.stop()
```

---

### 12.3 Integration Tests

#### 12.3.1 Tool Invocation End-to-End

```python
import pytest
from httpx import AsyncClient

@pytest.mark.integration
@pytest.mark.asyncio
async def test_complete_tool_invocation_flow(test_app, db_pool, redis_client):
    """Test complete tool invocation from API to execution."""
    async with AsyncClient(app=test_app, base_url="http://test") as client:
        # 1. Register tool
        tool_manifest = {
            'tool_id': 'echo_tool',
            'version': '1.0.0',
            'name': 'Echo Tool',
            'description': 'Echoes input back',
            'parameters': {
                'type': 'object',
                'properties': {
                    'message': {'type': 'string'}
                },
                'required': ['message']
            },
            'result_schema': {
                'type': 'object',
                'properties': {
                    'echoed': {'type': 'string'}
                }
            }
        }
        
        response = await client.post('/v1/tools/register', json=tool_manifest)
        assert response.status_code == 201
        
        # 2. Generate capability token
        token = create_test_capability_token(['echo_tool'])
        
        # 3. Invoke tool
        response = await client.post(
            '/v1/tools/invoke',
            json={
                'tool_id': 'echo_tool',
                'tool_version': '1.0.0',
                'parameters': {'message': 'Hello World'}
            },
            headers={'Authorization': f'Bearer {token}'}
        )
        
        assert response.status_code == 200
        result = response.json()
        assert result['status'] == 'success'
        assert result['result']['echoed'] == 'Hello World'

@pytest.mark.integration
@pytest.mark.asyncio
async def test_tool_invocation_with_permission_denial(test_app):
    """Test tool invocation denied without proper permissions."""
    async with AsyncClient(app=test_app, base_url="http://test") as client:
        # Token without tool permission
        token = create_test_capability_token([])  # Empty permissions
        
        response = await client.post(
            '/v1/tools/invoke',
            json={
                'tool_id': 'echo_tool',
                'tool_version': '1.0.0',
                'parameters': {'message': 'Hello'}
            },
            headers={'Authorization': f'Bearer {token}'}
        )
        
        assert response.status_code == 403
        assert 'E3204' in response.json()['detail']
```

---

#### 12.3.2 ABAC Integration Test

```python
@pytest.mark.integration
@pytest.mark.asyncio
async def test_abac_engine_integration(test_app, abac_engine_url):
    """Test integration with ABAC engine for fine-grained permissions."""
    async with AsyncClient(app=test_app, base_url="http://test") as client:
        # Token with tool permission
        token = create_test_capability_token(['restricted_tool'])
        
        # First invocation - ABAC allows
        response = await client.post(
            '/v1/tools/invoke',
            json={
                'tool_id': 'restricted_tool',
                'tool_version': '1.0.0',
                'parameters': {'action': 'read'}
            },
            headers={'Authorization': f'Bearer {token}'}
        )
        assert response.status_code == 200
        
        # Update ABAC policy to deny
        # (Test helper updates ABAC engine)
        
        # Second invocation - ABAC denies
        response = await client.post(
            '/v1/tools/invoke',
            json={
                'tool_id': 'restricted_tool',
                'tool_version': '1.0.0',
                'parameters': {'action': 'delete'}
            },
            headers={'Authorization': f'Bearer {token}'}
        )
        assert response.status_code == 403
```

---

#### 12.3.3 Phase 15 Document Context Flow

```python
@pytest.mark.integration
@pytest.mark.asyncio
async def test_tool_with_document_context(test_app, document_consolidator_server):
    """Test tool accessing document context via Phase 15 bridge."""
    async with AsyncClient(app=test_app, base_url="http://test") as client:
        token = create_test_capability_token(['document_aware_tool'])
        
        # Tool implementation queries documents during execution
        response = await client.post(
            '/v1/tools/invoke',
            json={
                'tool_id': 'document_aware_tool',
                'tool_version': '1.0.0',
                'parameters': {
                    'document_query': 'API authentication requirements'
                }
            },
            headers={'Authorization': f'Bearer {token}'}
        )
        
        assert response.status_code == 200
        result = response.json()
        # Verify tool result includes document context
        assert 'document_context' in result['result']
        assert result['result']['document_context']['confidence'] > 0.7
```

---

#### 12.3.4 Phase 16 Checkpoint/Restore Flow

```python
@pytest.mark.integration
@pytest.mark.asyncio
async def test_long_running_tool_with_checkpoints(test_app, context_orchestrator_server):
    """Test long-running tool with checkpoint/restore."""
    async with AsyncClient(app=test_app, base_url="http://test") as client:
        token = create_test_capability_token(['long_running_tool'])
        
        # Start async tool invocation
        response = await client.post(
            '/v1/tools/invoke',
            json={
                'tool_id': 'long_running_tool',
                'tool_version': '1.0.0',
                'parameters': {'iterations': 100},
                'execution_mode': 'async'
            },
            headers={'Authorization': f'Bearer {token}'}
        )
        
        assert response.status_code == 202  # Accepted
        invocation_id = response.json()['invocation_id']
        
        # Wait for checkpoint creation
        await asyncio.sleep(35)  # Micro-checkpoint every 30s
        
        # Simulate failure - kill tool process
        # (Test helper kills the execution)
        
        # Resume from checkpoint
        response = await client.post(
            f'/v1/tools/resume/{invocation_id}',
            headers={'Authorization': f'Bearer {token}'}
        )
        
        assert response.status_code == 200
        # Verify tool resumed from checkpoint, not restarted from scratch
```

---

### 12.4 Performance Tests

#### 12.4.1 Tool Execution Latency

```python
@pytest.mark.performance
@pytest.mark.asyncio
async def test_tool_execution_latency_p95(test_app, metrics):
    """Test P95 tool execution latency < 500ms."""
    latencies = []
    
    async with AsyncClient(app=test_app, base_url="http://test") as client:
        token = create_test_capability_token(['fast_tool'])
        
        # Execute 100 invocations
        for _ in range(100):
            start = time.time()
            response = await client.post(
                '/v1/tools/invoke',
                json={
                    'tool_id': 'fast_tool',
                    'tool_version': '1.0.0',
                    'parameters': {}
                },
                headers={'Authorization': f'Bearer {token}'}
            )
            latency = (time.time() - start) * 1000  # Convert to ms
            latencies.append(latency)
            assert response.status_code == 200
        
        # Calculate P95
        latencies.sort()
        p95 = latencies[94]  # 95th percentile
        
        assert p95 < 500, f"P95 latency {p95}ms exceeds 500ms target"

@pytest.mark.performance
@pytest.mark.asyncio
async def test_concurrent_tool_invocations(test_app):
    """Test concurrent tool invocation throughput."""
    async with AsyncClient(app=test_app, base_url="http://test") as client:
        token = create_test_capability_token(['concurrent_tool'])
        
        async def invoke_tool():
            response = await client.post(
                '/v1/tools/invoke',
                json={
                    'tool_id': 'concurrent_tool',
                    'tool_version': '1.0.0',
                    'parameters': {}
                },
                headers={'Authorization': f'Bearer {token}'}
            )
            return response.status_code
        
        # Launch 50 concurrent invocations
        start = time.time()
        tasks = [invoke_tool() for _ in range(50)]
        results = await asyncio.gather(*tasks)
        duration = time.time() - start
        
        # All should succeed
        assert all(status == 200 for status in results)
        
        # Throughput > 20 req/sec
        throughput = 50 / duration
        assert throughput > 20, f"Throughput {throughput} req/s below 20 req/s target"
```

---

#### 12.4.2 Permission Check Latency

```python
@pytest.mark.performance
@pytest.mark.asyncio
async def test_permission_check_latency(permission_checker, redis_client):
    """Test permission check latency < 50ms (P95)."""
    latencies = []
    
    token = create_test_capability_token(['test_tool'])
    
    # Warm up cache
    await permission_checker.check_permission(token, 'test_tool', '1.0.0', [])
    
    # Measure cached performance
    for _ in range(100):
        start = time.time()
        await permission_checker.check_permission(token, 'test_tool', '1.0.0', [])
        latency = (time.time() - start) * 1000
        latencies.append(latency)
    
    latencies.sort()
    p95 = latencies[94]
    
    assert p95 < 50, f"P95 permission check latency {p95}ms exceeds 50ms target"
```

---

### 12.5 Chaos Tests

#### 12.5.1 External Service Failure

```python
@pytest.mark.chaos
@pytest.mark.asyncio
async def test_external_service_failure_resilience(test_app, chaos_engineering):
    """Test circuit breaker opens on external service failure."""
    async with AsyncClient(app=test_app, base_url="http://test") as client:
        token = create_test_capability_token(['external_api_tool'])
        
        # Inject failure into external service
        chaos_engineering.inject_fault('external_api', failure_rate=1.0)
        
        # First few invocations fail
        for i in range(5):
            response = await client.post(
                '/v1/tools/invoke',
                json={
                    'tool_id': 'external_api_tool',
                    'tool_version': '1.0.0',
                    'parameters': {}
                },
                headers={'Authorization': f'Bearer {token}'}
            )
            # Circuit breaker opens after threshold
            if i < 5:
                assert response.status_code == 500
        
        # Circuit breaker should be open now
        response = await client.post(
            '/v1/tools/invoke',
            json={
                'tool_id': 'external_api_tool',
                'tool_version': '1.0.0',
                'parameters': {}
            },
            headers={'Authorization': f'Bearer {token}'}
        )
        assert response.status_code == 503  # Service unavailable
        assert 'E3501' in response.text  # Circuit breaker open
        
        # Remove fault
        chaos_engineering.clear_faults()

@pytest.mark.chaos
@pytest.mark.asyncio
async def test_mcp_service_unavailability(test_app, chaos_engineering):
    """Test graceful degradation when MCP services unavailable."""
    async with AsyncClient(app=test_app, base_url="http://test") as client:
        token = create_test_capability_token(['document_aware_tool'])
        
        # Kill MCP document server
        chaos_engineering.kill_process('document-consolidator')
        
        # Tool invocation should still succeed with fallback
        response = await client.post(
            '/v1/tools/invoke',
            json={
                'tool_id': 'document_aware_tool',
                'tool_version': '1.0.0',
                'parameters': {'query': 'test'}
            },
            headers={'Authorization': f'Bearer {token}'}
        )
        
        assert response.status_code == 200
        result = response.json()
        # Should have fallback result with lower confidence
        assert result['result']['document_context']['confidence'] < 0.5
        
        # Restart MCP server
        chaos_engineering.start_process('document-consolidator')
```

---

#### 12.5.2 Checkpoint Corruption Recovery

```python
@pytest.mark.chaos
@pytest.mark.asyncio
async def test_checkpoint_corruption_recovery(test_app, chaos_engineering):
    """Test recovery from corrupted checkpoint."""
    async with AsyncClient(app=test_app, base_url="http://test") as client:
        token = create_test_capability_token(['long_running_tool'])
        
        # Start tool execution
        response = await client.post(
            '/v1/tools/invoke',
            json={
                'tool_id': 'long_running_tool',
                'tool_version': '1.0.0',
                'parameters': {'iterations': 50},
                'execution_mode': 'async'
            },
            headers={'Authorization': f'Bearer {token}'}
        )
        invocation_id = response.json()['invocation_id']
        
        # Wait for checkpoint
        await asyncio.sleep(35)
        
        # Corrupt checkpoint in Redis
        chaos_engineering.corrupt_redis_key(f"checkpoint:{invocation_id}")
        
        # Attempt resume - should fall back to earlier checkpoint
        response = await client.post(
            f'/v1/tools/resume/{invocation_id}',
            headers={'Authorization': f'Bearer {token}'}
        )
        
        # Should recover from PostgreSQL macro-checkpoint
        assert response.status_code == 200
```

---

### 12.6 Security Tests

#### 12.6.1 Sandbox Escape Attempt

```python
@pytest.mark.security
@pytest.mark.asyncio
async def test_sandbox_escape_prevention(test_app):
    """Test that malicious tools cannot escape sandbox."""
    async with AsyncClient(app=test_app, base_url="http://test") as client:
        token = create_test_capability_token(['malicious_tool'])
        
        # Tool attempts to read /etc/passwd
        response = await client.post(
            '/v1/tools/invoke',
            json={
                'tool_id': 'malicious_tool',
                'tool_version': '1.0.0',
                'parameters': {'file': '/etc/passwd'}
            },
            headers={'Authorization': f'Bearer {token}'}
        )
        
        # Should fail due to read-only filesystem
        assert response.status_code == 500
        # Verify /etc/passwd not in output
        assert '/etc/passwd' not in response.text

@pytest.mark.security
@pytest.mark.asyncio
async def test_privilege_escalation_prevention(test_app):
    """Test that tools cannot escalate privileges."""
    async with AsyncClient(app=test_app, base_url="http://test") as client:
        token = create_test_capability_token(['privilege_escalation_tool'])
        
        # Tool attempts to run 'sudo'
        response = await client.post(
            '/v1/tools/invoke',
            json={
                'tool_id': 'privilege_escalation_tool',
                'tool_version': '1.0.0',
                'parameters': {'command': 'sudo ls'}
            },
            headers={'Authorization': f'Bearer {token}'}
        )
        
        # Should fail - no sudo in sandbox
        assert response.status_code == 500
```

---

#### 12.6.2 Credential Exposure Prevention

```python
@pytest.mark.security
@pytest.mark.asyncio
async def test_credential_not_in_logs(test_app, audit_logger):
    """Test that credentials are not leaked in audit logs."""
    async with AsyncClient(app=test_app, base_url="http://test") as client:
        token = create_test_capability_token(['credential_tool'])
        
        response = await client.post(
            '/v1/tools/invoke',
            json={
                'tool_id': 'credential_tool',
                'tool_version': '1.0.0',
                'parameters': {
                    'api_key': 'sk-secret123456',
                    'password': 'supersecret'
                }
            },
            headers={'Authorization': f'Bearer {token}'}
        )
        
        # Check audit logs
        logs = await audit_logger.get_recent_logs(limit=10)
        
        for log in logs:
            # Credentials should be redacted
            assert 'sk-secret123456' not in json.dumps(log)
            assert 'supersecret' not in json.dumps(log)
            assert '[REDACTED]' in json.dumps(log)

@pytest.mark.security
@pytest.mark.asyncio
async def test_mcp_injection_attack(test_app):
    """Test prevention of MCP injection attacks."""
    async with AsyncClient(app=test_app, base_url="http://test") as client:
        token = create_test_capability_token(['document_aware_tool'])
        
        # Attempt to inject malicious MCP command
        malicious_query = '"; DROP TABLE documents;--'
        
        response = await client.post(
            '/v1/tools/invoke',
            json={
                'tool_id': 'document_aware_tool',
                'tool_version': '1.0.0',
                'parameters': {'query': malicious_query}
            },
            headers={'Authorization': f'Bearer {token}'}
        )
        
        # Should sanitize and not execute SQL
        assert response.status_code == 200
        # Verify no SQL injection occurred
```

---

### 12.7 Test Examples (pytest code)

**Test Fixtures:**

```python
# conftest.py
import pytest
import asyncpg
import aioredis
from httpx import AsyncClient

@pytest.fixture
async def db_pool():
    """PostgreSQL connection pool."""
    pool = await asyncpg.create_pool(
        'postgresql://user:pass@localhost/test_db',
        min_size=2,
        max_size=10
    )
    yield pool
    await pool.close()

@pytest.fixture
async def redis_client():
    """Redis client."""
    client = await aioredis.create_redis_pool('redis://localhost')
    yield client
    client.close()
    await client.wait_closed()

@pytest.fixture
def jwt_keypair():
    """RSA keypair for JWT signing."""
    from cryptography.hazmat.primitives.asymmetric import rsa
    from cryptography.hazmat.primitives import serialization
    
    private_key = rsa.generate_private_key(public_exponent=65537, key_size=2048)
    public_key = private_key.public_key()
    
    return {
        'private': private_key.private_bytes(
            encoding=serialization.Encoding.PEM,
            format=serialization.PrivateFormat.PKCS8,
            encryption_algorithm=serialization.NoEncryption()
        ),
        'public': public_key.public_bytes(
            encoding=serialization.Encoding.PEM,
            format=serialization.PublicFormat.SubjectPublicKeyInfo
        )
    }

@pytest.fixture
def mock_mcp_server(tmp_path):
    """Mock MCP server for testing."""
    # Implementation creates a fake MCP server process
    pass

def create_test_capability_token(tools: list) -> str:
    """Helper to create capability tokens for testing."""
    payload = {
        'sub': 'did:example:test_agent',
        'exp': datetime.utcnow() + timedelta(hours=1),
        'tools': [{'tool_id': tool_id, 'version_range': '*'} for tool_id in tools]
    }
    return jwt.encode(payload, test_private_key, algorithm='RS256')
```

---

## Section 13: Migration and Deployment

### 13.1 Deployment Strategy

#### 13.1.1 Container Image Specification

**Base Image:**
```dockerfile
FROM python:3.11-slim

# Install system dependencies
RUN apt-get update && apt-get install -y \
    postgresql-client \
    redis-tools \
    curl \
    && rm -rf /var/lib/apt/lists/*

# Create non-root user
RUN useradd -m -u 1000 toolexec && \
    mkdir -p /app && \
    chown -R toolexec:toolexec /app

WORKDIR /app

# Install Python dependencies
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copy application code
COPY --chown=toolexec:toolexec . .

USER toolexec

# Health check
HEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \
  CMD curl -f http://localhost:8080/health || exit 1

EXPOSE 8080

CMD ["python", "-m", "uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8080"]
```

**Key Design Decisions:**
- Non-root user for security
- Multi-stage build for smaller images
- Health checks for Kubernetes readiness

---

### 13.2 Infrastructure Prerequisites (per ADR-002)

#### 13.2.1 PostgreSQL 16 + pgvector Setup

**Production Deployment:**
- High availability with Patroni
- 3-node cluster (1 primary, 2 replicas)
- pgvector extension enabled
- Connection pooling via PgBouncer

#### 13.2.2 Redis 7 Cluster Setup

**Production Configuration:**
- 6-node cluster (3 masters + 3 replicas)
- Persistence: AOF + RDB snapshots
- Memory: 4GB per node minimum
- Eviction policy: allkeys-lru

#### 13.2.3 Ollama Deployment

**Optional Component:**
- Required for semantic tool search
- Mistral 7B model (4GB VRAM)
- CPU-only deployment acceptable for <100 req/s

#### 13.2.4 MCP Services via PM2

**Process Management:**
- document-consolidator on port stdio
- context-orchestrator on port stdio
- Auto-restart on failure
- Log rotation enabled

---

### 13.3 Upgrade Procedures

#### 13.3.1 Zero-Downtime Deployment

**Rolling Update Strategy:**
1. Deploy new version to 1 pod
2. Wait for health checks
3. Gradually roll out to remaining pods
4. Monitor error rates
5. Rollback if error rate > 1%

#### 13.3.2 Database Migration

**Alembic Migrations:**
- Always backward compatible
- Test on staging first
- Automated rollback on failure

#### 13.3.3 MCP Service Updates

**PM2 Reload:**
- Graceful restart with zero downtime
- stdio connections preserved
- Automatic health verification

---

### 13.4 Rollback Procedures

#### 13.4.1 Application Rollback

```bash
kubectl rollout undo deployment/tool-execution-layer -n agentic-platform
```

#### 13.4.2 Database Rollback

```bash
alembic downgrade -1
```

#### 13.4.3 MCP Service Rollback

```bash
git checkout <previous_tag>
npm run build
pm2 reload <service_name>
```

---

### 13.5 Disaster Recovery

#### 13.5.1 Tool Registry Backup

**Automated Daily Backups:**
- PostgreSQL dump to S3
- 30-day retention
- Point-in-time recovery enabled

#### 13.5.2 Circuit Breaker State Recovery

**Redis Persistence:**
- RDB snapshots every 15 minutes
- AOF with everysec fsync
- Automatic recovery on restart

#### 13.5.3 MCP Service Recovery

**Health Monitoring:**
- Automated health checks every 5 minutes
- Auto-restart on failure
- Alert escalation if recovery fails

#### 13.5.4 External Service Failover

**Multi-Region Configuration:**
- Primary + 2 failover endpoints
- Circuit breakers per endpoint
- Cached result fallback

---

## Section 14: Open Questions and Decisions

### 14.1 Resolved Questions

| Question | Decision | Rationale | Version |
|----------|----------|-----------|---------|
| **Q1: Tool Versioning (independent vs agent-tied)?** | Independent with semantic versioning (SemVer) | Tools evolve independently of agents. Agents specify version ranges (e.g., "^2.1.0"). Breaking changes require major version bump. Tool registry stores multiple versions concurrently. | 1.0 |
| **Q2: Long-running operations (>30s)?** | Hybrid checkpointing via Phase 16 State Bridge | Micro-checkpoints (Redis/30s) for resume, macro-checkpoints (PostgreSQL/milestones) for audit, named checkpoints (manual) for recovery. Async execution modes: polling (30s-15min), webhook (15min-24h), job queue (>24h). | 1.0 |
| **Q3: Credential rotation during invocations?** | Just-in-time retrieval, no mid-execution rotation | Credentials fetched from Vault at invocation start. Ephemeral lifetime = tool timeout. No mid-execution rotation (complexity vs benefit trade-off). Rotation happens between invocations. | 1.0 |
| **Q4: MCP tool adapter pattern?** | stdio JSON-RPC 2.0 bridge per ADR-001 | L03 spawns MCP server process via PM2. Opens stdin/stdout pipes. Capability negotiation on startup. Tool invocation serialized to JSON-RPC request. Response deserialized from stdout. No HTTP configuration needed. | 1.0 |
| **Q5: Phase 15 document context caching?** | Two-tier caching: Redis (hot) + local LRU (warm) | `get_source_of_truth` cached in Redis (5-min TTL). Document versions cached locally (immutable). Cache invalidation via Redis pub/sub. Direct PostgreSQL fallback on MCP unavailability. | 1.0 |
| **Q6: Phase 16 checkpoint granularity?** | Hybrid: micro (30s) + macro (event) + named (manual) | Micro-checkpoints to Redis for fine-grained resume. Macro-checkpoints to PostgreSQL for audit trail. Named checkpoints for critical recovery points. Granularity configurable per tool manifest. | 1.0 |
| **Q7: Redis vs PostgreSQL for circuit breaker?** | Redis for state, PostgreSQL for config/history | Circuit breaker state (open/closed, failure counts, timestamps) in Redis with TTL. Configuration (thresholds, timeouts) in PostgreSQL. State transitions logged to PostgreSQL for analytics. Per ADR-002. | 1.0 |

---

### 14.2 Deferred Decisions

| Decision | Reason for Deferral | Target Version | Dependencies |
|----------|---------------------|----------------|--------------|
| **Multi-tool workflow orchestration** | Requires Integration Layer (L11) workflow engine. L03 provides atomic tool invocation only. Workflow logic belongs at higher layer. | v2.0 | L11 specification completion |
| **Tool dependency graph resolution** | Depends on workflow orchestration decision. Currently, Integration Layer responsible for ordering tool calls. | v2.0 | Multi-tool workflows (above) |
| **gRPC alternative to REST API** | REST sufficient for v1.0. gRPC optimization deferred until performance requirements proven unmet. | v1.5 | Performance benchmarks |
| **Tool marketplace and discovery UI** | Developer experience feature. Command-line tools sufficient for v1.0. Web UI deferred to separate project. | v3.0 | None |
| **Advanced semantic search (RAG)** | Ollama embeddings + pgvector sufficient for <1000 tools. RAG needed only for >10K tools. | v2.0 | Tool registry scale requirements |

---

### 14.3 Assumptions

| Assumption | Confidence | Validation Plan | Risk if Invalid |
|------------|------------|-----------------|-----------------|
| **External APIs are RESTful** | High | 95% of enterprise APIs are REST. gRPC/GraphQL adapters can be added later. | Low - Adapter pattern extensible |
| **Tool execution < 2 hours** | Medium | Most agent tasks complete in minutes. Longer tasks use async mode with checkpoints. | Medium - May need job queue optimization |
| **10-100 concurrent tool invocations per agent** | Medium | Based on LangChain/LangGraph benchmarks. Actual workload TBD. | Medium - HPA can scale to 20 pods |
| **Circuit breaker thresholds are consistent across services** | Low | Services may have different SLAs. Thresholds may need per-service tuning. | Low - Configuration supports per-service overrides |
| **PII sanitization regex is sufficient** | Medium | Covers common patterns (email, SSN, CC). May miss domain-specific PII. | High - Requires ongoing updates |
| **MCP servers are reliable** | Medium | Phase 15/16 servers are critical dependencies. Fallback mechanisms in place. | High - Three-tier fallback mitigates |

---

### 14.4 Risks and Mitigations

| Risk | Likelihood | Impact | Mitigation | Owner |
|------|------------|--------|------------|-------|
| **External API rate limits exceeded** | High | High | Circuit breaker with rate limiting. Back-off strategy. Multiple API keys rotation. | L03 Team |
| **Sandbox escape vulnerability** | Low | Critical | gVisor/Firecracker isolation. Regular security audits. Penetration testing. | Security Team |
| **MCP server crashes** | Medium | High | PM2 auto-restart. Health monitoring. Three-tier fallback (cache â†’ MCP â†’ direct DB). | Platform Team |
| **PostgreSQL connection pool exhaustion** | Medium | High | Connection pooling with PgBouncer. HPA scaling. Connection limit alerts. | Database Team |
| **Redis memory exhaustion** | Medium | Medium | LRU eviction policy. Memory usage alerts. Scaling to 6-node cluster. | Platform Team |
| **Credential leakage in logs** | Medium | Critical | PII sanitization before logging. Field-based redaction. Log access controls. | Security Team |
| **Tool versioning conflicts** | High | Medium | SemVer enforcement. Version range validation. Breaking change warnings. | L03 Team |
| **Checkpoint storage growth** | High | Medium | Tiered retention (Redis 1h, PostgreSQL 90d, S3 Glacier 7y). Compression. | Platform Team |
| **Circuit breaker thrashing** | Medium | Medium | Half-open canary testing. Gradual recovery. Configurable thresholds. | L03 Team |
| **ABAC policy cache stale data** | Low | High | Redis pub/sub invalidation. 5-minute TTL. Cache miss fallback. | Data Layer Team |

---

## Section 15: References and Appendices

### 15.1 External References

| Reference | Version | URL | Usage |
|-----------|---------|-----|-------|
| **Model Context Protocol (MCP)** | 2025-11-25 | https://modelcontextprotocol.io/specification | Phase 15/16 integration, JSON-RPC 2.0 over stdio |
| **JSON-RPC 2.0 Specification** | 2.0 | https://www.jsonrpc.org/specification | MCP wire protocol |
| **Semantic Versioning (SemVer)** | 2.0.0 | https://semver.org | Tool versioning schema |
| **OpenAPI Specification** | 3.1 | https://spec.openapi.org/oas/v3.1.0 | External API tool definitions |
| **JSON Schema** | 2020-12 | https://json-schema.org/draft/2020-12/release-notes | Tool input/output validation |
| **OWASP Secrets Management Cheat Sheet** | 2024 | https://cheatsheetseries.owasp.org/cheatsheets/Secrets_Management_Cheat_Sheet.html | Credential injection patterns |
| **Kubernetes CRD API Reference** | v1 | https://kubernetes.io/docs/reference/kubernetes-api/ | Sandbox, NetworkPolicy definitions |
| **CloudEvents Specification** | 1.0 | https://cloudevents.io | Audit event format |
| **gVisor Documentation** | Latest | https://gvisor.dev/docs/ | Sandbox isolation (cloud) |
| **Firecracker MicroVM** | Latest | https://firecracker-microvm.github.io | Sandbox isolation (on-prem) |
| **Resilience4j Documentation** | 2.x | https://resilience4j.readme.io | Circuit breaker pattern |
| **Tenacity Python Library** | Latest | https://tenacity.readthedocs.io | Retry logic with jitter |
| **pgvector Documentation** | 0.5.x | https://github.com/pgvector/pgvector | Vector embeddings in PostgreSQL |
| **Redis Data Structures** | 7.x | https://redis.io/docs/data-types/ | Sorted sets, JSON, pub/sub |
| **HashiCorp Vault** | Latest | https://www.vaultproject.io/docs | Secrets management |
| **Apache Kafka** | 3.x | https://kafka.apache.org/documentation | Audit event streaming |
| **Ollama API** | Latest | https://github.com/ollama/ollama/blob/main/docs/api.md | Local LLM inference |
| **PM2 Documentation** | Latest | https://pm2.keymetrics.io/docs/usage/quick-start/ | MCP process management |

---

### 15.2 Internal References

| Document | Section | Description |
|----------|---------|-------------|
| **Data Layer Specification v4.0** | Section 5: Event Store | Tool invocation events published to Event Store |
| **Data Layer Specification v4.0** | Section 6: ABAC Engine | Permission checks via ABAC policy engine |
| **Data Layer Specification v4.0** | Section 13: Phase 13 MCP Integration | Foundation for Phase 15/16 MCP patterns |
| **Data Layer Specification v4.0** | Phase 15: Document Management | Document Bridge integration via document-consolidator |
| **Data Layer Specification v4.0** | Phase 16: Session Orchestration | State Bridge integration via context-orchestrator |
| **Agent Runtime Specification v1.2** | Section 4: Sandbox Management | BC-1 nested sandbox interface |
| **Model Gateway Specification v1.2** | Section 3: Function Calling | Tool selection and parameter extraction |
| **Integration Layer Specification v1.0** | Section 2: Tool Orchestration | BC-2 tool.invoke() interface consumer |
| **ADR-001: MCP Integration Architecture** | Full Document | stdio transport, capability negotiation, error handling |
| **ADR-002: Lightweight Development Stack** | Full Document | PostgreSQL + Redis + Ollama + PM2 technology decisions |

---

### 15.3 Glossary

| Term | Definition |
|------|------------|
| **ABAC** | Attribute-Based Access Control - Fine-grained authorization based on attributes of subject, resource, action, and context |
| **ADR** | Architecture Decision Record - Document capturing an important architectural decision |
| **AJV** | Another JSON Schema Validator - Industry-standard JSON Schema validation library |
| **BC-1** | Boundary Condition 1 - Nested sandbox interface between Agent Runtime (L02) and Tool Execution Layer (L03) |
| **BC-2** | Boundary Condition 2 - tool.invoke() interface between Tool Execution Layer (L03) and Integration Layer (L11) |
| **Circuit Breaker** | Resilience pattern that prevents cascading failures by opening circuit after threshold failures |
| **CloudEvents** | Specification for describing event data in a common way |
| **DID** | Decentralized Identifier - W3C standard for verifiable, self-sovereign digital identities |
| **gVisor** | User-space kernel for container isolation (cloud deployments) |
| **Firecracker** | MicroVM technology for hardware-level isolation (on-prem deployments) |
| **HPA** | Horizontal Pod Autoscaler - Kubernetes resource for auto-scaling pods based on metrics |
| **HITL** | Human-in-the-Loop - Approval workflow requiring human intervention |
| **JSON-RPC 2.0** | Remote procedure call protocol encoded in JSON |
| **JWT** | JSON Web Token - Compact, URL-safe means of representing claims |
| **L02** | Agent Runtime Layer - Layer responsible for agent execution sandboxing |
| **L03** | Tool Execution Layer - This specification's layer |
| **L11** | Integration Layer - Layer responsible for workflow orchestration |
| **LRU** | Least Recently Used - Cache eviction policy |
| **MCP** | Model Context Protocol - Open standard for AI agent-tool integration |
| **Micro-checkpoint** | Frequent (30s) checkpoint to Redis for quick resume |
| **Macro-checkpoint** | Milestone checkpoint to PostgreSQL for audit trail |
| **Named checkpoint** | Manual checkpoint for critical recovery points |
| **OPA** | Open Policy Agent - Policy engine for fine-grained authorization |
| **PII** | Personally Identifiable Information - Data that can identify an individual |
| **PM2** | Process Manager 2 - Production process manager for Node.js |
| **pgvector** | PostgreSQL extension for vector similarity search |
| **RS256** | RSA Signature with SHA-256 - Asymmetric signing algorithm for JWT |
| **SemVer** | Semantic Versioning - Version numbering scheme (major.minor.patch) |
| **STRIDE** | Security threat modeling framework: Spoofing, Tampering, Repudiation, Information Disclosure, Denial of Service, Elevation of Privilege |
| **TTL** | Time To Live - Expiration time for cached data |

------

## Appendix A: Gap Analysis Integration Summary

This appendix shows how all 24 gaps identified in the gap analysis have been addressed in the specification.

| Gap ID | Description | Priority | Section | How Addressed |
|--------|-------------|----------|---------|---------------|
| **G-001** | Tool capability manifest schema not fully defined | High | 11.3.1 | Complete manifest schema with required_permissions, result_schema, timeout_default, retry_policy, circuit_breaker_config fields defined in PostgreSQL schema and Python implementation |
| **G-002** | Semantic versioning conflict resolution for parallel versions | Medium | 11.3.1 | Version resolution algorithm using semantic_version library with version range matching (resolve_version method) |
| **G-003** | Tool deprecation workflow and migration paths | Medium | 11.3.1 | Lifecycle states (active, deprecated, sunset, removed) with deprecation_date, sunset_date, migration_guide_url fields and deprecate_tool method |
| **G-004** | Async execution patterns for long-running tools (> 15 min) | High | 11.3.7, 11.4.1 | Hybrid checkpointing with micro (Redis/30s), macro (PostgreSQL/milestones), named (manual) checkpoints. Async execution modes: polling, webhook, job queue |
| **G-005** | Tool execution priority scheduling and resource allocation | Medium | 10.4 | Feature flag `enable_tool_priority_scheduling` with priority field in tool manifest. HPA scales based on priority-weighted metrics |
| **G-006** | Capability token format and signing mechanism | Critical | 11.3.3 | JWT with RS256 signatures. Token structure with sub (DID), exp, tools[] array. Validation in Permission Checker |
| **G-007** | Permission cache invalidation on policy updates | High | 11.3.3 | Redis pub/sub subscription to 'abac:policy:updates' channel with automatic cache key deletion for affected DIDs |
| **G-008** | Circuit breaker transition notifications to dependent tools | Medium | 11.3.4 | State transition events published to Redis pub/sub channel 'cb:state:changes' for monitoring and dependent tool awareness |
| **G-009** | Half-open state testing strategy (canary vs all-or-nothing) | Medium | 11.3.4 | Canary testing in HALF_OPEN state with configurable half_open_max_calls (default 10). Gradual traffic increase on success |
| **G-010** | Result validation schema definition and enforcement | Critical | 11.3.5 | JSON Schema validation using AJV (jsonschema library) with type coercion and validation against tool manifest result_schema |
| **G-011** | Type coercion and sanitization rules for tool inputs | High | 11.3.5 | Type coercion pipeline (string->number, ISO 8601->Date, etc.) with injection attack prevention (SQL, command, XSS) |
| **G-012** | Structured output validation against tool manifest | High | 11.3.5 | validate_result method enforces JSON Schema from manifest. Validation errors return E3301 with detailed path and message |
| **G-013** | Document access permission model (ABAC integration) | High | 11.3.6 | Document queries check ABAC permissions before MCP retrieval. Permission results cached in Redis with pub/sub invalidation |
| **G-014** | Bulk document retrieval optimization | Medium | 11.3.6 | Two-tier caching (Redis 5-min + local LRU) reduces MCP round-trips. Batch queries supported via MCP protocol |
| **G-015** | Checkpoint diff/delta encoding for large states | Medium | 11.3.7 | Delta encoding with parent_checkpoint_id reference. gzip compression for >10KB checkpoints (60-80% reduction) |
| **G-016** | Checkpoint compression threshold tuning | Low | 11.3.7 | Compression applied for checkpoints >10KB. Configurable threshold per tool manifest. gzip chosen for balance of speed/ratio |
| **G-017** | PII sanitization rules for tool parameters in audit logs | Critical | 11.3.5, 12.2.4 | Regex patterns (email, SSN, CC, phone, IP) + field-based redaction (password, secret, token, apiKey). Applied before audit logging |
| **G-018** | Audit log schema with CloudEvents 1.0 alignment | High | 11.5 | CloudEvents 1.0 format for tool invocation events (tool.invoke.*, tool.complete.*, tool.error.*) with tool-specific extensions |
| **G-019** | Real-time audit stream backpressure handling | Medium | 9.4 | Backpressure detection via Kafka lag monitoring. Mitigation: sampling (10%), local disk buffering, compression, batching |
| **G-020** | Multi-tool workflow orchestration (sequential, parallel, conditional) | High | 14.2 | **Deferred to L11 Integration Layer**. L03 provides atomic tool invocation only. Workflow DSL and orchestration is L11 responsibility |
| **G-021** | Tool dependency graph resolution and cycle detection | Medium | 14.2 | **Deferred to L11 Integration Layer**. Dependency management belongs at workflow orchestration layer, not individual tool execution |
| **G-022** | HITL approval timeout and escalation policies | Medium | 7.4 | Three-tier escalation: primary approver (1h timeout) â†’ manager (4h) â†’ admin (24h). Configurable per tool manifest |
| **G-023** | Tool execution cost tracking and budgeting | Medium | 9.1 | Prometheus metrics track execution duration and resource usage. Cost calculation based on CPU/memory/duration in external analytics |
| **G-024** | Tool usage analytics and recommendation engine | Medium | 9.5 | Tool invocation history in PostgreSQL enables analytics. Recommendation engine uses invocation patterns and Ollama embeddings |

**Gap Status Summary:**
- **Total Gaps:** 24
- **Addressed in Specification:** 22 (92%)
- **Deferred to Other Layers:** 2 (G-020, G-021 - deferred to L11 Integration Layer)
- **Critical Gaps Addressed:** 3/3 (100%)
- **High-Priority Gaps Addressed:** 10/10 (100%)
- **Medium-Priority Gaps Addressed:** 9/10 (90% - 1 deferred)
- **Low-Priority Gaps Addressed:** 1/1 (100%)

**All critical and high-priority gaps have been fully addressed.**

---

## Appendix B: Error Code Reference

Complete error code reference for E3000-E3999 range.

### Error Code Ranges

| Range | Category | Description |
|-------|----------|-------------|
| E3000-E3099 | General Errors | Service-level errors, timeouts, rate limits |
| E3100-E3149 | Tool Registry | Tool not found, version conflicts, manifest errors |
| E3200-E3249 | Permissions | Authentication, authorization, capability token errors |
| E3300-E3349 | Validation | Schema validation, type coercion, sanitization |
| E3400-E3449 | Execution | Tool execution failures, timeouts, sandbox errors |
| E3500-E3549 | Circuit Breaker | External service failures, circuit breaker states |
| E3600-E3649 | Secrets Management | Vault errors, credential failures |
| E3700-E3749 | Async Execution | Job queue, webhook delivery, cancellation |
| E3800-E3849 | Audit Logging | Kafka errors, event serialization, backpressure |
| E3850-E3899 | Phase 15 MCP Document Bridge | MCP document server errors |
| E3900-E3949 | Phase 16 MCP State Bridge | MCP context server errors |

### Detailed Error Codes (E3000-E3999)

Refer to Section 11.5 for complete error code table with:
- Error code
- Description
- HTTP status code
- Resolution steps

**Error Code Design Principles:**
1. **Numeric ranges** indicate error category
2. **HTTP status codes** aligned with REST API standards
3. **Resolution guidance** provided for each code
4. **Consistent format** across all layers (E-prefix + 4 digits)

---

## Appendix C: Tool Manifest Schema (Complete JSON Schema)

```json
{
  "$schema": "https://json-schema.org/draft/2020-12/schema",
  "$id": "https://agentic-platform.local/schemas/tool-manifest.schema.json",
  "title": "Tool Manifest",
  "description": "Complete schema for tool capability manifest",
  "type": "object",
  "required": ["tool_id", "version", "name", "description", "provider", "protocol", "parameters"],
  "properties": {
    "tool_id": {
      "type": "string",
      "pattern": "^[a-z][a-z0-9_]*$",
      "minLength": 3,
      "maxLength": 255,
      "description": "Unique identifier for tool (snake_case)"
    },
    "version": {
      "type": "string",
      "pattern": "^\\d+\\.\\d+\\.\\d+(-[a-z0-9.]+)?(\\+[a-z0-9.]+)?$",
      "description": "Semantic version (major.minor.patch)"
    },
    "name": {
      "type": "string",
      "minLength": 3,
      "maxLength": 255,
      "description": "Human-readable tool name"
    },
    "description": {
      "type": "string",
      "minLength": 10,
      "maxLength": 2000,
      "description": "Detailed description for semantic search"
    },
    "provider": {
      "type": "string",
      "description": "Tool provider organization or author"
    },
    "protocol": {
      "type": "string",
      "enum": ["native", "mcp", "openapi", "langchain", "custom"],
      "description": "Tool invocation protocol"
    },
    "parameters": {
      "type": "object",
      "description": "JSON Schema for tool parameters",
      "$ref": "https://json-schema.org/draft/2020-12/schema"
    },
    "result_schema": {
      "type": "object",
      "description": "JSON Schema for tool output",
      "$ref": "https://json-schema.org/draft/2020-12/schema"
    },
    "required_permissions": {
      "type": "array",
      "items": {
        "type": "string",
        "pattern": "^[a-z_]+:[^ ]+$"
      },
      "description": "Permission requirements (e.g., 'filesystem:read', 'network:https://api.example.com')",
      "examples": [
        "filesystem:read:/data",
        "network:https://api.example.com",
        "credentials:aws_s3",
        "database:postgresql:read"
      ]
    },
    "timeout_default": {
      "type": "integer",
      "minimum": 1,
      "maximum": 7200,
      "default": 30,
      "description": "Default timeout in seconds"
    },
    "timeout_max": {
      "type": "integer",
      "minimum": 1,
      "maximum": 86400,
      "description": "Maximum allowed timeout (for async operations)"
    },
    "retry_policy": {
      "type": "object",
      "properties": {
        "max_attempts": {
          "type": "integer",
          "minimum": 1,
          "maximum": 10,
          "default": 3
        },
        "backoff_multiplier": {
          "type": "number",
          "minimum": 1.0,
          "maximum": 10.0,
          "default": 2.0
        },
        "backoff_max_seconds": {
          "type": "integer",
          "minimum": 1,
          "maximum": 300,
          "default": 60
        },
        "retry_on_status_codes": {
          "type": "array",
          "items": {
            "type": "integer",
            "minimum": 400,
            "maximum": 599
          },
          "default": [429, 500, 502, 503, 504]
        }
      }
    },
    "circuit_breaker_config": {
      "type": "object",
      "properties": {
        "failure_threshold": {
          "type": "integer",
          "minimum": 1,
          "maximum": 100,
          "default": 5,
          "description": "Number of failures to open circuit"
        },
        "success_threshold": {
          "type": "integer",
          "minimum": 1,
          "maximum": 100,
          "default": 3,
          "description": "Number of successes to close circuit"
        },
        "timeout_seconds": {
          "type": "integer",
          "minimum": 1,
          "maximum": 3600,
          "default": 60,
          "description": "Time to wait before half-open"
        },
        "half_open_max_calls": {
          "type": "integer",
          "minimum": 1,
          "maximum": 100,
          "default": 10,
          "description": "Canary request limit in half-open"
        }
      }
    },
    "resource_limits": {
      "type": "object",
      "properties": {
        "cpu": {
          "type": "string",
          "pattern": "^\\d+m?$",
          "default": "1",
          "description": "CPU limit (e.g., '500m', '2')"
        },
        "memory": {
          "type": "string",
          "pattern": "^\\d+(Mi|Gi)$",
          "default": "512Mi",
          "description": "Memory limit (e.g., '512Mi', '2Gi')"
        },
        "ephemeral_storage": {
          "type": "string",
          "pattern": "^\\d+(Mi|Gi)$",
          "default": "1Gi",
          "description": "Ephemeral storage limit"
        }
      }
    },
    "network_policy": {
      "type": "object",
      "properties": {
        "allowed_domains": {
          "type": "array",
          "items": {
            "type": "string",
            "format": "hostname"
          },
          "description": "Allowed hostnames (wildcards supported: *.example.com)"
        },
        "allowed_ports": {
          "type": "array",
          "items": {
            "type": "integer",
            "minimum": 1,
            "maximum": 65535
          },
          "default": [80, 443]
        },
        "deny_all_egress": {
          "type": "boolean",
          "default": false,
          "description": "Block all outbound network access"
        }
      }
    },
    "external_service": {
      "type": "string",
      "description": "External service ID for circuit breaker (e.g., 'stripe_api', 'sendgrid')"
    },
    "checkpoint_config": {
      "type": "object",
      "properties": {
        "enabled": {
          "type": "boolean",
          "default": false,
          "description": "Enable checkpointing for this tool"
        },
        "micro_interval_seconds": {
          "type": "integer",
          "minimum": 10,
          "maximum": 300,
          "default": 30,
          "description": "Micro-checkpoint interval"
        },
        "macro_events": {
          "type": "array",
          "items": {
            "type": "string"
          },
          "description": "Events that trigger macro-checkpoints",
          "examples": [
            "phase_complete",
            "milestone_reached",
            "approval_required"
          ]
        }
      }
    },
    "lifecycle_state": {
      "type": "string",
      "enum": ["active", "deprecated", "sunset", "removed"],
      "default": "active"
    },
    "deprecation_date": {
      "type": "string",
      "format": "date",
      "description": "Date tool was marked deprecated"
    },
    "sunset_date": {
      "type": "string",
      "format": "date",
      "description": "Date tool will be removed"
    },
    "migration_guide_url": {
      "type": "string",
      "format": "uri",
      "description": "URL to migration documentation"
    },
    "replacement_tool_id": {
      "type": "string",
      "description": "Recommended replacement tool"
    },
    "priority": {
      "type": "integer",
      "minimum": 1,
      "maximum": 10,
      "default": 5,
      "description": "Execution priority (1=low, 10=critical)"
    },
    "tags": {
      "type": "array",
      "items": {
        "type": "string"
      },
      "description": "Searchable tags for tool discovery"
    },
    "changelog": {
      "type": "string",
      "description": "Version changelog"
    },
    "breaking_changes": {
      "type": "boolean",
      "default": false,
      "description": "True if version introduces breaking changes"
    },
    "documentation_url": {
      "type": "string",
      "format": "uri",
      "description": "Link to tool documentation"
    },
    "source_code_url": {
      "type": "string",
      "format": "uri",
      "description": "Link to tool source code"
    },
    "license": {
      "type": "string",
      "description": "Tool license (SPDX identifier)",
      "examples": ["MIT", "Apache-2.0", "GPL-3.0", "Proprietary"]
    },
    "author": {
      "type": "object",
      "properties": {
        "name": {"type": "string"},
        "email": {"type": "string", "format": "email"},
        "url": {"type": "string", "format": "uri"}
      }
    }
  },
  "examples": [
    {
      "tool_id": "send_email",
      "version": "1.2.3",
      "name": "Email Sender",
      "description": "Send emails via SMTP or SendGrid API. Supports attachments, HTML templates, and delivery tracking.",
      "provider": "Platform Team",
      "protocol": "native",
      "parameters": {
        "type": "object",
        "properties": {
          "to": {"type": "string", "format": "email"},
          "subject": {"type": "string", "maxLength": 200},
          "body": {"type": "string"},
          "attachments": {
            "type": "array",
            "items": {"type": "string", "format": "uri"}
          }
        },
        "required": ["to", "subject", "body"]
      },
      "result_schema": {
        "type": "object",
        "properties": {
          "message_id": {"type": "string"},
          "status": {"type": "string", "enum": ["sent", "queued", "failed"]}
        },
        "required": ["message_id", "status"]
      },
      "required_permissions": [
        "network:https://api.sendgrid.com",
        "credentials:sendgrid"
      ],
      "timeout_default": 30,
      "external_service": "sendgrid",
      "circuit_breaker_config": {
        "failure_threshold": 5,
        "timeout_seconds": 60
      },
      "priority": 7,
      "tags": ["communication", "email", "notifications"]
    }
  ]
}
```

---

## Appendix D: MCP Bridge Configuration Examples

### D.1 Document Bridge Configuration

**PM2 Ecosystem Configuration:**
```javascript
// ecosystem.config.js (excerpt)
{
  name: 'mcp-document-consolidator',
  script: './platform/services/mcp-document-consolidator/build/index.js',
  instances: 1,
  exec_mode: 'fork',
  env: {
    NODE_ENV: 'production',
    POSTGRES_HOST: 'localhost',
    POSTGRES_PORT: 5432,
    POSTGRES_DB: 'document_consolidator',
    POSTGRES_USER: 'toolexec',
    POSTGRES_PASSWORD: process.env.POSTGRES_PASSWORD,
    LOG_LEVEL: 'info',
    EMBEDDING_MODEL: 'mistral:7b',  // For semantic search
    CACHE_TTL_SECONDS: 300  // 5-minute cache TTL
  },
  autorestart: true,
  max_restarts: 10,
  min_uptime: '10s'
}
```

**Tool Execution Layer Configuration:**
```yaml
# config/mcp_bridges.yaml
document_bridge:
  mcp_server_path: /mcp/document-consolidator/server.js
  enabled: true
  cache:
    redis:
      enabled: true
      ttl_seconds: 300
      key_prefix: "doc:query:"
    local:
      enabled: true
      max_size: 1000
      ttl_seconds: 3600
  fallback:
    direct_postgres: true
    timeout_ms: 5000
  retry:
    max_attempts: 3
    backoff_ms: 1000
```

**MCP Method Mappings:**
```yaml
# Available MCP methods from document-consolidator
methods:
  - name: get_source_of_truth
    description: Query for authoritative document information
    parameters:
      - query: string
      - scope: array (optional)
      - confidence_threshold: number (default: 0.7)
      - verify_claims: boolean (default: true)
    cache: true

  - name: find_overlaps
    description: Find overlapping or conflicting document content
    parameters:
      - scope: array (optional)
      - similarity_threshold: number (default: 0.8)
      - include_archived: boolean (default: false)
    cache: false

  - name: ingest_document
    description: Add document to consolidation index
    parameters:
      - content: string
      - document_type: enum
      - tags: array (optional)
      - extract_claims: boolean (default: true)
    cache: false

  - name: deprecate_document
    description: Mark document as deprecated
    parameters:
      - document_id: uuid
      - reason: string
      - superseded_by: uuid (optional)
    cache: false
```

---

### D.2 State Bridge Configuration

**PM2 Ecosystem Configuration:**
```javascript
// ecosystem.config.js (excerpt)
{
  name: 'mcp-context-orchestrator',
  script: './platform/services/mcp-context-orchestrator/build/index.js',
  instances: 1,
  exec_mode: 'fork',
  env: {
    NODE_ENV: 'production',
    POSTGRES_HOST: 'localhost',
    POSTGRES_PORT: 5432,
    POSTGRES_DB: 'context_orchestrator',
    POSTGRES_USER: 'toolexec',
    POSTGRES_PASSWORD: process.env.POSTGRES_PASSWORD,
    REDIS_HOST: 'localhost',
    REDIS_PORT: 6379,
    REDIS_PASSWORD: process.env.REDIS_PASSWORD,
    LOG_LEVEL: 'info',
    CHECKPOINT_RETENTION_DAYS: 90,
    MICRO_CHECKPOINT_TTL_SECONDS: 3600  // 1 hour TTL for micro-checkpoints
  },
  autorestart: true,
  max_restarts: 10,
  min_uptime: '10s'
}
```

**Tool Execution Layer Configuration:**
```yaml
# config/mcp_bridges.yaml
state_bridge:
  mcp_server_path: /mcp/context-orchestrator/server.js
  enabled: true
  checkpointing:
    micro:
      enabled: true
      interval_seconds: 30
      storage: redis
      ttl_seconds: 3600
      compression: true
      compression_threshold_bytes: 10240
    macro:
      enabled: true
      storage: postgresql
      retention_days: 90
      archive_to_s3: true
      archive_after_days: 90
      compression: true
    named:
      enabled: true
      storage: postgresql
      retention: indefinite
      compression: true
  retry:
    max_attempts: 3
    backoff_ms: 1000
```

**MCP Method Mappings:**
```yaml
# Available MCP methods from context-orchestrator
methods:
  - name: save_context_snapshot
    description: Save micro-checkpoint to Redis
    parameters:
      - taskId: string
      - updates: object
      - syncToFile: boolean (default: true)
    cache: false

  - name: create_checkpoint
    description: Create macro or named checkpoint
    parameters:
      - taskId: string
      - label: string
      - checkpointType: enum (milestone, manual, pre_migration, recovery_point, auto)
      - description: string (optional)
    cache: false

  - name: get_unified_context
    description: Retrieve current task context
    parameters:
      - taskId: string
      - includeVersionHistory: boolean (default: false)
      - includeRelationships: boolean (default: true)
    cache: true
    ttl_seconds: 60

  - name: rollback_to
    description: Rollback to previous checkpoint
    parameters:
      - taskId: string
      - target: object {type: "version" | "checkpoint", version?: number, checkpointId?: string}
      - createBackup: boolean (default: true)
    cache: false

  - name: switch_task
    description: Switch between tasks with state preservation
    parameters:
      - fromTaskId: string (optional)
      - toTaskId: string
      - currentTaskUpdates: object (optional)
      - saveCurrentState: boolean (default: true)
    cache: false
```

---

### D.3 MCP Health Check Script

```bash
#!/bin/bash
# check-mcp-health.sh

check_mcp_service() {
  SERVICE_NAME=$1

  # Check if PM2 process is running
  if ! pm2 describe $SERVICE_NAME > /dev/null 2>&1; then
    echo "CRITICAL: $SERVICE_NAME not running"
    return 1
  fi

  # Check if process is responsive
  HEALTH_RESPONSE=$(echo '{"jsonrpc":"2.0","id":1,"method":"health","params":{}}' | \
    timeout 5s node platform/services/${SERVICE_NAME}/build/index.js 2>&1 | \
    tail -n 1)

  if echo "$HEALTH_RESPONSE" | grep -q '"status":"healthy"'; then
    echo "OK: $SERVICE_NAME is healthy"
    return 0
  else
    echo "WARNING: $SERVICE_NAME is unresponsive"
    echo "Response: $HEALTH_RESPONSE"
    return 2
  fi
}

# Check both MCP services
check_mcp_service "mcp-document-consolidator"
DOC_STATUS=$?

check_mcp_service "mcp-context-orchestrator"
CTX_STATUS=$?

# Exit with worst status
if [ $DOC_STATUS -ne 0 ] || [ $CTX_STATUS -ne 0 ]; then
  exit 1
fi

exit 0
```

---

### D.4 MCP Error Handling Patterns

**Connection Error Handling:**
```python
async def call_mcp_with_retry(method: str, params: dict, max_attempts: int = 3):
    """Call MCP method with retry and fallback."""
    last_error = None

    for attempt in range(max_attempts):
        try:
            result = await mcp_client.call(method, params)
            return result
        except MCPConnectionError as e:
            last_error = e
            if attempt < max_attempts - 1:
                backoff_ms = 1000 * (2 ** attempt)  # Exponential backoff
                await asyncio.sleep(backoff_ms / 1000)
        except MCPTimeoutError as e:
            last_error = e
            # Timeout errors don't retry - fail fast
            break

    # All retries exhausted - use fallback
    if method == 'get_source_of_truth':
        # Fallback to direct PostgreSQL query
        return await fallback_direct_query(params)
    elif method == 'save_context_snapshot':
        # Non-critical - log and continue
        logger.warning(f"Failed to save micro-checkpoint: {last_error}")
        return None
    else:
        raise MCPError(f"MCP method {method} failed after {max_attempts} attempts: {last_error}")
```

**Graceful Degradation:**
```python
async def get_document_context_safe(query: str) -> dict:
    """Get document context with graceful degradation."""
    try:
        # Try MCP bridge first
        result = await document_bridge.get_source_of_truth(query)
        return {
            'answer': result['answer'],
            'confidence': result['confidence'],
            'sources': result['sources'],
            'source': 'mcp'
        }
    except MCPError as e:
        logger.warning(f"MCP unavailable, using fallback: {e}")

        # Fallback to cached data
        cached = await redis.get(f"doc:fallback:{hash(query)}")
        if cached:
            return {
                'answer': cached['answer'],
                'confidence': 0.5,  # Lower confidence for cached
                'sources': cached['sources'],
                'source': 'cache'
            }

        # Last resort: return error but don't fail invocation
        return {
            'answer': 'Document context unavailable',
            'confidence': 0.0,
            'sources': [],
            'source': 'unavailable'
        }
```

---

## Document Version History

| Version | Date | Author | Changes |
|---------|------|--------|---------|
| 1.0 | 2026-01-14 | Tool Execution Layer Team | Initial specification (Sections 11-15, Appendices A-D) |

---

## Acknowledgments

This specification was developed through:
- **Industry research** across 8 categories (tool registries, sandboxing, resilience, MCP integration, etc.)
- **Gap analysis** identifying 24 gaps in existing architecture
- **Integration** with Data Layer (v4.0), Agent Runtime (v1.2), Model Gateway (v1.2), Integration Layer (v1.0)
- **Alignment** with ADR-001 (MCP stdio transport) and ADR-002 (PostgreSQL + Redis + Ollama + PM2 stack)
- **Standards compliance** with MCP, JSON-RPC 2.0, SemVer, OpenAPI, JSON Schema, CloudEvents 1.0

Special thanks to:
- Data Layer team for ABAC engine, Event Store, and Phase 15/16 MCP services
- Agent Runtime team for BC-1 nested sandbox interface definition
- Security team for threat modeling and PII sanitization requirements
- Platform team for Kubernetes and PM2 operational guidance

---

**End of Tool Execution Layer Specification - Part 3**


---

## Document Version History

| Version | Date | Author | Changes |
|---------|------|--------|---------|
| 1.0.0 | 2026-01-14 | Tool Execution Layer Team | Initial release: 15 sections, 4 appendices, complete implementation guide, testing strategy, deployment procedures, and MCP Phase 15/16 integration |

---

## Change Log

### Version 1.0.0 (2026-01-14)

**Initial Release**

- Complete specification for Tool Execution Layer (L03)
- 10 core components: Tool Registry, Tool Executor, Permission Checker, External Adapter Manager, Circuit Breaker Controller, Result Validator, Document Bridge, State Bridge, Audit Logger
- Integration with Data Layer (ABAC, Event Store, Phase 13/15/16)
- Boundary conditions: BC-1 (nested sandbox with L02), BC-2 (tool.invoke() with L11)
- Technology stack: PostgreSQL 16 + pgvector, Redis 7, Ollama, PM2, Kubernetes
- MCP integration: stdio transport (ADR-001), Phase 15 Document Bridge, Phase 16 State Bridge
- Security: JWT RS256 capability tokens, PII sanitization, gVisor/Firecracker isolation
- Observability: Prometheus metrics, structured logging, OpenTelemetry tracing, Grafana dashboards
- Testing: Unit, integration, performance, chaos, and security test suites
- Deployment: Kubernetes manifests, Docker images, PM2 ecosystem, disaster recovery procedures
- Error codes: E3000-E3999 complete reference
- Gap analysis: 24 gaps addressed (92% in L03, 8% deferred to L11)

---

**End of Tool Execution Layer Specification v1.0.0**
